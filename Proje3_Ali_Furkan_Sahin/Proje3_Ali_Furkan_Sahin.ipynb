{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05824c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe5f95e-7755-4211-bdcc-c17a02ba2141",
   "metadata": {},
   "source": [
    "## Web Scraping:\n",
    "\"https://stockanalysis.com\" sitesinin icerisinde bulunan industry ve industry icerisindeki sector'leri fetch eden method'lari yazalim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f7d2e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Industry icerisindeki sector'leri fetch eder.\n",
    "def fetch_sectors_name():\n",
    "    url = \"https://stockanalysis.com/stocks/industry/sectors/\"\n",
    "    response = requests.get(url) # Url'deki server'a client'ten bir get request'i gonderiyoruz.\n",
    "    if response.status_code == 200: # Gonderilen get request'ine gelen response'un status_code'u 200 ise basarili bir sekilde gelmis demektir.\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\") \n",
    "        df = pd.read_html(str(soup.find_all(\"table\")))[0]\n",
    "    else:\n",
    "        print(f\"Error: Failed to fetch datasets from page {url}\")\n",
    "    return df\n",
    "    \n",
    "# Industry'leri fetch eder.\n",
    "def fetch_industry_names():\n",
    "    url = \"https://stockanalysis.com/stocks/industry/all/\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        df = pd.read_html(str(soup.find_all(\"table\")))[0]\n",
    "    else:\n",
    "        print(f\"Error: Failed to fetch datasets from page {url}\")\n",
    "    return df\n",
    "\n",
    "# Parameter olarak girilen sector'un kendisini fetch eder.\n",
    "def fetch_data(sectors):\n",
    "    url = f\"https://stockanalysis.com/stocks/sector/{sectors}/\" # Endpoint'i handle ederek sector'leri fetch edebiliriz.\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        df = pd.read_html(str(soup.find_all(\"table\")))[0]\n",
    "        df.drop(columns=\"No.\", inplace=True)\n",
    "    else:\n",
    "        print(f\"Error: Failed to fetch datasets from page {url}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "177d4095",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jedim\\AppData\\Local\\Temp\\ipykernel_22196\\889521384.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(soup.find_all(\"table\")))[0]\n",
      "C:\\Users\\jedim\\AppData\\Local\\Temp\\ipykernel_22196\\889521384.py:18: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(soup.find_all(\"table\")))[0]\n"
     ]
    }
   ],
   "source": [
    "sectors = fetch_sectors_name()\n",
    "industry = fetch_industry_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab177ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector Name</th>\n",
       "      <th>Stocks</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Div. Yield</th>\n",
       "      <th>PE Ratio</th>\n",
       "      <th>Profit Margin</th>\n",
       "      <th>1D Change</th>\n",
       "      <th>1Y Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Financials</td>\n",
       "      <td>1384</td>\n",
       "      <td>9,687.69B</td>\n",
       "      <td>2.41%</td>\n",
       "      <td>14.70</td>\n",
       "      <td>17.75%</td>\n",
       "      <td>-0.02%</td>\n",
       "      <td>11.46%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1217</td>\n",
       "      <td>8,168.36B</td>\n",
       "      <td>0.43%</td>\n",
       "      <td>50.93</td>\n",
       "      <td>4.07%</td>\n",
       "      <td>-0.26%</td>\n",
       "      <td>7.46%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Technology</td>\n",
       "      <td>788</td>\n",
       "      <td>17.72T</td>\n",
       "      <td>0.43%</td>\n",
       "      <td>44.88</td>\n",
       "      <td>13.16%</td>\n",
       "      <td>0.30%</td>\n",
       "      <td>14.79%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Industrials</td>\n",
       "      <td>652</td>\n",
       "      <td>5,478.42B</td>\n",
       "      <td>1.10%</td>\n",
       "      <td>26.71</td>\n",
       "      <td>7.32%</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>17.82%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>578</td>\n",
       "      <td>7,264.49B</td>\n",
       "      <td>0.65%</td>\n",
       "      <td>27.33</td>\n",
       "      <td>5.95%</td>\n",
       "      <td>0.11%</td>\n",
       "      <td>2.22%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Real Estate</td>\n",
       "      <td>264</td>\n",
       "      <td>1,506.12B</td>\n",
       "      <td>4.12%</td>\n",
       "      <td>50.70</td>\n",
       "      <td>8.89%</td>\n",
       "      <td>1.20%</td>\n",
       "      <td>7.95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Materials</td>\n",
       "      <td>263</td>\n",
       "      <td>2,069.57B</td>\n",
       "      <td>1.55%</td>\n",
       "      <td>19.61</td>\n",
       "      <td>8.68%</td>\n",
       "      <td>-0.20%</td>\n",
       "      <td>1.63%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Communication Services</td>\n",
       "      <td>260</td>\n",
       "      <td>5,361.59B</td>\n",
       "      <td>1.08%</td>\n",
       "      <td>28.01</td>\n",
       "      <td>10.40%</td>\n",
       "      <td>-0.15%</td>\n",
       "      <td>2.41%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Energy</td>\n",
       "      <td>253</td>\n",
       "      <td>3,646.12B</td>\n",
       "      <td>2.85%</td>\n",
       "      <td>8.01</td>\n",
       "      <td>12.42%</td>\n",
       "      <td>-0.15%</td>\n",
       "      <td>17.73%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Consumer Staples</td>\n",
       "      <td>241</td>\n",
       "      <td>4,035.50B</td>\n",
       "      <td>1.44%</td>\n",
       "      <td>29.74</td>\n",
       "      <td>4.72%</td>\n",
       "      <td>0.28%</td>\n",
       "      <td>12.48%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Utilities</td>\n",
       "      <td>108</td>\n",
       "      <td>1,292.69B</td>\n",
       "      <td>3.60%</td>\n",
       "      <td>24.57</td>\n",
       "      <td>7.86%</td>\n",
       "      <td>0.11%</td>\n",
       "      <td>-5.43%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>4</td>\n",
       "      <td>2.42B</td>\n",
       "      <td>9.50%</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.13%</td>\n",
       "      <td>4.40%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Sector Name  Stocks Market Cap Div. Yield PE Ratio  \\\n",
       "0               Financials    1384  9,687.69B      2.41%    14.70   \n",
       "1               Healthcare    1217  8,168.36B      0.43%    50.93   \n",
       "2               Technology     788     17.72T      0.43%    44.88   \n",
       "3              Industrials     652  5,478.42B      1.10%    26.71   \n",
       "4   Consumer Discretionary     578  7,264.49B      0.65%    27.33   \n",
       "5              Real Estate     264  1,506.12B      4.12%    50.70   \n",
       "6                Materials     263  2,069.57B      1.55%    19.61   \n",
       "7   Communication Services     260  5,361.59B      1.08%    28.01   \n",
       "8                   Energy     253  3,646.12B      2.85%     8.01   \n",
       "9         Consumer Staples     241  4,035.50B      1.44%    29.74   \n",
       "10               Utilities     108  1,292.69B      3.60%    24.57   \n",
       "11           Miscellaneous       4      2.42B      9.50%        -   \n",
       "\n",
       "   Profit Margin 1D Change 1Y Change  \n",
       "0         17.75%    -0.02%    11.46%  \n",
       "1          4.07%    -0.26%     7.46%  \n",
       "2         13.16%     0.30%    14.79%  \n",
       "3          7.32%     0.27%    17.82%  \n",
       "4          5.95%     0.11%     2.22%  \n",
       "5          8.89%     1.20%     7.95%  \n",
       "6          8.68%    -0.20%     1.63%  \n",
       "7         10.40%    -0.15%     2.41%  \n",
       "8         12.42%    -0.15%    17.73%  \n",
       "9          4.72%     0.28%    12.48%  \n",
       "10         7.86%     0.11%    -5.43%  \n",
       "11             -    -0.13%     4.40%  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58126926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry Name</th>\n",
       "      <th>Stocks</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Div. Yield</th>\n",
       "      <th>PE Ratio</th>\n",
       "      <th>Profit Margin</th>\n",
       "      <th>1D Change</th>\n",
       "      <th>1Y Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Biotechnology</td>\n",
       "      <td>690</td>\n",
       "      <td>1,492.64B</td>\n",
       "      <td>0.02%</td>\n",
       "      <td>-</td>\n",
       "      <td>-26.05%</td>\n",
       "      <td>-0.73%</td>\n",
       "      <td>14.61%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asset Management</td>\n",
       "      <td>485</td>\n",
       "      <td>1,095.86B</td>\n",
       "      <td>5.70%</td>\n",
       "      <td>32.23</td>\n",
       "      <td>10.86%</td>\n",
       "      <td>0.06%</td>\n",
       "      <td>6.66%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Banks - Regional</td>\n",
       "      <td>356</td>\n",
       "      <td>1,277.63B</td>\n",
       "      <td>2.76%</td>\n",
       "      <td>9.80</td>\n",
       "      <td>22.99%</td>\n",
       "      <td>-0.20%</td>\n",
       "      <td>4.40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Software - Application</td>\n",
       "      <td>248</td>\n",
       "      <td>2,212.06B</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>159.53</td>\n",
       "      <td>4.61%</td>\n",
       "      <td>0.03%</td>\n",
       "      <td>17.40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shell Companies</td>\n",
       "      <td>242</td>\n",
       "      <td>60.96B</td>\n",
       "      <td>0.02%</td>\n",
       "      <td>-</td>\n",
       "      <td>-39.12%</td>\n",
       "      <td>0.25%</td>\n",
       "      <td>6.95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Utilities - Independent Power Producers</td>\n",
       "      <td>5</td>\n",
       "      <td>40.67B</td>\n",
       "      <td>2.77%</td>\n",
       "      <td>43.18</td>\n",
       "      <td>1.94%</td>\n",
       "      <td>1.60%</td>\n",
       "      <td>48.88%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Aluminum</td>\n",
       "      <td>4</td>\n",
       "      <td>10.75B</td>\n",
       "      <td>2.46%</td>\n",
       "      <td>-</td>\n",
       "      <td>-2.13%</td>\n",
       "      <td>1.00%</td>\n",
       "      <td>19.92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Confectioners</td>\n",
       "      <td>4</td>\n",
       "      <td>137.01B</td>\n",
       "      <td>2.50%</td>\n",
       "      <td>19.83</td>\n",
       "      <td>14.40%</td>\n",
       "      <td>2.43%</td>\n",
       "      <td>-17.96%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Infrastructure Operations</td>\n",
       "      <td>3</td>\n",
       "      <td>7.93B</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>43.82</td>\n",
       "      <td>5.71%</td>\n",
       "      <td>-1.20%</td>\n",
       "      <td>3.73%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Financial Conglomerates</td>\n",
       "      <td>3</td>\n",
       "      <td>8.16B</td>\n",
       "      <td>4.15%</td>\n",
       "      <td>20.89</td>\n",
       "      <td>3.98%</td>\n",
       "      <td>-4.57%</td>\n",
       "      <td>2.94%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Industry Name  Stocks Market Cap Div. Yield  \\\n",
       "0                              Biotechnology     690  1,492.64B      0.02%   \n",
       "1                           Asset Management     485  1,095.86B      5.70%   \n",
       "2                           Banks - Regional     356  1,277.63B      2.76%   \n",
       "3                     Software - Application     248  2,212.06B      0.12%   \n",
       "4                            Shell Companies     242     60.96B      0.02%   \n",
       "..                                       ...     ...        ...        ...   \n",
       "140  Utilities - Independent Power Producers       5     40.67B      2.77%   \n",
       "141                                 Aluminum       4     10.75B      2.46%   \n",
       "142                            Confectioners       4    137.01B      2.50%   \n",
       "143                Infrastructure Operations       3      7.93B      0.18%   \n",
       "144                  Financial Conglomerates       3      8.16B      4.15%   \n",
       "\n",
       "    PE Ratio Profit Margin 1D Change 1Y Change  \n",
       "0          -       -26.05%    -0.73%    14.61%  \n",
       "1      32.23        10.86%     0.06%     6.66%  \n",
       "2       9.80        22.99%    -0.20%     4.40%  \n",
       "3     159.53         4.61%     0.03%    17.40%  \n",
       "4          -       -39.12%     0.25%     6.95%  \n",
       "..       ...           ...       ...       ...  \n",
       "140    43.18         1.94%     1.60%    48.88%  \n",
       "141        -        -2.13%     1.00%    19.92%  \n",
       "142    19.83        14.40%     2.43%   -17.96%  \n",
       "143    43.82         5.71%    -1.20%     3.73%  \n",
       "144    20.89         3.98%    -4.57%     2.94%  \n",
       "\n",
       "[145 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "industry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2307d9a9-d568-4d49-82f7-5ec9d4d0f3a4",
   "metadata": {},
   "source": [
    "## Download Sectors Data:\n",
    "Define ettigimiz fetch_data() method'unu kullanarak financials, healtcare ve technology sector'lerindeki data'lari fetch edip to_csv() method'u ile indirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "def94f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jedim\\AppData\\Local\\Temp\\ipykernel_22196\\889521384.py:29: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(soup.find_all(\"table\")))[0]\n",
      "C:\\Users\\jedim\\AppData\\Local\\Temp\\ipykernel_22196\\889521384.py:29: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(soup.find_all(\"table\")))[0]\n",
      "C:\\Users\\jedim\\AppData\\Local\\Temp\\ipykernel_22196\\889521384.py:29: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(soup.find_all(\"table\")))[0]\n"
     ]
    }
   ],
   "source": [
    "fetch_data(sectors=\"financials\").to_csv(\"Datasets/financials.csv\") # financials sector'undeki data'lari Datasets/financials.csv icerisine save eder.\n",
    "fetch_data(sectors=\"healthcare\").to_csv(\"Datasets/healthcare.csv\")\n",
    "fetch_data(sectors=\"technology\").to_csv(\"Datasets/technology.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bedd6909",
   "metadata": {},
   "outputs": [],
   "source": [
    "finance = pd.read_csv(\"Datasets/financials.csv\") # Datasets/financials.csv icerisindeki csv'yi read eder.\n",
    "healthcare = pd.read_csv(\"Datasets/healthcare.csv\")\n",
    "technology = pd.read_csv(\"Datasets/technology.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3233e724-af6f-4e83-b11e-16e341f1c07a",
   "metadata": {},
   "source": [
    "## Filter Valid Symbols in Sectors:\n",
    "Fetch ettigimiz sector'lerin sembollerini kullanip 2005-01-01 tarihinden gunumuze kadar gecerli olan sembollerin karsılık geldigi data'lari yfinance uzerinden indirebilmek icin gerekli query'leri yazalim ve bunlardan Open isimli column'ini ay ay olacak sekilde tutalim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "347b4189",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  997 of 997 completed\n",
      "\n",
      "8 Failed downloads:\n",
      "['BNRE.A', 'CRD.B', 'BRK.B', 'DYCQ', 'AGM.A', 'LEGT', 'CRD.A', 'DISA']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1217 of 1217 completed\n",
      "\n",
      "1 Failed download:\n",
      "['BIO.B']: Exception('%ticker%: No price data found, symbol may be delisted (1d 2005-01-01 -> 2024-03-18)')\n",
      "[*********************100%%**********************]  786 of 786 completed\n"
     ]
    }
   ],
   "source": [
    "# Yahoo Finance uzerinden sector'lere gore indirme yapabilmek icin sector'lerin symbol'lerini kullanmaliyiz.\n",
    "# Bunu yapmak icin symbol'lerin Nan deger olmamali ve hepsinin string olmasi gerekmektedir. \n",
    "# Bu sebepten oturu valid symbol'leri iceren bir list comprehension yazmaliyiz.\n",
    "valid_symbols_f = [str(symbol) for symbol in finance.Symbol if isinstance(symbol, str)]\n",
    "\n",
    "# 2005-01-01 tarihinden itibaren valid symbol'leri iceren finance data'larini indirelim.\n",
    "finance_data = yf.download(valid_symbols_f, start='2005-01-01') \n",
    "\n",
    "# Healthcare sector'u icin de yapalim.\n",
    "valid_symbols_h = [str(symbol) for symbol in healthcare.Symbol if isinstance(symbol, str)]\n",
    "\n",
    "healthcare_data = yf.download(valid_symbols_h, start='2005-01-01') \n",
    "\n",
    "# Ayni sekilde technology sector'u icin de yapalim.\n",
    "valid_symbols_t =  [str(symbol) for symbol in technology.Symbol if isinstance(symbol, str)]\n",
    "\n",
    "technology_data = yf.download(valid_symbols_t, start='2005-01-01') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaefece2-b7b5-481c-8831-88758efea04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Adj Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>AACI</th>\n",
       "      <th>AACT</th>\n",
       "      <th>AAMC</th>\n",
       "      <th>AAME</th>\n",
       "      <th>AB</th>\n",
       "      <th>ABCB</th>\n",
       "      <th>ABL</th>\n",
       "      <th>ABTS</th>\n",
       "      <th>AC</th>\n",
       "      <th>ACAB</th>\n",
       "      <th>...</th>\n",
       "      <th>WU</th>\n",
       "      <th>WULF</th>\n",
       "      <th>XFIN</th>\n",
       "      <th>XP</th>\n",
       "      <th>XYF</th>\n",
       "      <th>YOTA</th>\n",
       "      <th>YRD</th>\n",
       "      <th>ZEO</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZLS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.822284</td>\n",
       "      <td>11.708350</td>\n",
       "      <td>13.489056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>347900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.895829</td>\n",
       "      <td>11.415431</td>\n",
       "      <td>13.252292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>388200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.849864</td>\n",
       "      <td>11.379169</td>\n",
       "      <td>12.837952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>602100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.776319</td>\n",
       "      <td>11.368010</td>\n",
       "      <td>13.107606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>321100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.950988</td>\n",
       "      <td>11.278738</td>\n",
       "      <td>12.923451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>806100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-12</th>\n",
       "      <td>10.990</td>\n",
       "      <td>10.550</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.760000</td>\n",
       "      <td>33.919998</td>\n",
       "      <td>46.480000</td>\n",
       "      <td>11.15</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>33.470001</td>\n",
       "      <td>11.344</td>\n",
       "      <td>...</td>\n",
       "      <td>4716300.0</td>\n",
       "      <td>13004600</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>6420000.0</td>\n",
       "      <td>32200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92400.0</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>2254900</td>\n",
       "      <td>3300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-13</th>\n",
       "      <td>10.990</td>\n",
       "      <td>10.560</td>\n",
       "      <td>3.51</td>\n",
       "      <td>2.790000</td>\n",
       "      <td>34.099998</td>\n",
       "      <td>46.080002</td>\n",
       "      <td>12.20</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>33.380001</td>\n",
       "      <td>10.730</td>\n",
       "      <td>...</td>\n",
       "      <td>6271000.0</td>\n",
       "      <td>13967000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14006800.0</td>\n",
       "      <td>48400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139400.0</td>\n",
       "      <td>27800.0</td>\n",
       "      <td>1956600</td>\n",
       "      <td>20200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-14</th>\n",
       "      <td>10.990</td>\n",
       "      <td>10.560</td>\n",
       "      <td>3.44</td>\n",
       "      <td>2.790000</td>\n",
       "      <td>33.369999</td>\n",
       "      <td>45.369999</td>\n",
       "      <td>12.22</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>33.290001</td>\n",
       "      <td>10.730</td>\n",
       "      <td>...</td>\n",
       "      <td>5671700.0</td>\n",
       "      <td>13796800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4594500.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46800.0</td>\n",
       "      <td>24600.0</td>\n",
       "      <td>2837400</td>\n",
       "      <td>68900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-15</th>\n",
       "      <td>11.050</td>\n",
       "      <td>10.565</td>\n",
       "      <td>3.66</td>\n",
       "      <td>2.710000</td>\n",
       "      <td>33.290001</td>\n",
       "      <td>45.590000</td>\n",
       "      <td>12.20</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>33.980000</td>\n",
       "      <td>10.730</td>\n",
       "      <td>...</td>\n",
       "      <td>9714000.0</td>\n",
       "      <td>13250300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6544500.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47500.0</td>\n",
       "      <td>554000.0</td>\n",
       "      <td>37419300</td>\n",
       "      <td>6300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-18</th>\n",
       "      <td>11.963</td>\n",
       "      <td>10.550</td>\n",
       "      <td>3.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.639999</td>\n",
       "      <td>45.810001</td>\n",
       "      <td>12.10</td>\n",
       "      <td>0.7599</td>\n",
       "      <td>33.790001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2344776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>339758.0</td>\n",
       "      <td>18568.0</td>\n",
       "      <td>12713.0</td>\n",
       "      <td>39811.0</td>\n",
       "      <td>9437.0</td>\n",
       "      <td>508657</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4834 rows × 5982 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price      Adj Close                                                       \\\n",
       "Ticker          AACI    AACT  AAMC      AAME         AB       ABCB    ABL   \n",
       "Date                                                                        \n",
       "2005-01-03       NaN     NaN   NaN  2.822284  11.708350  13.489056    NaN   \n",
       "2005-01-04       NaN     NaN   NaN  2.895829  11.415431  13.252292    NaN   \n",
       "2005-01-05       NaN     NaN   NaN  2.849864  11.379169  12.837952    NaN   \n",
       "2005-01-06       NaN     NaN   NaN  2.776319  11.368010  13.107606    NaN   \n",
       "2005-01-07       NaN     NaN   NaN  2.950988  11.278738  12.923451    NaN   \n",
       "...              ...     ...   ...       ...        ...        ...    ...   \n",
       "2024-03-12    10.990  10.550  3.45  2.760000  33.919998  46.480000  11.15   \n",
       "2024-03-13    10.990  10.560  3.51  2.790000  34.099998  46.080002  12.20   \n",
       "2024-03-14    10.990  10.560  3.44  2.790000  33.369999  45.369999  12.22   \n",
       "2024-03-15    11.050  10.565  3.66  2.710000  33.290001  45.590000  12.20   \n",
       "2024-03-18    11.963  10.550  3.92       NaN  33.639999  45.810001  12.10   \n",
       "\n",
       "Price                                  ...     Volume                    \\\n",
       "Ticker        ABTS         AC    ACAB  ...         WU      WULF    XFIN   \n",
       "Date                                   ...                                \n",
       "2005-01-03     NaN        NaN     NaN  ...        NaN         0     NaN   \n",
       "2005-01-04     NaN        NaN     NaN  ...        NaN     14600     NaN   \n",
       "2005-01-05     NaN        NaN     NaN  ...        NaN         0     NaN   \n",
       "2005-01-06     NaN        NaN     NaN  ...        NaN      2700     NaN   \n",
       "2005-01-07     NaN        NaN     NaN  ...        NaN      2600     NaN   \n",
       "...            ...        ...     ...  ...        ...       ...     ...   \n",
       "2024-03-12  0.8360  33.470001  11.344  ...  4716300.0  13004600  8000.0   \n",
       "2024-03-13  0.8250  33.380001  10.730  ...  6271000.0  13967000     0.0   \n",
       "2024-03-14  0.8100  33.290001  10.730  ...  5671700.0  13796800     0.0   \n",
       "2024-03-15  0.7500  33.980000  10.730  ...  9714000.0  13250300     0.0   \n",
       "2024-03-18  0.7599  33.790001     NaN  ...        NaN   2344776     NaN   \n",
       "\n",
       "Price                                                                   \\\n",
       "Ticker              XP      XYF     YOTA       YRD       ZEO      ZION   \n",
       "Date                                                                     \n",
       "2005-01-03         NaN      NaN      NaN       NaN       NaN    347900   \n",
       "2005-01-04         NaN      NaN      NaN       NaN       NaN    388200   \n",
       "2005-01-05         NaN      NaN      NaN       NaN       NaN    602100   \n",
       "2005-01-06         NaN      NaN      NaN       NaN       NaN    321100   \n",
       "2005-01-07         NaN      NaN      NaN       NaN       NaN    806100   \n",
       "...                ...      ...      ...       ...       ...       ...   \n",
       "2024-03-12   6420000.0  32200.0      0.0   92400.0    4300.0   2254900   \n",
       "2024-03-13  14006800.0  48400.0      0.0  139400.0   27800.0   1956600   \n",
       "2024-03-14   4594500.0   7000.0      0.0   46800.0   24600.0   2837400   \n",
       "2024-03-15   6544500.0   3000.0      0.0   47500.0  554000.0  37419300   \n",
       "2024-03-18    339758.0  18568.0  12713.0   39811.0    9437.0    508657   \n",
       "\n",
       "Price                \n",
       "Ticker          ZLS  \n",
       "Date                 \n",
       "2005-01-03      NaN  \n",
       "2005-01-04      NaN  \n",
       "2005-01-05      NaN  \n",
       "2005-01-06      NaN  \n",
       "2005-01-07      NaN  \n",
       "...             ...  \n",
       "2024-03-12   3300.0  \n",
       "2024-03-13  20200.0  \n",
       "2024-03-14  68900.0  \n",
       "2024-03-15   6300.0  \n",
       "2024-03-18      NaN  \n",
       "\n",
       "[4834 rows x 5982 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finance_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d839dd9-fe39-49cf-a127-23b81a68a187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Adj Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>A</th>\n",
       "      <th>AADI</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABCL</th>\n",
       "      <th>ABEO</th>\n",
       "      <th>ABIO</th>\n",
       "      <th>ABOS</th>\n",
       "      <th>ABSI</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ABUS</th>\n",
       "      <th>...</th>\n",
       "      <th>ZLAB</th>\n",
       "      <th>ZNTL</th>\n",
       "      <th>ZOM</th>\n",
       "      <th>ZTEK</th>\n",
       "      <th>ZTS</th>\n",
       "      <th>ZURA</th>\n",
       "      <th>ZVRA</th>\n",
       "      <th>ZVSA</th>\n",
       "      <th>ZYME</th>\n",
       "      <th>ZYXI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-01-03</th>\n",
       "      <td>14.689768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21500.00</td>\n",
       "      <td>148932.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.846619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-04</th>\n",
       "      <td>14.302225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21750.00</td>\n",
       "      <td>148932.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.697101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-05</th>\n",
       "      <td>14.296078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20812.50</td>\n",
       "      <td>148327.203125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.528505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-06</th>\n",
       "      <td>13.982349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20812.50</td>\n",
       "      <td>150595.203125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.856168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-07</th>\n",
       "      <td>13.970040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20312.50</td>\n",
       "      <td>148629.593750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.110657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-12</th>\n",
       "      <td>147.839996</td>\n",
       "      <td>1.94</td>\n",
       "      <td>180.919998</td>\n",
       "      <td>4.880</td>\n",
       "      <td>8.18</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>4.12</td>\n",
       "      <td>4.94</td>\n",
       "      <td>120.760002</td>\n",
       "      <td>2.69</td>\n",
       "      <td>...</td>\n",
       "      <td>396700.0</td>\n",
       "      <td>1013900.0</td>\n",
       "      <td>3869800.0</td>\n",
       "      <td>15400.0</td>\n",
       "      <td>2598400.0</td>\n",
       "      <td>59300.0</td>\n",
       "      <td>213500.0</td>\n",
       "      <td>484400.0</td>\n",
       "      <td>760700.0</td>\n",
       "      <td>151100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-13</th>\n",
       "      <td>147.820007</td>\n",
       "      <td>2.16</td>\n",
       "      <td>179.860001</td>\n",
       "      <td>4.910</td>\n",
       "      <td>8.23</td>\n",
       "      <td>1.690000</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.88</td>\n",
       "      <td>120.160004</td>\n",
       "      <td>2.70</td>\n",
       "      <td>...</td>\n",
       "      <td>1127600.0</td>\n",
       "      <td>1078400.0</td>\n",
       "      <td>3379900.0</td>\n",
       "      <td>27200.0</td>\n",
       "      <td>5947400.0</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>197500.0</td>\n",
       "      <td>368300.0</td>\n",
       "      <td>688100.0</td>\n",
       "      <td>89900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-14</th>\n",
       "      <td>145.210007</td>\n",
       "      <td>2.05</td>\n",
       "      <td>181.199997</td>\n",
       "      <td>4.700</td>\n",
       "      <td>8.14</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.79</td>\n",
       "      <td>118.849998</td>\n",
       "      <td>2.61</td>\n",
       "      <td>...</td>\n",
       "      <td>493400.0</td>\n",
       "      <td>1065800.0</td>\n",
       "      <td>5978400.0</td>\n",
       "      <td>23100.0</td>\n",
       "      <td>6432600.0</td>\n",
       "      <td>87700.0</td>\n",
       "      <td>201400.0</td>\n",
       "      <td>389300.0</td>\n",
       "      <td>730700.0</td>\n",
       "      <td>313900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-15</th>\n",
       "      <td>147.479996</td>\n",
       "      <td>2.17</td>\n",
       "      <td>177.880005</td>\n",
       "      <td>4.710</td>\n",
       "      <td>8.63</td>\n",
       "      <td>1.690000</td>\n",
       "      <td>4.18</td>\n",
       "      <td>4.90</td>\n",
       "      <td>115.489998</td>\n",
       "      <td>2.62</td>\n",
       "      <td>...</td>\n",
       "      <td>545200.0</td>\n",
       "      <td>2308000.0</td>\n",
       "      <td>4286700.0</td>\n",
       "      <td>28700.0</td>\n",
       "      <td>3399500.0</td>\n",
       "      <td>93400.0</td>\n",
       "      <td>595100.0</td>\n",
       "      <td>420200.0</td>\n",
       "      <td>1007600.0</td>\n",
       "      <td>235100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.545</td>\n",
       "      <td>7.54</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>4.02</td>\n",
       "      <td>4.62</td>\n",
       "      <td>115.059998</td>\n",
       "      <td>2.57</td>\n",
       "      <td>...</td>\n",
       "      <td>41636.0</td>\n",
       "      <td>66171.0</td>\n",
       "      <td>740701.0</td>\n",
       "      <td>9180.0</td>\n",
       "      <td>789461.0</td>\n",
       "      <td>8610.0</td>\n",
       "      <td>66496.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59455.0</td>\n",
       "      <td>13782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4834 rows × 7302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price        Adj Close                                                    \\\n",
       "Ticker               A  AADI        ABBV   ABCL      ABEO           ABIO   \n",
       "Date                                                                       \n",
       "2005-01-03   14.689768   NaN         NaN    NaN  21500.00  148932.000000   \n",
       "2005-01-04   14.302225   NaN         NaN    NaN  21750.00  148932.000000   \n",
       "2005-01-05   14.296078   NaN         NaN    NaN  20812.50  148327.203125   \n",
       "2005-01-06   13.982349   NaN         NaN    NaN  20812.50  150595.203125   \n",
       "2005-01-07   13.970040   NaN         NaN    NaN  20312.50  148629.593750   \n",
       "...                ...   ...         ...    ...       ...            ...   \n",
       "2024-03-12  147.839996  1.94  180.919998  4.880      8.18       1.660000   \n",
       "2024-03-13  147.820007  2.16  179.860001  4.910      8.23       1.690000   \n",
       "2024-03-14  145.210007  2.05  181.199997  4.700      8.14       1.700000   \n",
       "2024-03-15  147.479996  2.17  177.880005  4.710      8.63       1.690000   \n",
       "2024-03-18         NaN  2.14         NaN  4.545      7.54       1.700000   \n",
       "\n",
       "Price                                     ...     Volume             \\\n",
       "Ticker      ABOS  ABSI         ABT  ABUS  ...       ZLAB       ZNTL   \n",
       "Date                                      ...                         \n",
       "2005-01-03   NaN   NaN   14.846619   NaN  ...        NaN        NaN   \n",
       "2005-01-04   NaN   NaN   14.697101   NaN  ...        NaN        NaN   \n",
       "2005-01-05   NaN   NaN   14.528505   NaN  ...        NaN        NaN   \n",
       "2005-01-06   NaN   NaN   14.856168   NaN  ...        NaN        NaN   \n",
       "2005-01-07   NaN   NaN   15.110657   NaN  ...        NaN        NaN   \n",
       "...          ...   ...         ...   ...  ...        ...        ...   \n",
       "2024-03-12  4.12  4.94  120.760002  2.69  ...   396700.0  1013900.0   \n",
       "2024-03-13  4.35  4.88  120.160004  2.70  ...  1127600.0  1078400.0   \n",
       "2024-03-14  4.09  4.79  118.849998  2.61  ...   493400.0  1065800.0   \n",
       "2024-03-15  4.18  4.90  115.489998  2.62  ...   545200.0  2308000.0   \n",
       "2024-03-18  4.02  4.62  115.059998  2.57  ...    41636.0    66171.0   \n",
       "\n",
       "Price                                                                   \\\n",
       "Ticker            ZOM     ZTEK        ZTS     ZURA      ZVRA      ZVSA   \n",
       "Date                                                                     \n",
       "2005-01-03        NaN      NaN        NaN      NaN       NaN       NaN   \n",
       "2005-01-04        NaN      NaN        NaN      NaN       NaN       NaN   \n",
       "2005-01-05        NaN      NaN        NaN      NaN       NaN       NaN   \n",
       "2005-01-06        NaN      NaN        NaN      NaN       NaN       NaN   \n",
       "2005-01-07        NaN      NaN        NaN      NaN       NaN       NaN   \n",
       "...               ...      ...        ...      ...       ...       ...   \n",
       "2024-03-12  3869800.0  15400.0  2598400.0  59300.0  213500.0  484400.0   \n",
       "2024-03-13  3379900.0  27200.0  5947400.0  65000.0  197500.0  368300.0   \n",
       "2024-03-14  5978400.0  23100.0  6432600.0  87700.0  201400.0  389300.0   \n",
       "2024-03-15  4286700.0  28700.0  3399500.0  93400.0  595100.0  420200.0   \n",
       "2024-03-18   740701.0   9180.0   789461.0   8610.0   66496.0       NaN   \n",
       "\n",
       "Price                          \n",
       "Ticker           ZYME    ZYXI  \n",
       "Date                           \n",
       "2005-01-03        NaN     660  \n",
       "2005-01-04        NaN       0  \n",
       "2005-01-05        NaN    6050  \n",
       "2005-01-06        NaN   89870  \n",
       "2005-01-07        NaN    7480  \n",
       "...               ...     ...  \n",
       "2024-03-12   760700.0  151100  \n",
       "2024-03-13   688100.0   89900  \n",
       "2024-03-14   730700.0  313900  \n",
       "2024-03-15  1007600.0  235100  \n",
       "2024-03-18    59455.0   13782  \n",
       "\n",
       "[4834 rows x 7302 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthcare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67dccd4d-e53e-4f84-8a10-a01f8abe7017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Adj Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>AAOI</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ACIW</th>\n",
       "      <th>ACLS</th>\n",
       "      <th>ACMR</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>ADEA</th>\n",
       "      <th>ADI</th>\n",
       "      <th>ADSK</th>\n",
       "      <th>...</th>\n",
       "      <th>YOU</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZENV</th>\n",
       "      <th>ZEPP</th>\n",
       "      <th>ZETA</th>\n",
       "      <th>ZFOX</th>\n",
       "      <th>ZI</th>\n",
       "      <th>ZM</th>\n",
       "      <th>ZS</th>\n",
       "      <th>ZUO</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.971845</td>\n",
       "      <td>6.510000</td>\n",
       "      <td>31.559999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.297291</td>\n",
       "      <td>30.838949</td>\n",
       "      <td>15.363024</td>\n",
       "      <td>24.284067</td>\n",
       "      <td>37.410706</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>443500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981825</td>\n",
       "      <td>6.183333</td>\n",
       "      <td>29.559999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.843580</td>\n",
       "      <td>30.024111</td>\n",
       "      <td>15.150251</td>\n",
       "      <td>23.623425</td>\n",
       "      <td>34.981960</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>696500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990424</td>\n",
       "      <td>6.093333</td>\n",
       "      <td>27.840000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.770399</td>\n",
       "      <td>29.859142</td>\n",
       "      <td>14.785499</td>\n",
       "      <td>23.730200</td>\n",
       "      <td>35.251820</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1054400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991192</td>\n",
       "      <td>6.170000</td>\n",
       "      <td>27.760000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.602087</td>\n",
       "      <td>29.364239</td>\n",
       "      <td>14.759445</td>\n",
       "      <td>23.690151</td>\n",
       "      <td>35.081905</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>280000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.063362</td>\n",
       "      <td>6.026667</td>\n",
       "      <td>27.160000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.472919</td>\n",
       "      <td>29.384233</td>\n",
       "      <td>14.720365</td>\n",
       "      <td>23.723516</td>\n",
       "      <td>34.282318</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>351600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-12</th>\n",
       "      <td>14.26</td>\n",
       "      <td>173.229996</td>\n",
       "      <td>32.200001</td>\n",
       "      <td>111.889999</td>\n",
       "      <td>29.350000</td>\n",
       "      <td>380.480011</td>\n",
       "      <td>579.140015</td>\n",
       "      <td>11.040000</td>\n",
       "      <td>199.199997</td>\n",
       "      <td>262.779999</td>\n",
       "      <td>...</td>\n",
       "      <td>1036500.0</td>\n",
       "      <td>316100</td>\n",
       "      <td>23300.0</td>\n",
       "      <td>44900.0</td>\n",
       "      <td>1139000.0</td>\n",
       "      <td>305700.0</td>\n",
       "      <td>8992700.0</td>\n",
       "      <td>3160600.0</td>\n",
       "      <td>2305000.0</td>\n",
       "      <td>1853200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-13</th>\n",
       "      <td>13.98</td>\n",
       "      <td>171.130005</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>108.650002</td>\n",
       "      <td>28.750000</td>\n",
       "      <td>378.720001</td>\n",
       "      <td>573.549988</td>\n",
       "      <td>11.020000</td>\n",
       "      <td>198.600006</td>\n",
       "      <td>258.700012</td>\n",
       "      <td>...</td>\n",
       "      <td>1984500.0</td>\n",
       "      <td>286200</td>\n",
       "      <td>6900.0</td>\n",
       "      <td>62700.0</td>\n",
       "      <td>1218600.0</td>\n",
       "      <td>157700.0</td>\n",
       "      <td>4706400.0</td>\n",
       "      <td>2402900.0</td>\n",
       "      <td>1753200.0</td>\n",
       "      <td>963600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-14</th>\n",
       "      <td>12.92</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>31.469999</td>\n",
       "      <td>108.110001</td>\n",
       "      <td>27.469999</td>\n",
       "      <td>378.209991</td>\n",
       "      <td>570.450012</td>\n",
       "      <td>10.870000</td>\n",
       "      <td>194.429993</td>\n",
       "      <td>258.529999</td>\n",
       "      <td>...</td>\n",
       "      <td>2008800.0</td>\n",
       "      <td>375300</td>\n",
       "      <td>24800.0</td>\n",
       "      <td>63400.0</td>\n",
       "      <td>1080200.0</td>\n",
       "      <td>339200.0</td>\n",
       "      <td>5904500.0</td>\n",
       "      <td>1902800.0</td>\n",
       "      <td>1220700.0</td>\n",
       "      <td>1285300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-15</th>\n",
       "      <td>12.70</td>\n",
       "      <td>172.619995</td>\n",
       "      <td>31.830000</td>\n",
       "      <td>107.610001</td>\n",
       "      <td>27.110001</td>\n",
       "      <td>374.600006</td>\n",
       "      <td>492.459991</td>\n",
       "      <td>11.150000</td>\n",
       "      <td>195.199997</td>\n",
       "      <td>254.240005</td>\n",
       "      <td>...</td>\n",
       "      <td>2720600.0</td>\n",
       "      <td>539300</td>\n",
       "      <td>106400.0</td>\n",
       "      <td>49000.0</td>\n",
       "      <td>1937700.0</td>\n",
       "      <td>124100.0</td>\n",
       "      <td>11331700.0</td>\n",
       "      <td>5674700.0</td>\n",
       "      <td>2664700.0</td>\n",
       "      <td>3380500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-18</th>\n",
       "      <td>12.77</td>\n",
       "      <td>177.190002</td>\n",
       "      <td>31.990000</td>\n",
       "      <td>109.910004</td>\n",
       "      <td>28.360001</td>\n",
       "      <td>376.260010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.345000</td>\n",
       "      <td>196.145004</td>\n",
       "      <td>258.820007</td>\n",
       "      <td>...</td>\n",
       "      <td>88996.0</td>\n",
       "      <td>22770</td>\n",
       "      <td>2472.0</td>\n",
       "      <td>12716.0</td>\n",
       "      <td>138761.0</td>\n",
       "      <td>82567.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101985.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4834 rows × 4716 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price      Adj Close                                                \\\n",
       "Ticker          AAOI        AAPL       ACIW        ACLS       ACMR   \n",
       "Date                                                                 \n",
       "2005-01-03       NaN    0.971845   6.510000   31.559999        NaN   \n",
       "2005-01-04       NaN    0.981825   6.183333   29.559999        NaN   \n",
       "2005-01-05       NaN    0.990424   6.093333   27.840000        NaN   \n",
       "2005-01-06       NaN    0.991192   6.170000   27.760000        NaN   \n",
       "2005-01-07       NaN    1.063362   6.026667   27.160000        NaN   \n",
       "...              ...         ...        ...         ...        ...   \n",
       "2024-03-12     14.26  173.229996  32.200001  111.889999  29.350000   \n",
       "2024-03-13     13.98  171.130005  31.730000  108.650002  28.750000   \n",
       "2024-03-14     12.92  173.000000  31.469999  108.110001  27.469999   \n",
       "2024-03-15     12.70  172.619995  31.830000  107.610001  27.110001   \n",
       "2024-03-18     12.77  177.190002  31.990000  109.910004  28.360001   \n",
       "\n",
       "Price                                                                  ...  \\\n",
       "Ticker             ACN        ADBE       ADEA         ADI        ADSK  ...   \n",
       "Date                                                                   ...   \n",
       "2005-01-03   19.297291   30.838949  15.363024   24.284067   37.410706  ...   \n",
       "2005-01-04   18.843580   30.024111  15.150251   23.623425   34.981960  ...   \n",
       "2005-01-05   18.770399   29.859142  14.785499   23.730200   35.251820  ...   \n",
       "2005-01-06   18.602087   29.364239  14.759445   23.690151   35.081905  ...   \n",
       "2005-01-07   19.472919   29.384233  14.720365   23.723516   34.282318  ...   \n",
       "...                ...         ...        ...         ...         ...  ...   \n",
       "2024-03-12  380.480011  579.140015  11.040000  199.199997  262.779999  ...   \n",
       "2024-03-13  378.720001  573.549988  11.020000  198.600006  258.700012  ...   \n",
       "2024-03-14  378.209991  570.450012  10.870000  194.429993  258.529999  ...   \n",
       "2024-03-15  374.600006  492.459991  11.150000  195.199997  254.240005  ...   \n",
       "2024-03-18  376.260010         NaN  11.345000  196.145004  258.820007  ...   \n",
       "\n",
       "Price          Volume                                                   \\\n",
       "Ticker            YOU     ZBRA      ZENV     ZEPP       ZETA      ZFOX   \n",
       "Date                                                                     \n",
       "2005-01-03        NaN   443500       NaN      NaN        NaN       NaN   \n",
       "2005-01-04        NaN   696500       NaN      NaN        NaN       NaN   \n",
       "2005-01-05        NaN  1054400       NaN      NaN        NaN       NaN   \n",
       "2005-01-06        NaN   280000       NaN      NaN        NaN       NaN   \n",
       "2005-01-07        NaN   351600       NaN      NaN        NaN       NaN   \n",
       "...               ...      ...       ...      ...        ...       ...   \n",
       "2024-03-12  1036500.0   316100   23300.0  44900.0  1139000.0  305700.0   \n",
       "2024-03-13  1984500.0   286200    6900.0  62700.0  1218600.0  157700.0   \n",
       "2024-03-14  2008800.0   375300   24800.0  63400.0  1080200.0  339200.0   \n",
       "2024-03-15  2720600.0   539300  106400.0  49000.0  1937700.0  124100.0   \n",
       "2024-03-18    88996.0    22770    2472.0  12716.0   138761.0   82567.0   \n",
       "\n",
       "Price                                                    \n",
       "Ticker              ZI         ZM         ZS        ZUO  \n",
       "Date                                                     \n",
       "2005-01-03         NaN        NaN        NaN        NaN  \n",
       "2005-01-04         NaN        NaN        NaN        NaN  \n",
       "2005-01-05         NaN        NaN        NaN        NaN  \n",
       "2005-01-06         NaN        NaN        NaN        NaN  \n",
       "2005-01-07         NaN        NaN        NaN        NaN  \n",
       "...                ...        ...        ...        ...  \n",
       "2024-03-12   8992700.0  3160600.0  2305000.0  1853200.0  \n",
       "2024-03-13   4706400.0  2402900.0  1753200.0   963600.0  \n",
       "2024-03-14   5904500.0  1902800.0  1220700.0  1285300.0  \n",
       "2024-03-15  11331700.0  5674700.0  2664700.0  3380500.0  \n",
       "2024-03-18         NaN        NaN        NaN   101985.0  \n",
       "\n",
       "[4834 rows x 4716 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "technology_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8133a706-715c-49cc-b61d-7f48f712d37d",
   "metadata": {},
   "source": [
    "## Filter Sector Data:\n",
    "Goruldugu uzere sector data'larimizda bir suru feature bulunmaktadir. Bu proje kapsaminda sadece 'Open' feature'i kullanılacak ve data'lari Ay ay olacak sekilde alacagiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6191aed1-b5e4-4c0c-bc44-a39b5788d1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jedim\\AppData\\Local\\Temp\\ipykernel_22196\\2306332920.py:1: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  finance_data_open = finance_data['Open'].resample(\"M\").last().pct_change() + 1\n"
     ]
    }
   ],
   "source": [
    "finance_data_open = finance_data['Open'].resample(\"M\").last().pct_change() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad6e147a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jedim\\AppData\\Local\\Temp\\ipykernel_22196\\168157782.py:1: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  healthcare_data_open = healthcare_data['Open'].resample(\"M\").last().pct_change() + 1\n"
     ]
    }
   ],
   "source": [
    "healthcare_data_open = healthcare_data['Open'].resample(\"M\").last().pct_change() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db47b9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "technology_data_open = technology_data['Open'].resample(\"M\").last().pct_change() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec0dc2b-8f89-46a1-88d1-3de27fd8fa28",
   "metadata": {},
   "source": [
    "## Organize Downloaded yfinance Sectors Data:\n",
    "Indirdigimiz data'lari duzenleyen yani onlari birer anlasilir dataframe'e ceviren method'umuzu define edelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76f40372-d1bf-4206-bd4b-08799acb04b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame'leri iceren bir list'in icerisindeki tum dataframe'leri birlestirir.\n",
    "def merge_ts(list_dataframes):\n",
    "    return pd.concat(list_dataframes).reset_index()\n",
    "\n",
    "# DataFrame list'i olusturur ve en son bunlari merge eder.\n",
    "def get_ts(data_open):\n",
    "    all = []\n",
    "    for name, data in data_open.items():\n",
    "        f_df = pd.DataFrame(data)\n",
    "        f_df.rename(columns={f_df.columns[0] : 'Open'}, inplace=True)\n",
    "        f_df['Symbols'] = name\n",
    "        all.append(f_df)\n",
    "    return merge_ts(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63448ba8-e907-400a-a2cc-ad96214f7bb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f_df = get_ts(finance_data_open)\n",
    "h_df = get_ts(healthcare_data_open)\n",
    "t_df = get_ts(technology_data_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9722c8ad-03e4-4fca-8d8f-ef801c8bb7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Symbols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AACI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-02-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AACI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-03-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AACI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-04-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AACI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-05-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AACI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230302</th>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>1.004726</td>\n",
       "      <td>ZLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230303</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>1.005644</td>\n",
       "      <td>ZLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230304</th>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>1.005613</td>\n",
       "      <td>ZLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230305</th>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>ZLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230306</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>1.004651</td>\n",
       "      <td>ZLS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230307 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date      Open Symbols\n",
       "0      2005-01-31       NaN    AACI\n",
       "1      2005-02-28       NaN    AACI\n",
       "2      2005-03-31       NaN    AACI\n",
       "3      2005-04-30       NaN    AACI\n",
       "4      2005-05-31       NaN    AACI\n",
       "...           ...       ...     ...\n",
       "230302 2023-11-30  1.004726     ZLS\n",
       "230303 2023-12-31  1.005644     ZLS\n",
       "230304 2024-01-31  1.005613     ZLS\n",
       "230305 2024-02-29  1.000000     ZLS\n",
       "230306 2024-03-31  1.004651     ZLS\n",
       "\n",
       "[230307 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5477982f-70cf-4077-bd4e-41e77a12e633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Symbols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-02-28</td>\n",
       "      <td>1.073382</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-03-31</td>\n",
       "      <td>0.946072</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-04-30</td>\n",
       "      <td>0.933573</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-05-31</td>\n",
       "      <td>1.141827</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281122</th>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>1.027778</td>\n",
       "      <td>ZYXI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281123</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>1.176216</td>\n",
       "      <td>ZYXI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281124</th>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>1.075368</td>\n",
       "      <td>ZYXI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281125</th>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>1.154701</td>\n",
       "      <td>ZYXI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281126</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>0.929682</td>\n",
       "      <td>ZYXI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281127 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date      Open Symbols\n",
       "0      2005-01-31       NaN       A\n",
       "1      2005-02-28  1.073382       A\n",
       "2      2005-03-31  0.946072       A\n",
       "3      2005-04-30  0.933573       A\n",
       "4      2005-05-31  1.141827       A\n",
       "...           ...       ...     ...\n",
       "281122 2023-11-30  1.027778    ZYXI\n",
       "281123 2023-12-31  1.176216    ZYXI\n",
       "281124 2024-01-31  1.075368    ZYXI\n",
       "281125 2024-02-29  1.154701    ZYXI\n",
       "281126 2024-03-31  0.929682    ZYXI\n",
       "\n",
       "[281127 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7f21465-e1e2-4ec0-aea2-4ff8a638b026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Symbols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAOI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-02-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAOI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-03-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAOI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-04-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAOI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-05-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAOI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181561</th>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>1.310867</td>\n",
       "      <td>ZUO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181562</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>1.009444</td>\n",
       "      <td>ZUO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181563</th>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>ZUO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181564</th>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>0.860238</td>\n",
       "      <td>ZUO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181565</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>1.115869</td>\n",
       "      <td>ZUO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181566 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date      Open Symbols\n",
       "0      2005-01-31       NaN    AAOI\n",
       "1      2005-02-28       NaN    AAOI\n",
       "2      2005-03-31       NaN    AAOI\n",
       "3      2005-04-30       NaN    AAOI\n",
       "4      2005-05-31       NaN    AAOI\n",
       "...           ...       ...     ...\n",
       "181561 2023-11-30  1.310867     ZUO\n",
       "181562 2023-12-31  1.009444     ZUO\n",
       "181563 2024-01-31  0.959459     ZUO\n",
       "181564 2024-02-29  0.860238     ZUO\n",
       "181565 2024-03-31  1.115869     ZUO\n",
       "\n",
       "[181566 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df1967b-dfa4-4035-bdaf-eb18f29efe14",
   "metadata": {},
   "source": [
    "## Drop Missing Values:\n",
    "Her bir sector icin elde ettigimiz her bir dataframe'in icersinde bulunan Nan degerleri axis=0 parametresinde kaldiran kodu yazalim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0616e8fa-6ead-4680-98b6-f662800604dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f_df.dropna(inplace=True)\n",
    "h_df.dropna(inplace=True)\n",
    "t_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7032867-e66b-44fa-be8a-b66c8e17daf1",
   "metadata": {},
   "source": [
    "## Feature Extraction:\n",
    "Her bir dataframe'e extracting_features() method'unu uygulayan bir method yaziyoruz. Burada amacimiz feature sayisini arttirarak modelimizin training islemini daha dogru ve anlamlı bir sekilde yapmasini saglamaktir.\n",
    "\n",
    "Parametre olarak ComprehensiveFCParameters() kullanmamizin sebebi ortak parametrelere sahip tüm ozellikleri icerecek sekilde feature extraction yapmasidir. Boylece modelimizin sonuclari daha da iyilesecektir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77372838-1570-4006-9592-ef0e7fcba7c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 20/20 [00:43<00:00,  2.16s/it]\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:46<00:00,  2.33s/it]\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:36<00:00,  1.84s/it]\n"
     ]
    }
   ],
   "source": [
    "import tsfresh\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters\n",
    "\n",
    "def extracting_symbols_features(df):   \n",
    "    return tsfresh.extract_features(df, column_id=\"Symbols\", column_sort=\"Date\", column_value =\"Open\", default_fc_parameters=ComprehensiveFCParameters())\n",
    "\n",
    "last_f_data = extracting_symbols_features(f_df)\n",
    "last_h_data = extracting_symbols_features(h_df)\n",
    "last_t_data = extracting_symbols_features(t_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a622b51b-bad8-4cf1-8e59-4a1fe1752dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open__variance_larger_than_standard_deviation</th>\n",
       "      <th>Open__has_duplicate_max</th>\n",
       "      <th>Open__has_duplicate_min</th>\n",
       "      <th>Open__has_duplicate</th>\n",
       "      <th>Open__sum_values</th>\n",
       "      <th>Open__abs_energy</th>\n",
       "      <th>Open__mean_abs_change</th>\n",
       "      <th>Open__mean_change</th>\n",
       "      <th>Open__mean_second_derivative_central</th>\n",
       "      <th>Open__median</th>\n",
       "      <th>...</th>\n",
       "      <th>Open__fourier_entropy__bins_5</th>\n",
       "      <th>Open__fourier_entropy__bins_10</th>\n",
       "      <th>Open__fourier_entropy__bins_100</th>\n",
       "      <th>Open__permutation_entropy__dimension_3__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_4__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_5__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_6__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_7__tau_1</th>\n",
       "      <th>Open__query_similarity_count__query_None__threshold_0.0</th>\n",
       "      <th>Open__mean_n_absolute_max__number_of_maxima_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AACI</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.140826</td>\n",
       "      <td>28.289593</td>\n",
       "      <td>0.013991</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>1.005337</td>\n",
       "      <td>...</td>\n",
       "      <td>1.210558</td>\n",
       "      <td>1.767009</td>\n",
       "      <td>2.430791</td>\n",
       "      <td>1.702816</td>\n",
       "      <td>2.830713</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.021379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AACT</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.036788</td>\n",
       "      <td>9.073787</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>-0.000626</td>\n",
       "      <td>1.003810</td>\n",
       "      <td>...</td>\n",
       "      <td>1.054920</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.955700</td>\n",
       "      <td>1.329661</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.005120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAMC</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.103148</td>\n",
       "      <td>29.404967</td>\n",
       "      <td>0.338392</td>\n",
       "      <td>0.007472</td>\n",
       "      <td>-0.007883</td>\n",
       "      <td>0.991054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793730</td>\n",
       "      <td>1.263626</td>\n",
       "      <td>2.311423</td>\n",
       "      <td>1.648841</td>\n",
       "      <td>2.309633</td>\n",
       "      <td>2.649159</td>\n",
       "      <td>2.798513</td>\n",
       "      <td>2.813355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.473320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAME</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>231.876674</td>\n",
       "      <td>238.060931</td>\n",
       "      <td>0.132384</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>-0.000157</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889028</td>\n",
       "      <td>1.508808</td>\n",
       "      <td>3.515792</td>\n",
       "      <td>1.779465</td>\n",
       "      <td>3.120384</td>\n",
       "      <td>4.448227</td>\n",
       "      <td>5.171158</td>\n",
       "      <td>5.368324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.460903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AB</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.728347</td>\n",
       "      <td>233.290372</td>\n",
       "      <td>0.088443</td>\n",
       "      <td>-0.000281</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>1.005657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623387</td>\n",
       "      <td>1.241455</td>\n",
       "      <td>3.214773</td>\n",
       "      <td>1.783427</td>\n",
       "      <td>3.111290</td>\n",
       "      <td>4.423633</td>\n",
       "      <td>5.205801</td>\n",
       "      <td>5.405457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.194028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YOTA</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.117440</td>\n",
       "      <td>21.238768</td>\n",
       "      <td>0.012931</td>\n",
       "      <td>-0.000255</td>\n",
       "      <td>-0.000859</td>\n",
       "      <td>1.005102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.759547</td>\n",
       "      <td>1.366711</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.690772</td>\n",
       "      <td>2.399204</td>\n",
       "      <td>2.751667</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.017388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YRD</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.901678</td>\n",
       "      <td>109.190110</td>\n",
       "      <td>0.245288</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>-0.001376</td>\n",
       "      <td>0.983240</td>\n",
       "      <td>...</td>\n",
       "      <td>1.467624</td>\n",
       "      <td>2.121745</td>\n",
       "      <td>3.530657</td>\n",
       "      <td>1.778002</td>\n",
       "      <td>3.050394</td>\n",
       "      <td>4.014869</td>\n",
       "      <td>4.454808</td>\n",
       "      <td>4.517693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.714045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZEO</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.685108</td>\n",
       "      <td>26.599670</td>\n",
       "      <td>0.035502</td>\n",
       "      <td>-0.018161</td>\n",
       "      <td>-0.009536</td>\n",
       "      <td>1.004545</td>\n",
       "      <td>...</td>\n",
       "      <td>1.437701</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.540036</td>\n",
       "      <td>1.735986</td>\n",
       "      <td>2.751916</td>\n",
       "      <td>3.075221</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.023887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZION</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.069471</td>\n",
       "      <td>235.308634</td>\n",
       "      <td>0.109571</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.997205</td>\n",
       "      <td>...</td>\n",
       "      <td>1.034281</td>\n",
       "      <td>1.715718</td>\n",
       "      <td>3.582043</td>\n",
       "      <td>1.765319</td>\n",
       "      <td>3.113452</td>\n",
       "      <td>4.479124</td>\n",
       "      <td>5.222774</td>\n",
       "      <td>5.399268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.371946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZLS</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.112033</td>\n",
       "      <td>30.225033</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>1.004556</td>\n",
       "      <td>...</td>\n",
       "      <td>1.424443</td>\n",
       "      <td>1.808046</td>\n",
       "      <td>2.599302</td>\n",
       "      <td>1.712569</td>\n",
       "      <td>2.743635</td>\n",
       "      <td>3.151459</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.009057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>985 rows × 783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Open__variance_larger_than_standard_deviation  Open__has_duplicate_max  \\\n",
       "AACI                                            0.0                      0.0   \n",
       "AACT                                            0.0                      0.0   \n",
       "AAMC                                            0.0                      0.0   \n",
       "AAME                                            0.0                      0.0   \n",
       "AB                                              0.0                      0.0   \n",
       "...                                             ...                      ...   \n",
       "YOTA                                            0.0                      0.0   \n",
       "YRD                                             0.0                      0.0   \n",
       "ZEO                                             0.0                      0.0   \n",
       "ZION                                            0.0                      0.0   \n",
       "ZLS                                             0.0                      0.0   \n",
       "\n",
       "      Open__has_duplicate_min  Open__has_duplicate  Open__sum_values  \\\n",
       "AACI                      0.0                  1.0         28.140826   \n",
       "AACT                      0.0                  0.0          9.036788   \n",
       "AAMC                      0.0                  0.0         25.103148   \n",
       "AAME                      0.0                  1.0        231.876674   \n",
       "AB                        0.0                  0.0        230.728347   \n",
       "...                       ...                  ...               ...   \n",
       "YOTA                      0.0                  1.0         21.117440   \n",
       "YRD                       0.0                  0.0        100.901678   \n",
       "ZEO                       0.0                  1.0         26.685108   \n",
       "ZION                      0.0                  0.0        231.069471   \n",
       "ZLS                       0.0                  1.0         30.112033   \n",
       "\n",
       "      Open__abs_energy  Open__mean_abs_change  Open__mean_change  \\\n",
       "AACI         28.289593               0.013991           0.000718   \n",
       "AACT          9.073787               0.002569           0.000119   \n",
       "AAMC         29.404967               0.338392           0.007472   \n",
       "AAME        238.060931               0.132384          -0.000171   \n",
       "AB          233.290372               0.088443          -0.000281   \n",
       "...                ...                    ...                ...   \n",
       "YOTA         21.238768               0.012931          -0.000255   \n",
       "YRD         109.190110               0.245288           0.003136   \n",
       "ZEO          26.599670               0.035502          -0.018161   \n",
       "ZION        235.308634               0.109571           0.000093   \n",
       "ZLS          30.225033               0.004384           0.000089   \n",
       "\n",
       "      Open__mean_second_derivative_central  Open__median  ...  \\\n",
       "AACI                              0.000255      1.005337  ...   \n",
       "AACT                             -0.000626      1.003810  ...   \n",
       "AAMC                             -0.007883      0.991054  ...   \n",
       "AAME                             -0.000157      1.000000  ...   \n",
       "AB                                0.000247      1.005657  ...   \n",
       "...                                    ...           ...  ...   \n",
       "YOTA                             -0.000859      1.005102  ...   \n",
       "YRD                              -0.001376      0.983240  ...   \n",
       "ZEO                              -0.009536      1.004545  ...   \n",
       "ZION                              0.000122      0.997205  ...   \n",
       "ZLS                               0.000083      1.004556  ...   \n",
       "\n",
       "      Open__fourier_entropy__bins_5  Open__fourier_entropy__bins_10  \\\n",
       "AACI                       1.210558                        1.767009   \n",
       "AACT                       1.054920                        1.609438   \n",
       "AAMC                       0.793730                        1.263626   \n",
       "AAME                       0.889028                        1.508808   \n",
       "AB                         0.623387                        1.241455   \n",
       "...                             ...                             ...   \n",
       "YOTA                       0.759547                        1.366711   \n",
       "YRD                        1.467624                        2.121745   \n",
       "ZEO                        1.437701                        1.945910   \n",
       "ZION                       1.034281                        1.715718   \n",
       "ZLS                        1.424443                        1.808046   \n",
       "\n",
       "      Open__fourier_entropy__bins_100  \\\n",
       "AACI                         2.430791   \n",
       "AACT                         1.609438   \n",
       "AAMC                         2.311423   \n",
       "AAME                         3.515792   \n",
       "AB                           3.214773   \n",
       "...                               ...   \n",
       "YOTA                         2.397895   \n",
       "YRD                          3.530657   \n",
       "ZEO                          2.540036   \n",
       "ZION                         3.582043   \n",
       "ZLS                          2.599302   \n",
       "\n",
       "      Open__permutation_entropy__dimension_3__tau_1  \\\n",
       "AACI                                       1.702816   \n",
       "AACT                                       0.955700   \n",
       "AAMC                                       1.648841   \n",
       "AAME                                       1.779465   \n",
       "AB                                         1.783427   \n",
       "...                                             ...   \n",
       "YOTA                                       1.690772   \n",
       "YRD                                        1.778002   \n",
       "ZEO                                        1.735986   \n",
       "ZION                                       1.765319   \n",
       "ZLS                                        1.712569   \n",
       "\n",
       "      Open__permutation_entropy__dimension_4__tau_1  \\\n",
       "AACI                                       2.830713   \n",
       "AACT                                       1.329661   \n",
       "AAMC                                       2.309633   \n",
       "AAME                                       3.120384   \n",
       "AB                                         3.111290   \n",
       "...                                             ...   \n",
       "YOTA                                       2.399204   \n",
       "YRD                                        3.050394   \n",
       "ZEO                                        2.751916   \n",
       "ZION                                       3.113452   \n",
       "ZLS                                        2.743635   \n",
       "\n",
       "      Open__permutation_entropy__dimension_5__tau_1  \\\n",
       "AACI                                       3.178054   \n",
       "AACT                                       1.609438   \n",
       "AAMC                                       2.649159   \n",
       "AAME                                       4.448227   \n",
       "AB                                         4.423633   \n",
       "...                                             ...   \n",
       "YOTA                                       2.751667   \n",
       "YRD                                        4.014869   \n",
       "ZEO                                        3.075221   \n",
       "ZION                                       4.479124   \n",
       "ZLS                                        3.151459   \n",
       "\n",
       "      Open__permutation_entropy__dimension_6__tau_1  \\\n",
       "AACI                                       3.135494   \n",
       "AACT                                       1.386294   \n",
       "AAMC                                       2.798513   \n",
       "AAME                                       5.171158   \n",
       "AB                                         5.205801   \n",
       "...                                             ...   \n",
       "YOTA                                       2.772589   \n",
       "YRD                                        4.454808   \n",
       "ZEO                                        3.091042   \n",
       "ZION                                       5.222774   \n",
       "ZLS                                        3.218876   \n",
       "\n",
       "      Open__permutation_entropy__dimension_7__tau_1  \\\n",
       "AACI                                       3.091042   \n",
       "AACT                                       1.098612   \n",
       "AAMC                                       2.813355   \n",
       "AAME                                       5.368324   \n",
       "AB                                         5.405457   \n",
       "...                                             ...   \n",
       "YOTA                                       2.708050   \n",
       "YRD                                        4.517693   \n",
       "ZEO                                        3.044522   \n",
       "ZION                                       5.399268   \n",
       "ZLS                                        3.178054   \n",
       "\n",
       "      Open__query_similarity_count__query_None__threshold_0.0  \\\n",
       "AACI                                                NaN         \n",
       "AACT                                                NaN         \n",
       "AAMC                                                NaN         \n",
       "AAME                                                NaN         \n",
       "AB                                                  NaN         \n",
       "...                                                 ...         \n",
       "YOTA                                                NaN         \n",
       "YRD                                                 NaN         \n",
       "ZEO                                                 NaN         \n",
       "ZION                                                NaN         \n",
       "ZLS                                                 NaN         \n",
       "\n",
       "      Open__mean_n_absolute_max__number_of_maxima_7  \n",
       "AACI                                       1.021379  \n",
       "AACT                                       1.005120  \n",
       "AAMC                                       1.473320  \n",
       "AAME                                       1.460903  \n",
       "AB                                         1.194028  \n",
       "...                                             ...  \n",
       "YOTA                                       1.017388  \n",
       "YRD                                        1.714045  \n",
       "ZEO                                        1.023887  \n",
       "ZION                                       1.371946  \n",
       "ZLS                                        1.009057  \n",
       "\n",
       "[985 rows x 783 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_f_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d9a2265-df68-4b16-9069-33646cba2ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open__variance_larger_than_standard_deviation</th>\n",
       "      <th>Open__has_duplicate_max</th>\n",
       "      <th>Open__has_duplicate_min</th>\n",
       "      <th>Open__has_duplicate</th>\n",
       "      <th>Open__sum_values</th>\n",
       "      <th>Open__abs_energy</th>\n",
       "      <th>Open__mean_abs_change</th>\n",
       "      <th>Open__mean_change</th>\n",
       "      <th>Open__mean_second_derivative_central</th>\n",
       "      <th>Open__median</th>\n",
       "      <th>...</th>\n",
       "      <th>Open__fourier_entropy__bins_5</th>\n",
       "      <th>Open__fourier_entropy__bins_10</th>\n",
       "      <th>Open__fourier_entropy__bins_100</th>\n",
       "      <th>Open__permutation_entropy__dimension_3__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_4__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_5__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_6__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_7__tau_1</th>\n",
       "      <th>Open__query_similarity_count__query_None__threshold_0.0</th>\n",
       "      <th>Open__mean_n_absolute_max__number_of_maxima_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.064922</td>\n",
       "      <td>237.851890</td>\n",
       "      <td>0.092876</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>1.014532</td>\n",
       "      <td>...</td>\n",
       "      <td>1.014479</td>\n",
       "      <td>1.677535</td>\n",
       "      <td>3.528019</td>\n",
       "      <td>1.787516</td>\n",
       "      <td>3.104159</td>\n",
       "      <td>4.443318</td>\n",
       "      <td>5.167710</td>\n",
       "      <td>5.349758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.228913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AADI</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.013583</td>\n",
       "      <td>75.989190</td>\n",
       "      <td>0.284100</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.988156</td>\n",
       "      <td>...</td>\n",
       "      <td>1.290699</td>\n",
       "      <td>1.937719</td>\n",
       "      <td>3.297037</td>\n",
       "      <td>1.773966</td>\n",
       "      <td>3.040307</td>\n",
       "      <td>3.993012</td>\n",
       "      <td>4.199121</td>\n",
       "      <td>4.204693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.489924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.934327</td>\n",
       "      <td>138.582182</td>\n",
       "      <td>0.080564</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>-0.000626</td>\n",
       "      <td>1.016032</td>\n",
       "      <td>...</td>\n",
       "      <td>1.048282</td>\n",
       "      <td>1.673284</td>\n",
       "      <td>3.492883</td>\n",
       "      <td>1.751884</td>\n",
       "      <td>3.056965</td>\n",
       "      <td>4.198258</td>\n",
       "      <td>4.694559</td>\n",
       "      <td>4.830369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.170471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABCL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.466273</td>\n",
       "      <td>37.082147</td>\n",
       "      <td>0.191168</td>\n",
       "      <td>-0.009005</td>\n",
       "      <td>0.005962</td>\n",
       "      <td>0.953545</td>\n",
       "      <td>...</td>\n",
       "      <td>1.487798</td>\n",
       "      <td>1.825199</td>\n",
       "      <td>2.857103</td>\n",
       "      <td>1.767102</td>\n",
       "      <td>2.894715</td>\n",
       "      <td>3.436523</td>\n",
       "      <td>3.526361</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.210670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABEO</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>230.885374</td>\n",
       "      <td>252.831806</td>\n",
       "      <td>0.288095</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>-0.000763</td>\n",
       "      <td>0.961419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885954</td>\n",
       "      <td>1.541387</td>\n",
       "      <td>3.565636</td>\n",
       "      <td>1.785235</td>\n",
       "      <td>3.132960</td>\n",
       "      <td>4.451075</td>\n",
       "      <td>5.208126</td>\n",
       "      <td>5.374513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.102701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZURA</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.000966</td>\n",
       "      <td>10.989604</td>\n",
       "      <td>0.336821</td>\n",
       "      <td>0.026584</td>\n",
       "      <td>-0.024478</td>\n",
       "      <td>0.891074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796312</td>\n",
       "      <td>1.277034</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.695743</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.077843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZVRA</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107.187700</td>\n",
       "      <td>114.988455</td>\n",
       "      <td>0.286744</td>\n",
       "      <td>-0.001431</td>\n",
       "      <td>-0.004334</td>\n",
       "      <td>0.966000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.452413</td>\n",
       "      <td>2.124329</td>\n",
       "      <td>3.655247</td>\n",
       "      <td>1.782094</td>\n",
       "      <td>3.095687</td>\n",
       "      <td>4.245931</td>\n",
       "      <td>4.570608</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.688972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZVSA</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.808165</td>\n",
       "      <td>21.609863</td>\n",
       "      <td>0.309515</td>\n",
       "      <td>-0.009856</td>\n",
       "      <td>-0.020612</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>...</td>\n",
       "      <td>1.377820</td>\n",
       "      <td>1.839297</td>\n",
       "      <td>2.245035</td>\n",
       "      <td>1.749978</td>\n",
       "      <td>2.523922</td>\n",
       "      <td>2.912494</td>\n",
       "      <td>2.926418</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.161472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZYME</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.115741</td>\n",
       "      <td>88.020538</td>\n",
       "      <td>0.195369</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>-0.000310</td>\n",
       "      <td>1.010974</td>\n",
       "      <td>...</td>\n",
       "      <td>1.295625</td>\n",
       "      <td>1.943617</td>\n",
       "      <td>3.440607</td>\n",
       "      <td>1.778137</td>\n",
       "      <td>3.068956</td>\n",
       "      <td>4.057885</td>\n",
       "      <td>4.285617</td>\n",
       "      <td>4.343805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.395983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZYXI</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.718067</td>\n",
       "      <td>268.583806</td>\n",
       "      <td>0.259600</td>\n",
       "      <td>-0.000307</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881686</td>\n",
       "      <td>1.544747</td>\n",
       "      <td>3.453418</td>\n",
       "      <td>1.787949</td>\n",
       "      <td>3.151418</td>\n",
       "      <td>4.504166</td>\n",
       "      <td>5.194293</td>\n",
       "      <td>5.349758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.984929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1216 rows × 783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Open__variance_larger_than_standard_deviation  Open__has_duplicate_max  \\\n",
       "A                                               0.0                      0.0   \n",
       "AADI                                            0.0                      0.0   \n",
       "ABBV                                            0.0                      0.0   \n",
       "ABCL                                            0.0                      0.0   \n",
       "ABEO                                            0.0                      0.0   \n",
       "...                                             ...                      ...   \n",
       "ZURA                                            0.0                      0.0   \n",
       "ZVRA                                            0.0                      0.0   \n",
       "ZVSA                                            0.0                      0.0   \n",
       "ZYME                                            0.0                      0.0   \n",
       "ZYXI                                            0.0                      0.0   \n",
       "\n",
       "      Open__has_duplicate_min  Open__has_duplicate  Open__sum_values  \\\n",
       "A                         0.0                  0.0        233.064922   \n",
       "AADI                      0.0                  0.0         72.013583   \n",
       "ABBV                      0.0                  0.0        135.934327   \n",
       "ABCL                      0.0                  0.0         37.466273   \n",
       "ABEO                      0.0                  1.0        230.885374   \n",
       "...                       ...                  ...               ...   \n",
       "ZURA                      0.0                  0.0         11.000966   \n",
       "ZVRA                      0.0                  1.0        107.187700   \n",
       "ZVSA                      0.0                  0.0         21.808165   \n",
       "ZYME                      0.0                  0.0         84.115741   \n",
       "ZYXI                      0.0                  1.0        240.718067   \n",
       "\n",
       "      Open__abs_energy  Open__mean_abs_change  Open__mean_change  \\\n",
       "A           237.851890               0.092876          -0.000115   \n",
       "AADI         75.989190               0.284100           0.000463   \n",
       "ABBV        138.582182               0.080564           0.000120   \n",
       "ABCL         37.082147               0.191168          -0.009005   \n",
       "ABEO        252.831806               0.288095           0.000709   \n",
       "...                ...                    ...                ...   \n",
       "ZURA         10.989604               0.336821           0.026584   \n",
       "ZVRA        114.988455               0.286744          -0.001431   \n",
       "ZVSA         21.609863               0.309515          -0.009856   \n",
       "ZYME         88.020538               0.195369          -0.000205   \n",
       "ZYXI        268.583806               0.259600          -0.000307   \n",
       "\n",
       "      Open__mean_second_derivative_central  Open__median  ...  \\\n",
       "A                                 0.000335      1.014532  ...   \n",
       "AADI                              0.000780      0.988156  ...   \n",
       "ABBV                             -0.000626      1.016032  ...   \n",
       "ABCL                              0.005962      0.953545  ...   \n",
       "ABEO                             -0.000763      0.961419  ...   \n",
       "...                                    ...           ...  ...   \n",
       "ZURA                             -0.024478      0.891074  ...   \n",
       "ZVRA                             -0.004334      0.966000  ...   \n",
       "ZVSA                             -0.020612      0.990099  ...   \n",
       "ZYME                             -0.000310      1.010974  ...   \n",
       "ZYXI                             -0.000040      1.000000  ...   \n",
       "\n",
       "      Open__fourier_entropy__bins_5  Open__fourier_entropy__bins_10  \\\n",
       "A                          1.014479                        1.677535   \n",
       "AADI                       1.290699                        1.937719   \n",
       "ABBV                       1.048282                        1.673284   \n",
       "ABCL                       1.487798                        1.825199   \n",
       "ABEO                       0.885954                        1.541387   \n",
       "...                             ...                             ...   \n",
       "ZURA                       0.796312                        1.277034   \n",
       "ZVRA                       1.452413                        2.124329   \n",
       "ZVSA                       1.377820                        1.839297   \n",
       "ZYME                       1.295625                        1.943617   \n",
       "ZYXI                       0.881686                        1.544747   \n",
       "\n",
       "      Open__fourier_entropy__bins_100  \\\n",
       "A                            3.528019   \n",
       "AADI                         3.297037   \n",
       "ABBV                         3.492883   \n",
       "ABCL                         2.857103   \n",
       "ABEO                         3.565636   \n",
       "...                               ...   \n",
       "ZURA                         1.945910   \n",
       "ZVRA                         3.655247   \n",
       "ZVSA                         2.245035   \n",
       "ZYME                         3.440607   \n",
       "ZYXI                         3.453418   \n",
       "\n",
       "      Open__permutation_entropy__dimension_3__tau_1  \\\n",
       "A                                          1.787516   \n",
       "AADI                                       1.773966   \n",
       "ABBV                                       1.751884   \n",
       "ABCL                                       1.767102   \n",
       "ABEO                                       1.785235   \n",
       "...                                             ...   \n",
       "ZURA                                       1.695743   \n",
       "ZVRA                                       1.782094   \n",
       "ZVSA                                       1.749978   \n",
       "ZYME                                       1.778137   \n",
       "ZYXI                                       1.787949   \n",
       "\n",
       "      Open__permutation_entropy__dimension_4__tau_1  \\\n",
       "A                                          3.104159   \n",
       "AADI                                       3.040307   \n",
       "ABBV                                       3.056965   \n",
       "ABCL                                       2.894715   \n",
       "ABEO                                       3.132960   \n",
       "...                                             ...   \n",
       "ZURA                                       2.197225   \n",
       "ZVRA                                       3.095687   \n",
       "ZVSA                                       2.523922   \n",
       "ZYME                                       3.068956   \n",
       "ZYXI                                       3.151418   \n",
       "\n",
       "      Open__permutation_entropy__dimension_5__tau_1  \\\n",
       "A                                          4.443318   \n",
       "AADI                                       3.993012   \n",
       "ABBV                                       4.198258   \n",
       "ABCL                                       3.436523   \n",
       "ABEO                                       4.451075   \n",
       "...                                             ...   \n",
       "ZURA                                       2.079442   \n",
       "ZVRA                                       4.245931   \n",
       "ZVSA                                       2.912494   \n",
       "ZYME                                       4.057885   \n",
       "ZYXI                                       4.504166   \n",
       "\n",
       "      Open__permutation_entropy__dimension_6__tau_1  \\\n",
       "A                                          5.167710   \n",
       "AADI                                       4.199121   \n",
       "ABBV                                       4.694559   \n",
       "ABCL                                       3.526361   \n",
       "ABEO                                       5.208126   \n",
       "...                                             ...   \n",
       "ZURA                                       1.945910   \n",
       "ZVRA                                       4.570608   \n",
       "ZVSA                                       2.926418   \n",
       "ZYME                                       4.285617   \n",
       "ZYXI                                       5.194293   \n",
       "\n",
       "      Open__permutation_entropy__dimension_7__tau_1  \\\n",
       "A                                          5.349758   \n",
       "AADI                                       4.204693   \n",
       "ABBV                                       4.830369   \n",
       "ABCL                                       3.496508   \n",
       "ABEO                                       5.374513   \n",
       "...                                             ...   \n",
       "ZURA                                       1.791759   \n",
       "ZVRA                                       4.615121   \n",
       "ZVSA                                       2.944439   \n",
       "ZYME                                       4.343805   \n",
       "ZYXI                                       5.349758   \n",
       "\n",
       "      Open__query_similarity_count__query_None__threshold_0.0  \\\n",
       "A                                                   NaN         \n",
       "AADI                                                NaN         \n",
       "ABBV                                                NaN         \n",
       "ABCL                                                NaN         \n",
       "ABEO                                                NaN         \n",
       "...                                                 ...         \n",
       "ZURA                                                NaN         \n",
       "ZVRA                                                NaN         \n",
       "ZVSA                                                NaN         \n",
       "ZYME                                                NaN         \n",
       "ZYXI                                                NaN         \n",
       "\n",
       "      Open__mean_n_absolute_max__number_of_maxima_7  \n",
       "A                                          1.228913  \n",
       "AADI                                       1.489924  \n",
       "ABBV                                       1.170471  \n",
       "ABCL                                       1.210670  \n",
       "ABEO                                       2.102701  \n",
       "...                                             ...  \n",
       "ZURA                                       1.077843  \n",
       "ZVRA                                       1.688972  \n",
       "ZVSA                                       1.161472  \n",
       "ZYME                                       1.395983  \n",
       "ZYXI                                       1.984929  \n",
       "\n",
       "[1216 rows x 783 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_h_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42d926b6-2e03-4408-af60-a07300b41f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open__variance_larger_than_standard_deviation</th>\n",
       "      <th>Open__has_duplicate_max</th>\n",
       "      <th>Open__has_duplicate_min</th>\n",
       "      <th>Open__has_duplicate</th>\n",
       "      <th>Open__sum_values</th>\n",
       "      <th>Open__abs_energy</th>\n",
       "      <th>Open__mean_abs_change</th>\n",
       "      <th>Open__mean_change</th>\n",
       "      <th>Open__mean_second_derivative_central</th>\n",
       "      <th>Open__median</th>\n",
       "      <th>...</th>\n",
       "      <th>Open__fourier_entropy__bins_5</th>\n",
       "      <th>Open__fourier_entropy__bins_10</th>\n",
       "      <th>Open__fourier_entropy__bins_100</th>\n",
       "      <th>Open__permutation_entropy__dimension_3__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_4__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_5__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_6__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_7__tau_1</th>\n",
       "      <th>Open__query_similarity_count__query_None__threshold_0.0</th>\n",
       "      <th>Open__mean_n_absolute_max__number_of_maxima_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAOI</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.326854</td>\n",
       "      <td>145.233609</td>\n",
       "      <td>0.297438</td>\n",
       "      <td>-0.003369</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.969256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.306471</td>\n",
       "      <td>1.919776</td>\n",
       "      <td>3.701139</td>\n",
       "      <td>1.789172</td>\n",
       "      <td>3.079022</td>\n",
       "      <td>4.250016</td>\n",
       "      <td>4.681221</td>\n",
       "      <td>4.775939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.872806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>235.977073</td>\n",
       "      <td>244.146471</td>\n",
       "      <td>0.102522</td>\n",
       "      <td>-0.001002</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.027885</td>\n",
       "      <td>...</td>\n",
       "      <td>1.281364</td>\n",
       "      <td>1.884422</td>\n",
       "      <td>3.786981</td>\n",
       "      <td>1.790489</td>\n",
       "      <td>3.159653</td>\n",
       "      <td>4.531096</td>\n",
       "      <td>5.235097</td>\n",
       "      <td>5.405457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.218478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACIW</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>232.527066</td>\n",
       "      <td>237.108832</td>\n",
       "      <td>0.101733</td>\n",
       "      <td>-0.000425</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>1.008722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692241</td>\n",
       "      <td>1.278668</td>\n",
       "      <td>3.255464</td>\n",
       "      <td>1.789476</td>\n",
       "      <td>3.146219</td>\n",
       "      <td>4.513990</td>\n",
       "      <td>5.187317</td>\n",
       "      <td>5.386891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.257802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACLS</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>235.125048</td>\n",
       "      <td>246.997251</td>\n",
       "      <td>0.177726</td>\n",
       "      <td>-0.000926</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>1.013420</td>\n",
       "      <td>...</td>\n",
       "      <td>1.188196</td>\n",
       "      <td>1.826451</td>\n",
       "      <td>3.722466</td>\n",
       "      <td>1.788837</td>\n",
       "      <td>3.152728</td>\n",
       "      <td>4.506759</td>\n",
       "      <td>5.209636</td>\n",
       "      <td>5.393080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.451027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACMR</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.824762</td>\n",
       "      <td>91.248884</td>\n",
       "      <td>0.310172</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>-0.007964</td>\n",
       "      <td>1.008573</td>\n",
       "      <td>...</td>\n",
       "      <td>1.354448</td>\n",
       "      <td>1.900262</td>\n",
       "      <td>3.281268</td>\n",
       "      <td>1.785733</td>\n",
       "      <td>3.083930</td>\n",
       "      <td>3.992574</td>\n",
       "      <td>4.223629</td>\n",
       "      <td>4.248495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.647787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZFOX</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.387535</td>\n",
       "      <td>35.706599</td>\n",
       "      <td>0.125435</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>-0.002871</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>...</td>\n",
       "      <td>1.370515</td>\n",
       "      <td>1.817382</td>\n",
       "      <td>2.622996</td>\n",
       "      <td>1.768230</td>\n",
       "      <td>2.837155</td>\n",
       "      <td>3.485587</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.124443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZI</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.358493</td>\n",
       "      <td>44.703179</td>\n",
       "      <td>0.190596</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>-0.002700</td>\n",
       "      <td>0.976888</td>\n",
       "      <td>...</td>\n",
       "      <td>1.363188</td>\n",
       "      <td>1.774477</td>\n",
       "      <td>3.014947</td>\n",
       "      <td>1.758812</td>\n",
       "      <td>2.936766</td>\n",
       "      <td>3.578324</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>3.663562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.213355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZM</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.749947</td>\n",
       "      <td>62.246140</td>\n",
       "      <td>0.169367</td>\n",
       "      <td>-0.003417</td>\n",
       "      <td>-0.001022</td>\n",
       "      <td>0.999566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903384</td>\n",
       "      <td>1.379292</td>\n",
       "      <td>2.748145</td>\n",
       "      <td>1.775446</td>\n",
       "      <td>2.939232</td>\n",
       "      <td>3.558556</td>\n",
       "      <td>3.911968</td>\n",
       "      <td>3.944135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.350458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZS</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.870751</td>\n",
       "      <td>79.664053</td>\n",
       "      <td>0.166460</td>\n",
       "      <td>-0.002925</td>\n",
       "      <td>-0.000303</td>\n",
       "      <td>1.045431</td>\n",
       "      <td>...</td>\n",
       "      <td>1.380208</td>\n",
       "      <td>1.962726</td>\n",
       "      <td>3.320362</td>\n",
       "      <td>1.771000</td>\n",
       "      <td>3.077269</td>\n",
       "      <td>3.939091</td>\n",
       "      <td>4.163311</td>\n",
       "      <td>4.189655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.345846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZUO</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.049666</td>\n",
       "      <td>72.744778</td>\n",
       "      <td>0.182902</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.970573</td>\n",
       "      <td>...</td>\n",
       "      <td>1.290039</td>\n",
       "      <td>1.919223</td>\n",
       "      <td>3.169368</td>\n",
       "      <td>1.784305</td>\n",
       "      <td>3.008863</td>\n",
       "      <td>3.927900</td>\n",
       "      <td>4.168650</td>\n",
       "      <td>4.174387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.275732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>784 rows × 783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Open__variance_larger_than_standard_deviation  Open__has_duplicate_max  \\\n",
       "AAOI                                            0.0                      0.0   \n",
       "AAPL                                            0.0                      0.0   \n",
       "ACIW                                            0.0                      0.0   \n",
       "ACLS                                            0.0                      0.0   \n",
       "ACMR                                            0.0                      0.0   \n",
       "...                                             ...                      ...   \n",
       "ZFOX                                            0.0                      0.0   \n",
       "ZI                                              0.0                      0.0   \n",
       "ZM                                              0.0                      0.0   \n",
       "ZS                                              0.0                      0.0   \n",
       "ZUO                                             0.0                      0.0   \n",
       "\n",
       "      Open__has_duplicate_min  Open__has_duplicate  Open__sum_values  \\\n",
       "AAOI                      0.0                  0.0        130.326854   \n",
       "AAPL                      0.0                  0.0        235.977073   \n",
       "ACIW                      0.0                  1.0        232.527066   \n",
       "ACLS                      0.0                  1.0        235.125048   \n",
       "ACMR                      0.0                  0.0         80.824762   \n",
       "...                       ...                  ...               ...   \n",
       "ZFOX                      0.0                  0.0         36.387535   \n",
       "ZI                        0.0                  0.0         44.358493   \n",
       "ZM                        0.0                  0.0         59.749947   \n",
       "ZS                        0.0                  0.0         74.870751   \n",
       "ZUO                       0.0                  0.0         71.049666   \n",
       "\n",
       "      Open__abs_energy  Open__mean_abs_change  Open__mean_change  \\\n",
       "AAOI        145.233609               0.297438          -0.003369   \n",
       "AAPL        244.146471               0.102522          -0.001002   \n",
       "ACIW        237.108832               0.101733          -0.000425   \n",
       "ACLS        246.997251               0.177726          -0.000926   \n",
       "ACMR         91.248884               0.310172           0.001472   \n",
       "...                ...                    ...                ...   \n",
       "ZFOX         35.706599               0.125435           0.000137   \n",
       "ZI           44.703179               0.190596           0.003235   \n",
       "ZM           62.246140               0.169367          -0.003417   \n",
       "ZS           79.664053               0.166460          -0.002925   \n",
       "ZUO          72.744778               0.182902          -0.000018   \n",
       "\n",
       "      Open__mean_second_derivative_central  Open__median  ...  \\\n",
       "AAOI                              0.000677      0.969256  ...   \n",
       "AAPL                              0.000543      1.027885  ...   \n",
       "ACIW                              0.000191      1.008722  ...   \n",
       "ACLS                              0.001029      1.013420  ...   \n",
       "ACMR                             -0.007964      1.008573  ...   \n",
       "...                                    ...           ...  ...   \n",
       "ZFOX                             -0.002871      0.999952  ...   \n",
       "ZI                               -0.002700      0.976888  ...   \n",
       "ZM                               -0.001022      0.999566  ...   \n",
       "ZS                               -0.000303      1.045431  ...   \n",
       "ZUO                               0.000428      0.970573  ...   \n",
       "\n",
       "      Open__fourier_entropy__bins_5  Open__fourier_entropy__bins_10  \\\n",
       "AAOI                       1.306471                        1.919776   \n",
       "AAPL                       1.281364                        1.884422   \n",
       "ACIW                       0.692241                        1.278668   \n",
       "ACLS                       1.188196                        1.826451   \n",
       "ACMR                       1.354448                        1.900262   \n",
       "...                             ...                             ...   \n",
       "ZFOX                       1.370515                        1.817382   \n",
       "ZI                         1.363188                        1.774477   \n",
       "ZM                         0.903384                        1.379292   \n",
       "ZS                         1.380208                        1.962726   \n",
       "ZUO                        1.290039                        1.919223   \n",
       "\n",
       "      Open__fourier_entropy__bins_100  \\\n",
       "AAOI                         3.701139   \n",
       "AAPL                         3.786981   \n",
       "ACIW                         3.255464   \n",
       "ACLS                         3.722466   \n",
       "ACMR                         3.281268   \n",
       "...                               ...   \n",
       "ZFOX                         2.622996   \n",
       "ZI                           3.014947   \n",
       "ZM                           2.748145   \n",
       "ZS                           3.320362   \n",
       "ZUO                          3.169368   \n",
       "\n",
       "      Open__permutation_entropy__dimension_3__tau_1  \\\n",
       "AAOI                                       1.789172   \n",
       "AAPL                                       1.790489   \n",
       "ACIW                                       1.789476   \n",
       "ACLS                                       1.788837   \n",
       "ACMR                                       1.785733   \n",
       "...                                             ...   \n",
       "ZFOX                                       1.768230   \n",
       "ZI                                         1.758812   \n",
       "ZM                                         1.775446   \n",
       "ZS                                         1.771000   \n",
       "ZUO                                        1.784305   \n",
       "\n",
       "      Open__permutation_entropy__dimension_4__tau_1  \\\n",
       "AAOI                                       3.079022   \n",
       "AAPL                                       3.159653   \n",
       "ACIW                                       3.146219   \n",
       "ACLS                                       3.152728   \n",
       "ACMR                                       3.083930   \n",
       "...                                             ...   \n",
       "ZFOX                                       2.837155   \n",
       "ZI                                         2.936766   \n",
       "ZM                                         2.939232   \n",
       "ZS                                         3.077269   \n",
       "ZUO                                        3.008863   \n",
       "\n",
       "      Open__permutation_entropy__dimension_5__tau_1  \\\n",
       "AAOI                                       4.250016   \n",
       "AAPL                                       4.531096   \n",
       "ACIW                                       4.513990   \n",
       "ACLS                                       4.506759   \n",
       "ACMR                                       3.992574   \n",
       "...                                             ...   \n",
       "ZFOX                                       3.485587   \n",
       "ZI                                         3.578324   \n",
       "ZM                                         3.558556   \n",
       "ZS                                         3.939091   \n",
       "ZUO                                        3.927900   \n",
       "\n",
       "      Open__permutation_entropy__dimension_6__tau_1  \\\n",
       "AAOI                                       4.681221   \n",
       "AAPL                                       5.235097   \n",
       "ACIW                                       5.187317   \n",
       "ACLS                                       5.209636   \n",
       "ACMR                                       4.223629   \n",
       "...                                             ...   \n",
       "ZFOX                                       3.496508   \n",
       "ZI                                         3.688879   \n",
       "ZM                                         3.911968   \n",
       "ZS                                         4.163311   \n",
       "ZUO                                        4.168650   \n",
       "\n",
       "      Open__permutation_entropy__dimension_7__tau_1  \\\n",
       "AAOI                                       4.775939   \n",
       "AAPL                                       5.405457   \n",
       "ACIW                                       5.386891   \n",
       "ACLS                                       5.393080   \n",
       "ACMR                                       4.248495   \n",
       "...                                             ...   \n",
       "ZFOX                                       3.465736   \n",
       "ZI                                         3.663562   \n",
       "ZM                                         3.944135   \n",
       "ZS                                         4.189655   \n",
       "ZUO                                        4.174387   \n",
       "\n",
       "      Open__query_similarity_count__query_None__threshold_0.0  \\\n",
       "AAOI                                                NaN         \n",
       "AAPL                                                NaN         \n",
       "ACIW                                                NaN         \n",
       "ACLS                                                NaN         \n",
       "ACMR                                                NaN         \n",
       "...                                                 ...         \n",
       "ZFOX                                                NaN         \n",
       "ZI                                                  NaN         \n",
       "ZM                                                  NaN         \n",
       "ZS                                                  NaN         \n",
       "ZUO                                                 NaN         \n",
       "\n",
       "      Open__mean_n_absolute_max__number_of_maxima_7  \n",
       "AAOI                                       1.872806  \n",
       "AAPL                                       1.218478  \n",
       "ACIW                                       1.257802  \n",
       "ACLS                                       1.451027  \n",
       "ACMR                                       1.647787  \n",
       "...                                             ...  \n",
       "ZFOX                                       1.124443  \n",
       "ZI                                         1.213355  \n",
       "ZM                                         1.350458  \n",
       "ZS                                         1.345846  \n",
       "ZUO                                        1.275732  \n",
       "\n",
       "[784 rows x 783 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_t_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9439a58a-6ac9-4ee9-968f-0eaac1beff83",
   "metadata": {},
   "source": [
    "## Prepare Target Column:\n",
    "Feature extraction sonrasinda index'lerimiz symbol'ler olacaktir. Bu yuden target column'unu ayarlamak icin reset_index() method'unu kullaniriz. Bu method sayesinde symbol'lerimizin artik bir column olur. \n",
    "\n",
    "Bu islemden sonra her bir dataframe icin index (Target) column'ini model training icin ayarlayabiliriz.\n",
    "\n",
    "https://saturncloud.io/blog/how-to-reset-index-in-a-pandas-dataframe/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f8b7e39-a689-4993-aabc-f5e6903225f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Var olan index'leri feature'a cevirir ve index'i default degere reset'ler.\n",
    "last_f_data.reset_index(inplace=True)\n",
    "last_h_data.reset_index(inplace=True)\n",
    "last_t_data.reset_index(inplace=True)\n",
    "\n",
    "# Her bir sector'un ismine gore target column'in degerlerini,\n",
    "# finance icin F, healthcare icin H, technology icin T olacak sekilde duzenliyoruz.\n",
    "last_f_data['index'] = 'F'\n",
    "last_h_data['index'] = 'H'\n",
    "last_t_data['index'] = 'T'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7750eb7-2374-4951-a7f1-3e62d46343f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Open__variance_larger_than_standard_deviation</th>\n",
       "      <th>Open__has_duplicate_max</th>\n",
       "      <th>Open__has_duplicate_min</th>\n",
       "      <th>Open__has_duplicate</th>\n",
       "      <th>Open__sum_values</th>\n",
       "      <th>Open__abs_energy</th>\n",
       "      <th>Open__mean_abs_change</th>\n",
       "      <th>Open__mean_change</th>\n",
       "      <th>Open__mean_second_derivative_central</th>\n",
       "      <th>...</th>\n",
       "      <th>Open__fourier_entropy__bins_5</th>\n",
       "      <th>Open__fourier_entropy__bins_10</th>\n",
       "      <th>Open__fourier_entropy__bins_100</th>\n",
       "      <th>Open__permutation_entropy__dimension_3__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_4__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_5__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_6__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_7__tau_1</th>\n",
       "      <th>Open__query_similarity_count__query_None__threshold_0.0</th>\n",
       "      <th>Open__mean_n_absolute_max__number_of_maxima_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.140826</td>\n",
       "      <td>28.289593</td>\n",
       "      <td>0.013991</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>...</td>\n",
       "      <td>1.210558</td>\n",
       "      <td>1.767009</td>\n",
       "      <td>2.430791</td>\n",
       "      <td>1.702816</td>\n",
       "      <td>2.830713</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.021379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.036788</td>\n",
       "      <td>9.073787</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>-0.000626</td>\n",
       "      <td>...</td>\n",
       "      <td>1.054920</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.955700</td>\n",
       "      <td>1.329661</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.005120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.103148</td>\n",
       "      <td>29.404967</td>\n",
       "      <td>0.338392</td>\n",
       "      <td>0.007472</td>\n",
       "      <td>-0.007883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793730</td>\n",
       "      <td>1.263626</td>\n",
       "      <td>2.311423</td>\n",
       "      <td>1.648841</td>\n",
       "      <td>2.309633</td>\n",
       "      <td>2.649159</td>\n",
       "      <td>2.798513</td>\n",
       "      <td>2.813355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.473320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>231.876674</td>\n",
       "      <td>238.060931</td>\n",
       "      <td>0.132384</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>-0.000157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889028</td>\n",
       "      <td>1.508808</td>\n",
       "      <td>3.515792</td>\n",
       "      <td>1.779465</td>\n",
       "      <td>3.120384</td>\n",
       "      <td>4.448227</td>\n",
       "      <td>5.171158</td>\n",
       "      <td>5.368324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.460903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.728347</td>\n",
       "      <td>233.290372</td>\n",
       "      <td>0.088443</td>\n",
       "      <td>-0.000281</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623387</td>\n",
       "      <td>1.241455</td>\n",
       "      <td>3.214773</td>\n",
       "      <td>1.783427</td>\n",
       "      <td>3.111290</td>\n",
       "      <td>4.423633</td>\n",
       "      <td>5.205801</td>\n",
       "      <td>5.405457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.194028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.117440</td>\n",
       "      <td>21.238768</td>\n",
       "      <td>0.012931</td>\n",
       "      <td>-0.000255</td>\n",
       "      <td>-0.000859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.759547</td>\n",
       "      <td>1.366711</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.690772</td>\n",
       "      <td>2.399204</td>\n",
       "      <td>2.751667</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.017388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.901678</td>\n",
       "      <td>109.190110</td>\n",
       "      <td>0.245288</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>-0.001376</td>\n",
       "      <td>...</td>\n",
       "      <td>1.467624</td>\n",
       "      <td>2.121745</td>\n",
       "      <td>3.530657</td>\n",
       "      <td>1.778002</td>\n",
       "      <td>3.050394</td>\n",
       "      <td>4.014869</td>\n",
       "      <td>4.454808</td>\n",
       "      <td>4.517693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.714045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.685108</td>\n",
       "      <td>26.599670</td>\n",
       "      <td>0.035502</td>\n",
       "      <td>-0.018161</td>\n",
       "      <td>-0.009536</td>\n",
       "      <td>...</td>\n",
       "      <td>1.437701</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.540036</td>\n",
       "      <td>1.735986</td>\n",
       "      <td>2.751916</td>\n",
       "      <td>3.075221</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.023887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.069471</td>\n",
       "      <td>235.308634</td>\n",
       "      <td>0.109571</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>...</td>\n",
       "      <td>1.034281</td>\n",
       "      <td>1.715718</td>\n",
       "      <td>3.582043</td>\n",
       "      <td>1.765319</td>\n",
       "      <td>3.113452</td>\n",
       "      <td>4.479124</td>\n",
       "      <td>5.222774</td>\n",
       "      <td>5.399268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.371946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.112033</td>\n",
       "      <td>30.225033</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>...</td>\n",
       "      <td>1.424443</td>\n",
       "      <td>1.808046</td>\n",
       "      <td>2.599302</td>\n",
       "      <td>1.712569</td>\n",
       "      <td>2.743635</td>\n",
       "      <td>3.151459</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.009057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>985 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  Open__variance_larger_than_standard_deviation  \\\n",
       "0       F                                            0.0   \n",
       "1       F                                            0.0   \n",
       "2       F                                            0.0   \n",
       "3       F                                            0.0   \n",
       "4       F                                            0.0   \n",
       "..    ...                                            ...   \n",
       "980     F                                            0.0   \n",
       "981     F                                            0.0   \n",
       "982     F                                            0.0   \n",
       "983     F                                            0.0   \n",
       "984     F                                            0.0   \n",
       "\n",
       "     Open__has_duplicate_max  Open__has_duplicate_min  Open__has_duplicate  \\\n",
       "0                        0.0                      0.0                  1.0   \n",
       "1                        0.0                      0.0                  0.0   \n",
       "2                        0.0                      0.0                  0.0   \n",
       "3                        0.0                      0.0                  1.0   \n",
       "4                        0.0                      0.0                  0.0   \n",
       "..                       ...                      ...                  ...   \n",
       "980                      0.0                      0.0                  1.0   \n",
       "981                      0.0                      0.0                  0.0   \n",
       "982                      0.0                      0.0                  1.0   \n",
       "983                      0.0                      0.0                  0.0   \n",
       "984                      0.0                      0.0                  1.0   \n",
       "\n",
       "     Open__sum_values  Open__abs_energy  Open__mean_abs_change  \\\n",
       "0           28.140826         28.289593               0.013991   \n",
       "1            9.036788          9.073787               0.002569   \n",
       "2           25.103148         29.404967               0.338392   \n",
       "3          231.876674        238.060931               0.132384   \n",
       "4          230.728347        233.290372               0.088443   \n",
       "..                ...               ...                    ...   \n",
       "980         21.117440         21.238768               0.012931   \n",
       "981        100.901678        109.190110               0.245288   \n",
       "982         26.685108         26.599670               0.035502   \n",
       "983        231.069471        235.308634               0.109571   \n",
       "984         30.112033         30.225033               0.004384   \n",
       "\n",
       "     Open__mean_change  Open__mean_second_derivative_central  ...  \\\n",
       "0             0.000718                              0.000255  ...   \n",
       "1             0.000119                             -0.000626  ...   \n",
       "2             0.007472                             -0.007883  ...   \n",
       "3            -0.000171                             -0.000157  ...   \n",
       "4            -0.000281                              0.000247  ...   \n",
       "..                 ...                                   ...  ...   \n",
       "980          -0.000255                             -0.000859  ...   \n",
       "981           0.003136                             -0.001376  ...   \n",
       "982          -0.018161                             -0.009536  ...   \n",
       "983           0.000093                              0.000122  ...   \n",
       "984           0.000089                              0.000083  ...   \n",
       "\n",
       "     Open__fourier_entropy__bins_5  Open__fourier_entropy__bins_10  \\\n",
       "0                         1.210558                        1.767009   \n",
       "1                         1.054920                        1.609438   \n",
       "2                         0.793730                        1.263626   \n",
       "3                         0.889028                        1.508808   \n",
       "4                         0.623387                        1.241455   \n",
       "..                             ...                             ...   \n",
       "980                       0.759547                        1.366711   \n",
       "981                       1.467624                        2.121745   \n",
       "982                       1.437701                        1.945910   \n",
       "983                       1.034281                        1.715718   \n",
       "984                       1.424443                        1.808046   \n",
       "\n",
       "     Open__fourier_entropy__bins_100  \\\n",
       "0                           2.430791   \n",
       "1                           1.609438   \n",
       "2                           2.311423   \n",
       "3                           3.515792   \n",
       "4                           3.214773   \n",
       "..                               ...   \n",
       "980                         2.397895   \n",
       "981                         3.530657   \n",
       "982                         2.540036   \n",
       "983                         3.582043   \n",
       "984                         2.599302   \n",
       "\n",
       "     Open__permutation_entropy__dimension_3__tau_1  \\\n",
       "0                                         1.702816   \n",
       "1                                         0.955700   \n",
       "2                                         1.648841   \n",
       "3                                         1.779465   \n",
       "4                                         1.783427   \n",
       "..                                             ...   \n",
       "980                                       1.690772   \n",
       "981                                       1.778002   \n",
       "982                                       1.735986   \n",
       "983                                       1.765319   \n",
       "984                                       1.712569   \n",
       "\n",
       "     Open__permutation_entropy__dimension_4__tau_1  \\\n",
       "0                                         2.830713   \n",
       "1                                         1.329661   \n",
       "2                                         2.309633   \n",
       "3                                         3.120384   \n",
       "4                                         3.111290   \n",
       "..                                             ...   \n",
       "980                                       2.399204   \n",
       "981                                       3.050394   \n",
       "982                                       2.751916   \n",
       "983                                       3.113452   \n",
       "984                                       2.743635   \n",
       "\n",
       "     Open__permutation_entropy__dimension_5__tau_1  \\\n",
       "0                                         3.178054   \n",
       "1                                         1.609438   \n",
       "2                                         2.649159   \n",
       "3                                         4.448227   \n",
       "4                                         4.423633   \n",
       "..                                             ...   \n",
       "980                                       2.751667   \n",
       "981                                       4.014869   \n",
       "982                                       3.075221   \n",
       "983                                       4.479124   \n",
       "984                                       3.151459   \n",
       "\n",
       "     Open__permutation_entropy__dimension_6__tau_1  \\\n",
       "0                                         3.135494   \n",
       "1                                         1.386294   \n",
       "2                                         2.798513   \n",
       "3                                         5.171158   \n",
       "4                                         5.205801   \n",
       "..                                             ...   \n",
       "980                                       2.772589   \n",
       "981                                       4.454808   \n",
       "982                                       3.091042   \n",
       "983                                       5.222774   \n",
       "984                                       3.218876   \n",
       "\n",
       "     Open__permutation_entropy__dimension_7__tau_1  \\\n",
       "0                                         3.091042   \n",
       "1                                         1.098612   \n",
       "2                                         2.813355   \n",
       "3                                         5.368324   \n",
       "4                                         5.405457   \n",
       "..                                             ...   \n",
       "980                                       2.708050   \n",
       "981                                       4.517693   \n",
       "982                                       3.044522   \n",
       "983                                       5.399268   \n",
       "984                                       3.178054   \n",
       "\n",
       "     Open__query_similarity_count__query_None__threshold_0.0  \\\n",
       "0                                                  NaN         \n",
       "1                                                  NaN         \n",
       "2                                                  NaN         \n",
       "3                                                  NaN         \n",
       "4                                                  NaN         \n",
       "..                                                 ...         \n",
       "980                                                NaN         \n",
       "981                                                NaN         \n",
       "982                                                NaN         \n",
       "983                                                NaN         \n",
       "984                                                NaN         \n",
       "\n",
       "     Open__mean_n_absolute_max__number_of_maxima_7  \n",
       "0                                         1.021379  \n",
       "1                                         1.005120  \n",
       "2                                         1.473320  \n",
       "3                                         1.460903  \n",
       "4                                         1.194028  \n",
       "..                                             ...  \n",
       "980                                       1.017388  \n",
       "981                                       1.714045  \n",
       "982                                       1.023887  \n",
       "983                                       1.371946  \n",
       "984                                       1.009057  \n",
       "\n",
       "[985 rows x 784 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_f_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6eb5cbee-42e8-4fb5-874a-b369ec190d49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Open__variance_larger_than_standard_deviation</th>\n",
       "      <th>Open__has_duplicate_max</th>\n",
       "      <th>Open__has_duplicate_min</th>\n",
       "      <th>Open__has_duplicate</th>\n",
       "      <th>Open__sum_values</th>\n",
       "      <th>Open__abs_energy</th>\n",
       "      <th>Open__mean_abs_change</th>\n",
       "      <th>Open__mean_change</th>\n",
       "      <th>Open__mean_second_derivative_central</th>\n",
       "      <th>...</th>\n",
       "      <th>Open__fourier_entropy__bins_5</th>\n",
       "      <th>Open__fourier_entropy__bins_10</th>\n",
       "      <th>Open__fourier_entropy__bins_100</th>\n",
       "      <th>Open__permutation_entropy__dimension_3__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_4__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_5__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_6__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_7__tau_1</th>\n",
       "      <th>Open__query_similarity_count__query_None__threshold_0.0</th>\n",
       "      <th>Open__mean_n_absolute_max__number_of_maxima_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.064922</td>\n",
       "      <td>237.851890</td>\n",
       "      <td>0.092876</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>...</td>\n",
       "      <td>1.014479</td>\n",
       "      <td>1.677535</td>\n",
       "      <td>3.528019</td>\n",
       "      <td>1.787516</td>\n",
       "      <td>3.104159</td>\n",
       "      <td>4.443318</td>\n",
       "      <td>5.167710</td>\n",
       "      <td>5.349758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.228913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.013583</td>\n",
       "      <td>75.989190</td>\n",
       "      <td>0.284100</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>...</td>\n",
       "      <td>1.290699</td>\n",
       "      <td>1.937719</td>\n",
       "      <td>3.297037</td>\n",
       "      <td>1.773966</td>\n",
       "      <td>3.040307</td>\n",
       "      <td>3.993012</td>\n",
       "      <td>4.199121</td>\n",
       "      <td>4.204693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.489924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.934327</td>\n",
       "      <td>138.582182</td>\n",
       "      <td>0.080564</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>-0.000626</td>\n",
       "      <td>...</td>\n",
       "      <td>1.048282</td>\n",
       "      <td>1.673284</td>\n",
       "      <td>3.492883</td>\n",
       "      <td>1.751884</td>\n",
       "      <td>3.056965</td>\n",
       "      <td>4.198258</td>\n",
       "      <td>4.694559</td>\n",
       "      <td>4.830369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.170471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.466273</td>\n",
       "      <td>37.082147</td>\n",
       "      <td>0.191168</td>\n",
       "      <td>-0.009005</td>\n",
       "      <td>0.005962</td>\n",
       "      <td>...</td>\n",
       "      <td>1.487798</td>\n",
       "      <td>1.825199</td>\n",
       "      <td>2.857103</td>\n",
       "      <td>1.767102</td>\n",
       "      <td>2.894715</td>\n",
       "      <td>3.436523</td>\n",
       "      <td>3.526361</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.210670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>230.885374</td>\n",
       "      <td>252.831806</td>\n",
       "      <td>0.288095</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>-0.000763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885954</td>\n",
       "      <td>1.541387</td>\n",
       "      <td>3.565636</td>\n",
       "      <td>1.785235</td>\n",
       "      <td>3.132960</td>\n",
       "      <td>4.451075</td>\n",
       "      <td>5.208126</td>\n",
       "      <td>5.374513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.102701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.000966</td>\n",
       "      <td>10.989604</td>\n",
       "      <td>0.336821</td>\n",
       "      <td>0.026584</td>\n",
       "      <td>-0.024478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796312</td>\n",
       "      <td>1.277034</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.695743</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.077843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107.187700</td>\n",
       "      <td>114.988455</td>\n",
       "      <td>0.286744</td>\n",
       "      <td>-0.001431</td>\n",
       "      <td>-0.004334</td>\n",
       "      <td>...</td>\n",
       "      <td>1.452413</td>\n",
       "      <td>2.124329</td>\n",
       "      <td>3.655247</td>\n",
       "      <td>1.782094</td>\n",
       "      <td>3.095687</td>\n",
       "      <td>4.245931</td>\n",
       "      <td>4.570608</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.688972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.808165</td>\n",
       "      <td>21.609863</td>\n",
       "      <td>0.309515</td>\n",
       "      <td>-0.009856</td>\n",
       "      <td>-0.020612</td>\n",
       "      <td>...</td>\n",
       "      <td>1.377820</td>\n",
       "      <td>1.839297</td>\n",
       "      <td>2.245035</td>\n",
       "      <td>1.749978</td>\n",
       "      <td>2.523922</td>\n",
       "      <td>2.912494</td>\n",
       "      <td>2.926418</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.161472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.115741</td>\n",
       "      <td>88.020538</td>\n",
       "      <td>0.195369</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>-0.000310</td>\n",
       "      <td>...</td>\n",
       "      <td>1.295625</td>\n",
       "      <td>1.943617</td>\n",
       "      <td>3.440607</td>\n",
       "      <td>1.778137</td>\n",
       "      <td>3.068956</td>\n",
       "      <td>4.057885</td>\n",
       "      <td>4.285617</td>\n",
       "      <td>4.343805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.395983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.718067</td>\n",
       "      <td>268.583806</td>\n",
       "      <td>0.259600</td>\n",
       "      <td>-0.000307</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881686</td>\n",
       "      <td>1.544747</td>\n",
       "      <td>3.453418</td>\n",
       "      <td>1.787949</td>\n",
       "      <td>3.151418</td>\n",
       "      <td>4.504166</td>\n",
       "      <td>5.194293</td>\n",
       "      <td>5.349758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.984929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1216 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  Open__variance_larger_than_standard_deviation  \\\n",
       "0        H                                            0.0   \n",
       "1        H                                            0.0   \n",
       "2        H                                            0.0   \n",
       "3        H                                            0.0   \n",
       "4        H                                            0.0   \n",
       "...    ...                                            ...   \n",
       "1211     H                                            0.0   \n",
       "1212     H                                            0.0   \n",
       "1213     H                                            0.0   \n",
       "1214     H                                            0.0   \n",
       "1215     H                                            0.0   \n",
       "\n",
       "      Open__has_duplicate_max  Open__has_duplicate_min  Open__has_duplicate  \\\n",
       "0                         0.0                      0.0                  0.0   \n",
       "1                         0.0                      0.0                  0.0   \n",
       "2                         0.0                      0.0                  0.0   \n",
       "3                         0.0                      0.0                  0.0   \n",
       "4                         0.0                      0.0                  1.0   \n",
       "...                       ...                      ...                  ...   \n",
       "1211                      0.0                      0.0                  0.0   \n",
       "1212                      0.0                      0.0                  1.0   \n",
       "1213                      0.0                      0.0                  0.0   \n",
       "1214                      0.0                      0.0                  0.0   \n",
       "1215                      0.0                      0.0                  1.0   \n",
       "\n",
       "      Open__sum_values  Open__abs_energy  Open__mean_abs_change  \\\n",
       "0           233.064922        237.851890               0.092876   \n",
       "1            72.013583         75.989190               0.284100   \n",
       "2           135.934327        138.582182               0.080564   \n",
       "3            37.466273         37.082147               0.191168   \n",
       "4           230.885374        252.831806               0.288095   \n",
       "...                ...               ...                    ...   \n",
       "1211         11.000966         10.989604               0.336821   \n",
       "1212        107.187700        114.988455               0.286744   \n",
       "1213         21.808165         21.609863               0.309515   \n",
       "1214         84.115741         88.020538               0.195369   \n",
       "1215        240.718067        268.583806               0.259600   \n",
       "\n",
       "      Open__mean_change  Open__mean_second_derivative_central  ...  \\\n",
       "0             -0.000115                              0.000335  ...   \n",
       "1              0.000463                              0.000780  ...   \n",
       "2              0.000120                             -0.000626  ...   \n",
       "3             -0.009005                              0.005962  ...   \n",
       "4              0.000709                             -0.000763  ...   \n",
       "...                 ...                                   ...  ...   \n",
       "1211           0.026584                             -0.024478  ...   \n",
       "1212          -0.001431                             -0.004334  ...   \n",
       "1213          -0.009856                             -0.020612  ...   \n",
       "1214          -0.000205                             -0.000310  ...   \n",
       "1215          -0.000307                             -0.000040  ...   \n",
       "\n",
       "      Open__fourier_entropy__bins_5  Open__fourier_entropy__bins_10  \\\n",
       "0                          1.014479                        1.677535   \n",
       "1                          1.290699                        1.937719   \n",
       "2                          1.048282                        1.673284   \n",
       "3                          1.487798                        1.825199   \n",
       "4                          0.885954                        1.541387   \n",
       "...                             ...                             ...   \n",
       "1211                       0.796312                        1.277034   \n",
       "1212                       1.452413                        2.124329   \n",
       "1213                       1.377820                        1.839297   \n",
       "1214                       1.295625                        1.943617   \n",
       "1215                       0.881686                        1.544747   \n",
       "\n",
       "      Open__fourier_entropy__bins_100  \\\n",
       "0                            3.528019   \n",
       "1                            3.297037   \n",
       "2                            3.492883   \n",
       "3                            2.857103   \n",
       "4                            3.565636   \n",
       "...                               ...   \n",
       "1211                         1.945910   \n",
       "1212                         3.655247   \n",
       "1213                         2.245035   \n",
       "1214                         3.440607   \n",
       "1215                         3.453418   \n",
       "\n",
       "      Open__permutation_entropy__dimension_3__tau_1  \\\n",
       "0                                          1.787516   \n",
       "1                                          1.773966   \n",
       "2                                          1.751884   \n",
       "3                                          1.767102   \n",
       "4                                          1.785235   \n",
       "...                                             ...   \n",
       "1211                                       1.695743   \n",
       "1212                                       1.782094   \n",
       "1213                                       1.749978   \n",
       "1214                                       1.778137   \n",
       "1215                                       1.787949   \n",
       "\n",
       "      Open__permutation_entropy__dimension_4__tau_1  \\\n",
       "0                                          3.104159   \n",
       "1                                          3.040307   \n",
       "2                                          3.056965   \n",
       "3                                          2.894715   \n",
       "4                                          3.132960   \n",
       "...                                             ...   \n",
       "1211                                       2.197225   \n",
       "1212                                       3.095687   \n",
       "1213                                       2.523922   \n",
       "1214                                       3.068956   \n",
       "1215                                       3.151418   \n",
       "\n",
       "      Open__permutation_entropy__dimension_5__tau_1  \\\n",
       "0                                          4.443318   \n",
       "1                                          3.993012   \n",
       "2                                          4.198258   \n",
       "3                                          3.436523   \n",
       "4                                          4.451075   \n",
       "...                                             ...   \n",
       "1211                                       2.079442   \n",
       "1212                                       4.245931   \n",
       "1213                                       2.912494   \n",
       "1214                                       4.057885   \n",
       "1215                                       4.504166   \n",
       "\n",
       "      Open__permutation_entropy__dimension_6__tau_1  \\\n",
       "0                                          5.167710   \n",
       "1                                          4.199121   \n",
       "2                                          4.694559   \n",
       "3                                          3.526361   \n",
       "4                                          5.208126   \n",
       "...                                             ...   \n",
       "1211                                       1.945910   \n",
       "1212                                       4.570608   \n",
       "1213                                       2.926418   \n",
       "1214                                       4.285617   \n",
       "1215                                       5.194293   \n",
       "\n",
       "      Open__permutation_entropy__dimension_7__tau_1  \\\n",
       "0                                          5.349758   \n",
       "1                                          4.204693   \n",
       "2                                          4.830369   \n",
       "3                                          3.496508   \n",
       "4                                          5.374513   \n",
       "...                                             ...   \n",
       "1211                                       1.791759   \n",
       "1212                                       4.615121   \n",
       "1213                                       2.944439   \n",
       "1214                                       4.343805   \n",
       "1215                                       5.349758   \n",
       "\n",
       "      Open__query_similarity_count__query_None__threshold_0.0  \\\n",
       "0                                                   NaN         \n",
       "1                                                   NaN         \n",
       "2                                                   NaN         \n",
       "3                                                   NaN         \n",
       "4                                                   NaN         \n",
       "...                                                 ...         \n",
       "1211                                                NaN         \n",
       "1212                                                NaN         \n",
       "1213                                                NaN         \n",
       "1214                                                NaN         \n",
       "1215                                                NaN         \n",
       "\n",
       "      Open__mean_n_absolute_max__number_of_maxima_7  \n",
       "0                                          1.228913  \n",
       "1                                          1.489924  \n",
       "2                                          1.170471  \n",
       "3                                          1.210670  \n",
       "4                                          2.102701  \n",
       "...                                             ...  \n",
       "1211                                       1.077843  \n",
       "1212                                       1.688972  \n",
       "1213                                       1.161472  \n",
       "1214                                       1.395983  \n",
       "1215                                       1.984929  \n",
       "\n",
       "[1216 rows x 784 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_h_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b054c296-8955-4e77-aed0-1e7ec1f6f984",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Open__variance_larger_than_standard_deviation</th>\n",
       "      <th>Open__has_duplicate_max</th>\n",
       "      <th>Open__has_duplicate_min</th>\n",
       "      <th>Open__has_duplicate</th>\n",
       "      <th>Open__sum_values</th>\n",
       "      <th>Open__abs_energy</th>\n",
       "      <th>Open__mean_abs_change</th>\n",
       "      <th>Open__mean_change</th>\n",
       "      <th>Open__mean_second_derivative_central</th>\n",
       "      <th>...</th>\n",
       "      <th>Open__fourier_entropy__bins_5</th>\n",
       "      <th>Open__fourier_entropy__bins_10</th>\n",
       "      <th>Open__fourier_entropy__bins_100</th>\n",
       "      <th>Open__permutation_entropy__dimension_3__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_4__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_5__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_6__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_7__tau_1</th>\n",
       "      <th>Open__query_similarity_count__query_None__threshold_0.0</th>\n",
       "      <th>Open__mean_n_absolute_max__number_of_maxima_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.326854</td>\n",
       "      <td>145.233609</td>\n",
       "      <td>0.297438</td>\n",
       "      <td>-0.003369</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>...</td>\n",
       "      <td>1.306471</td>\n",
       "      <td>1.919776</td>\n",
       "      <td>3.701139</td>\n",
       "      <td>1.789172</td>\n",
       "      <td>3.079022</td>\n",
       "      <td>4.250016</td>\n",
       "      <td>4.681221</td>\n",
       "      <td>4.775939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.872806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>235.977073</td>\n",
       "      <td>244.146471</td>\n",
       "      <td>0.102522</td>\n",
       "      <td>-0.001002</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>...</td>\n",
       "      <td>1.281364</td>\n",
       "      <td>1.884422</td>\n",
       "      <td>3.786981</td>\n",
       "      <td>1.790489</td>\n",
       "      <td>3.159653</td>\n",
       "      <td>4.531096</td>\n",
       "      <td>5.235097</td>\n",
       "      <td>5.405457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.218478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>232.527066</td>\n",
       "      <td>237.108832</td>\n",
       "      <td>0.101733</td>\n",
       "      <td>-0.000425</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692241</td>\n",
       "      <td>1.278668</td>\n",
       "      <td>3.255464</td>\n",
       "      <td>1.789476</td>\n",
       "      <td>3.146219</td>\n",
       "      <td>4.513990</td>\n",
       "      <td>5.187317</td>\n",
       "      <td>5.386891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.257802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>235.125048</td>\n",
       "      <td>246.997251</td>\n",
       "      <td>0.177726</td>\n",
       "      <td>-0.000926</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>...</td>\n",
       "      <td>1.188196</td>\n",
       "      <td>1.826451</td>\n",
       "      <td>3.722466</td>\n",
       "      <td>1.788837</td>\n",
       "      <td>3.152728</td>\n",
       "      <td>4.506759</td>\n",
       "      <td>5.209636</td>\n",
       "      <td>5.393080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.451027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.824762</td>\n",
       "      <td>91.248884</td>\n",
       "      <td>0.310172</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>-0.007964</td>\n",
       "      <td>...</td>\n",
       "      <td>1.354448</td>\n",
       "      <td>1.900262</td>\n",
       "      <td>3.281268</td>\n",
       "      <td>1.785733</td>\n",
       "      <td>3.083930</td>\n",
       "      <td>3.992574</td>\n",
       "      <td>4.223629</td>\n",
       "      <td>4.248495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.647787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.387535</td>\n",
       "      <td>35.706599</td>\n",
       "      <td>0.125435</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>-0.002871</td>\n",
       "      <td>...</td>\n",
       "      <td>1.370515</td>\n",
       "      <td>1.817382</td>\n",
       "      <td>2.622996</td>\n",
       "      <td>1.768230</td>\n",
       "      <td>2.837155</td>\n",
       "      <td>3.485587</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.124443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.358493</td>\n",
       "      <td>44.703179</td>\n",
       "      <td>0.190596</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>-0.002700</td>\n",
       "      <td>...</td>\n",
       "      <td>1.363188</td>\n",
       "      <td>1.774477</td>\n",
       "      <td>3.014947</td>\n",
       "      <td>1.758812</td>\n",
       "      <td>2.936766</td>\n",
       "      <td>3.578324</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>3.663562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.213355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.749947</td>\n",
       "      <td>62.246140</td>\n",
       "      <td>0.169367</td>\n",
       "      <td>-0.003417</td>\n",
       "      <td>-0.001022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903384</td>\n",
       "      <td>1.379292</td>\n",
       "      <td>2.748145</td>\n",
       "      <td>1.775446</td>\n",
       "      <td>2.939232</td>\n",
       "      <td>3.558556</td>\n",
       "      <td>3.911968</td>\n",
       "      <td>3.944135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.350458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.870751</td>\n",
       "      <td>79.664053</td>\n",
       "      <td>0.166460</td>\n",
       "      <td>-0.002925</td>\n",
       "      <td>-0.000303</td>\n",
       "      <td>...</td>\n",
       "      <td>1.380208</td>\n",
       "      <td>1.962726</td>\n",
       "      <td>3.320362</td>\n",
       "      <td>1.771000</td>\n",
       "      <td>3.077269</td>\n",
       "      <td>3.939091</td>\n",
       "      <td>4.163311</td>\n",
       "      <td>4.189655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.345846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.049666</td>\n",
       "      <td>72.744778</td>\n",
       "      <td>0.182902</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>...</td>\n",
       "      <td>1.290039</td>\n",
       "      <td>1.919223</td>\n",
       "      <td>3.169368</td>\n",
       "      <td>1.784305</td>\n",
       "      <td>3.008863</td>\n",
       "      <td>3.927900</td>\n",
       "      <td>4.168650</td>\n",
       "      <td>4.174387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.275732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>784 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  Open__variance_larger_than_standard_deviation  \\\n",
       "0       T                                            0.0   \n",
       "1       T                                            0.0   \n",
       "2       T                                            0.0   \n",
       "3       T                                            0.0   \n",
       "4       T                                            0.0   \n",
       "..    ...                                            ...   \n",
       "779     T                                            0.0   \n",
       "780     T                                            0.0   \n",
       "781     T                                            0.0   \n",
       "782     T                                            0.0   \n",
       "783     T                                            0.0   \n",
       "\n",
       "     Open__has_duplicate_max  Open__has_duplicate_min  Open__has_duplicate  \\\n",
       "0                        0.0                      0.0                  0.0   \n",
       "1                        0.0                      0.0                  0.0   \n",
       "2                        0.0                      0.0                  1.0   \n",
       "3                        0.0                      0.0                  1.0   \n",
       "4                        0.0                      0.0                  0.0   \n",
       "..                       ...                      ...                  ...   \n",
       "779                      0.0                      0.0                  0.0   \n",
       "780                      0.0                      0.0                  0.0   \n",
       "781                      0.0                      0.0                  0.0   \n",
       "782                      0.0                      0.0                  0.0   \n",
       "783                      0.0                      0.0                  0.0   \n",
       "\n",
       "     Open__sum_values  Open__abs_energy  Open__mean_abs_change  \\\n",
       "0          130.326854        145.233609               0.297438   \n",
       "1          235.977073        244.146471               0.102522   \n",
       "2          232.527066        237.108832               0.101733   \n",
       "3          235.125048        246.997251               0.177726   \n",
       "4           80.824762         91.248884               0.310172   \n",
       "..                ...               ...                    ...   \n",
       "779         36.387535         35.706599               0.125435   \n",
       "780         44.358493         44.703179               0.190596   \n",
       "781         59.749947         62.246140               0.169367   \n",
       "782         74.870751         79.664053               0.166460   \n",
       "783         71.049666         72.744778               0.182902   \n",
       "\n",
       "     Open__mean_change  Open__mean_second_derivative_central  ...  \\\n",
       "0            -0.003369                              0.000677  ...   \n",
       "1            -0.001002                              0.000543  ...   \n",
       "2            -0.000425                              0.000191  ...   \n",
       "3            -0.000926                              0.001029  ...   \n",
       "4             0.001472                             -0.007964  ...   \n",
       "..                 ...                                   ...  ...   \n",
       "779           0.000137                             -0.002871  ...   \n",
       "780           0.003235                             -0.002700  ...   \n",
       "781          -0.003417                             -0.001022  ...   \n",
       "782          -0.002925                             -0.000303  ...   \n",
       "783          -0.000018                              0.000428  ...   \n",
       "\n",
       "     Open__fourier_entropy__bins_5  Open__fourier_entropy__bins_10  \\\n",
       "0                         1.306471                        1.919776   \n",
       "1                         1.281364                        1.884422   \n",
       "2                         0.692241                        1.278668   \n",
       "3                         1.188196                        1.826451   \n",
       "4                         1.354448                        1.900262   \n",
       "..                             ...                             ...   \n",
       "779                       1.370515                        1.817382   \n",
       "780                       1.363188                        1.774477   \n",
       "781                       0.903384                        1.379292   \n",
       "782                       1.380208                        1.962726   \n",
       "783                       1.290039                        1.919223   \n",
       "\n",
       "     Open__fourier_entropy__bins_100  \\\n",
       "0                           3.701139   \n",
       "1                           3.786981   \n",
       "2                           3.255464   \n",
       "3                           3.722466   \n",
       "4                           3.281268   \n",
       "..                               ...   \n",
       "779                         2.622996   \n",
       "780                         3.014947   \n",
       "781                         2.748145   \n",
       "782                         3.320362   \n",
       "783                         3.169368   \n",
       "\n",
       "     Open__permutation_entropy__dimension_3__tau_1  \\\n",
       "0                                         1.789172   \n",
       "1                                         1.790489   \n",
       "2                                         1.789476   \n",
       "3                                         1.788837   \n",
       "4                                         1.785733   \n",
       "..                                             ...   \n",
       "779                                       1.768230   \n",
       "780                                       1.758812   \n",
       "781                                       1.775446   \n",
       "782                                       1.771000   \n",
       "783                                       1.784305   \n",
       "\n",
       "     Open__permutation_entropy__dimension_4__tau_1  \\\n",
       "0                                         3.079022   \n",
       "1                                         3.159653   \n",
       "2                                         3.146219   \n",
       "3                                         3.152728   \n",
       "4                                         3.083930   \n",
       "..                                             ...   \n",
       "779                                       2.837155   \n",
       "780                                       2.936766   \n",
       "781                                       2.939232   \n",
       "782                                       3.077269   \n",
       "783                                       3.008863   \n",
       "\n",
       "     Open__permutation_entropy__dimension_5__tau_1  \\\n",
       "0                                         4.250016   \n",
       "1                                         4.531096   \n",
       "2                                         4.513990   \n",
       "3                                         4.506759   \n",
       "4                                         3.992574   \n",
       "..                                             ...   \n",
       "779                                       3.485587   \n",
       "780                                       3.578324   \n",
       "781                                       3.558556   \n",
       "782                                       3.939091   \n",
       "783                                       3.927900   \n",
       "\n",
       "     Open__permutation_entropy__dimension_6__tau_1  \\\n",
       "0                                         4.681221   \n",
       "1                                         5.235097   \n",
       "2                                         5.187317   \n",
       "3                                         5.209636   \n",
       "4                                         4.223629   \n",
       "..                                             ...   \n",
       "779                                       3.496508   \n",
       "780                                       3.688879   \n",
       "781                                       3.911968   \n",
       "782                                       4.163311   \n",
       "783                                       4.168650   \n",
       "\n",
       "     Open__permutation_entropy__dimension_7__tau_1  \\\n",
       "0                                         4.775939   \n",
       "1                                         5.405457   \n",
       "2                                         5.386891   \n",
       "3                                         5.393080   \n",
       "4                                         4.248495   \n",
       "..                                             ...   \n",
       "779                                       3.465736   \n",
       "780                                       3.663562   \n",
       "781                                       3.944135   \n",
       "782                                       4.189655   \n",
       "783                                       4.174387   \n",
       "\n",
       "     Open__query_similarity_count__query_None__threshold_0.0  \\\n",
       "0                                                  NaN         \n",
       "1                                                  NaN         \n",
       "2                                                  NaN         \n",
       "3                                                  NaN         \n",
       "4                                                  NaN         \n",
       "..                                                 ...         \n",
       "779                                                NaN         \n",
       "780                                                NaN         \n",
       "781                                                NaN         \n",
       "782                                                NaN         \n",
       "783                                                NaN         \n",
       "\n",
       "     Open__mean_n_absolute_max__number_of_maxima_7  \n",
       "0                                         1.872806  \n",
       "1                                         1.218478  \n",
       "2                                         1.257802  \n",
       "3                                         1.451027  \n",
       "4                                         1.647787  \n",
       "..                                             ...  \n",
       "779                                       1.124443  \n",
       "780                                       1.213355  \n",
       "781                                       1.350458  \n",
       "782                                       1.345846  \n",
       "783                                       1.275732  \n",
       "\n",
       "[784 rows x 784 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_t_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c377730-104b-4b4b-b3d0-12d7d259c0eb",
   "metadata": {},
   "source": [
    "## Merge All DataFrames:\n",
    "Tum dataframe'lerimizi pandas.concat(dataframe_list) method'umuz sayesinde birlestirip tek bir dataframe olacak hale getiriyoruz. Boylece artik nihai dataframe'i elde etmis oluyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eecc12f4-3508-4ed3-871b-15713706de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# axis=0 yaparak SQL'deki union mantiginde merge ediyoruz.\n",
    "combined_df = pd.concat([last_f_data, last_h_data, last_t_data], axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69cd435d-e25c-48e5-80d0-141e9c842964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index column aslında target column oldugu icin bundan sonra yapilacak islemlerin daha anlasilir olmasi icin ismini Target olarak degistiriyoruz.\n",
    "combined_df.rename(columns={\"index\": \"Target\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18e5ec31-72c6-4ce8-ac8b-91c8d7417cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Open__variance_larger_than_standard_deviation</th>\n",
       "      <th>Open__has_duplicate_max</th>\n",
       "      <th>Open__has_duplicate_min</th>\n",
       "      <th>Open__has_duplicate</th>\n",
       "      <th>Open__sum_values</th>\n",
       "      <th>Open__abs_energy</th>\n",
       "      <th>Open__mean_abs_change</th>\n",
       "      <th>Open__mean_change</th>\n",
       "      <th>Open__mean_second_derivative_central</th>\n",
       "      <th>...</th>\n",
       "      <th>Open__fourier_entropy__bins_5</th>\n",
       "      <th>Open__fourier_entropy__bins_10</th>\n",
       "      <th>Open__fourier_entropy__bins_100</th>\n",
       "      <th>Open__permutation_entropy__dimension_3__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_4__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_5__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_6__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_7__tau_1</th>\n",
       "      <th>Open__query_similarity_count__query_None__threshold_0.0</th>\n",
       "      <th>Open__mean_n_absolute_max__number_of_maxima_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.140826</td>\n",
       "      <td>28.289593</td>\n",
       "      <td>0.013991</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>...</td>\n",
       "      <td>1.210558</td>\n",
       "      <td>1.767009</td>\n",
       "      <td>2.430791</td>\n",
       "      <td>1.702816</td>\n",
       "      <td>2.830713</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.021379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.036788</td>\n",
       "      <td>9.073787</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>-0.000626</td>\n",
       "      <td>...</td>\n",
       "      <td>1.054920</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.955700</td>\n",
       "      <td>1.329661</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.005120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.103148</td>\n",
       "      <td>29.404967</td>\n",
       "      <td>0.338392</td>\n",
       "      <td>0.007472</td>\n",
       "      <td>-0.007883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793730</td>\n",
       "      <td>1.263626</td>\n",
       "      <td>2.311423</td>\n",
       "      <td>1.648841</td>\n",
       "      <td>2.309633</td>\n",
       "      <td>2.649159</td>\n",
       "      <td>2.798513</td>\n",
       "      <td>2.813355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.473320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>231.876674</td>\n",
       "      <td>238.060931</td>\n",
       "      <td>0.132384</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>-0.000157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889028</td>\n",
       "      <td>1.508808</td>\n",
       "      <td>3.515792</td>\n",
       "      <td>1.779465</td>\n",
       "      <td>3.120384</td>\n",
       "      <td>4.448227</td>\n",
       "      <td>5.171158</td>\n",
       "      <td>5.368324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.460903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.728347</td>\n",
       "      <td>233.290372</td>\n",
       "      <td>0.088443</td>\n",
       "      <td>-0.000281</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623387</td>\n",
       "      <td>1.241455</td>\n",
       "      <td>3.214773</td>\n",
       "      <td>1.783427</td>\n",
       "      <td>3.111290</td>\n",
       "      <td>4.423633</td>\n",
       "      <td>5.205801</td>\n",
       "      <td>5.405457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.194028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.387535</td>\n",
       "      <td>35.706599</td>\n",
       "      <td>0.125435</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>-0.002871</td>\n",
       "      <td>...</td>\n",
       "      <td>1.370515</td>\n",
       "      <td>1.817382</td>\n",
       "      <td>2.622996</td>\n",
       "      <td>1.768230</td>\n",
       "      <td>2.837155</td>\n",
       "      <td>3.485587</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.124443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.358493</td>\n",
       "      <td>44.703179</td>\n",
       "      <td>0.190596</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>-0.002700</td>\n",
       "      <td>...</td>\n",
       "      <td>1.363188</td>\n",
       "      <td>1.774477</td>\n",
       "      <td>3.014947</td>\n",
       "      <td>1.758812</td>\n",
       "      <td>2.936766</td>\n",
       "      <td>3.578324</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>3.663562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.213355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.749947</td>\n",
       "      <td>62.246140</td>\n",
       "      <td>0.169367</td>\n",
       "      <td>-0.003417</td>\n",
       "      <td>-0.001022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903384</td>\n",
       "      <td>1.379292</td>\n",
       "      <td>2.748145</td>\n",
       "      <td>1.775446</td>\n",
       "      <td>2.939232</td>\n",
       "      <td>3.558556</td>\n",
       "      <td>3.911968</td>\n",
       "      <td>3.944135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.350458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.870751</td>\n",
       "      <td>79.664053</td>\n",
       "      <td>0.166460</td>\n",
       "      <td>-0.002925</td>\n",
       "      <td>-0.000303</td>\n",
       "      <td>...</td>\n",
       "      <td>1.380208</td>\n",
       "      <td>1.962726</td>\n",
       "      <td>3.320362</td>\n",
       "      <td>1.771000</td>\n",
       "      <td>3.077269</td>\n",
       "      <td>3.939091</td>\n",
       "      <td>4.163311</td>\n",
       "      <td>4.189655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.345846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.049666</td>\n",
       "      <td>72.744778</td>\n",
       "      <td>0.182902</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>...</td>\n",
       "      <td>1.290039</td>\n",
       "      <td>1.919223</td>\n",
       "      <td>3.169368</td>\n",
       "      <td>1.784305</td>\n",
       "      <td>3.008863</td>\n",
       "      <td>3.927900</td>\n",
       "      <td>4.168650</td>\n",
       "      <td>4.174387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.275732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2985 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Target  Open__variance_larger_than_standard_deviation  \\\n",
       "0        F                                            0.0   \n",
       "1        F                                            0.0   \n",
       "2        F                                            0.0   \n",
       "3        F                                            0.0   \n",
       "4        F                                            0.0   \n",
       "..     ...                                            ...   \n",
       "779      T                                            0.0   \n",
       "780      T                                            0.0   \n",
       "781      T                                            0.0   \n",
       "782      T                                            0.0   \n",
       "783      T                                            0.0   \n",
       "\n",
       "     Open__has_duplicate_max  Open__has_duplicate_min  Open__has_duplicate  \\\n",
       "0                        0.0                      0.0                  1.0   \n",
       "1                        0.0                      0.0                  0.0   \n",
       "2                        0.0                      0.0                  0.0   \n",
       "3                        0.0                      0.0                  1.0   \n",
       "4                        0.0                      0.0                  0.0   \n",
       "..                       ...                      ...                  ...   \n",
       "779                      0.0                      0.0                  0.0   \n",
       "780                      0.0                      0.0                  0.0   \n",
       "781                      0.0                      0.0                  0.0   \n",
       "782                      0.0                      0.0                  0.0   \n",
       "783                      0.0                      0.0                  0.0   \n",
       "\n",
       "     Open__sum_values  Open__abs_energy  Open__mean_abs_change  \\\n",
       "0           28.140826         28.289593               0.013991   \n",
       "1            9.036788          9.073787               0.002569   \n",
       "2           25.103148         29.404967               0.338392   \n",
       "3          231.876674        238.060931               0.132384   \n",
       "4          230.728347        233.290372               0.088443   \n",
       "..                ...               ...                    ...   \n",
       "779         36.387535         35.706599               0.125435   \n",
       "780         44.358493         44.703179               0.190596   \n",
       "781         59.749947         62.246140               0.169367   \n",
       "782         74.870751         79.664053               0.166460   \n",
       "783         71.049666         72.744778               0.182902   \n",
       "\n",
       "     Open__mean_change  Open__mean_second_derivative_central  ...  \\\n",
       "0             0.000718                              0.000255  ...   \n",
       "1             0.000119                             -0.000626  ...   \n",
       "2             0.007472                             -0.007883  ...   \n",
       "3            -0.000171                             -0.000157  ...   \n",
       "4            -0.000281                              0.000247  ...   \n",
       "..                 ...                                   ...  ...   \n",
       "779           0.000137                             -0.002871  ...   \n",
       "780           0.003235                             -0.002700  ...   \n",
       "781          -0.003417                             -0.001022  ...   \n",
       "782          -0.002925                             -0.000303  ...   \n",
       "783          -0.000018                              0.000428  ...   \n",
       "\n",
       "     Open__fourier_entropy__bins_5  Open__fourier_entropy__bins_10  \\\n",
       "0                         1.210558                        1.767009   \n",
       "1                         1.054920                        1.609438   \n",
       "2                         0.793730                        1.263626   \n",
       "3                         0.889028                        1.508808   \n",
       "4                         0.623387                        1.241455   \n",
       "..                             ...                             ...   \n",
       "779                       1.370515                        1.817382   \n",
       "780                       1.363188                        1.774477   \n",
       "781                       0.903384                        1.379292   \n",
       "782                       1.380208                        1.962726   \n",
       "783                       1.290039                        1.919223   \n",
       "\n",
       "     Open__fourier_entropy__bins_100  \\\n",
       "0                           2.430791   \n",
       "1                           1.609438   \n",
       "2                           2.311423   \n",
       "3                           3.515792   \n",
       "4                           3.214773   \n",
       "..                               ...   \n",
       "779                         2.622996   \n",
       "780                         3.014947   \n",
       "781                         2.748145   \n",
       "782                         3.320362   \n",
       "783                         3.169368   \n",
       "\n",
       "     Open__permutation_entropy__dimension_3__tau_1  \\\n",
       "0                                         1.702816   \n",
       "1                                         0.955700   \n",
       "2                                         1.648841   \n",
       "3                                         1.779465   \n",
       "4                                         1.783427   \n",
       "..                                             ...   \n",
       "779                                       1.768230   \n",
       "780                                       1.758812   \n",
       "781                                       1.775446   \n",
       "782                                       1.771000   \n",
       "783                                       1.784305   \n",
       "\n",
       "     Open__permutation_entropy__dimension_4__tau_1  \\\n",
       "0                                         2.830713   \n",
       "1                                         1.329661   \n",
       "2                                         2.309633   \n",
       "3                                         3.120384   \n",
       "4                                         3.111290   \n",
       "..                                             ...   \n",
       "779                                       2.837155   \n",
       "780                                       2.936766   \n",
       "781                                       2.939232   \n",
       "782                                       3.077269   \n",
       "783                                       3.008863   \n",
       "\n",
       "     Open__permutation_entropy__dimension_5__tau_1  \\\n",
       "0                                         3.178054   \n",
       "1                                         1.609438   \n",
       "2                                         2.649159   \n",
       "3                                         4.448227   \n",
       "4                                         4.423633   \n",
       "..                                             ...   \n",
       "779                                       3.485587   \n",
       "780                                       3.578324   \n",
       "781                                       3.558556   \n",
       "782                                       3.939091   \n",
       "783                                       3.927900   \n",
       "\n",
       "     Open__permutation_entropy__dimension_6__tau_1  \\\n",
       "0                                         3.135494   \n",
       "1                                         1.386294   \n",
       "2                                         2.798513   \n",
       "3                                         5.171158   \n",
       "4                                         5.205801   \n",
       "..                                             ...   \n",
       "779                                       3.496508   \n",
       "780                                       3.688879   \n",
       "781                                       3.911968   \n",
       "782                                       4.163311   \n",
       "783                                       4.168650   \n",
       "\n",
       "     Open__permutation_entropy__dimension_7__tau_1  \\\n",
       "0                                         3.091042   \n",
       "1                                         1.098612   \n",
       "2                                         2.813355   \n",
       "3                                         5.368324   \n",
       "4                                         5.405457   \n",
       "..                                             ...   \n",
       "779                                       3.465736   \n",
       "780                                       3.663562   \n",
       "781                                       3.944135   \n",
       "782                                       4.189655   \n",
       "783                                       4.174387   \n",
       "\n",
       "     Open__query_similarity_count__query_None__threshold_0.0  \\\n",
       "0                                                  NaN         \n",
       "1                                                  NaN         \n",
       "2                                                  NaN         \n",
       "3                                                  NaN         \n",
       "4                                                  NaN         \n",
       "..                                                 ...         \n",
       "779                                                NaN         \n",
       "780                                                NaN         \n",
       "781                                                NaN         \n",
       "782                                                NaN         \n",
       "783                                                NaN         \n",
       "\n",
       "     Open__mean_n_absolute_max__number_of_maxima_7  \n",
       "0                                         1.021379  \n",
       "1                                         1.005120  \n",
       "2                                         1.473320  \n",
       "3                                         1.460903  \n",
       "4                                         1.194028  \n",
       "..                                             ...  \n",
       "779                                       1.124443  \n",
       "780                                       1.213355  \n",
       "781                                       1.350458  \n",
       "782                                       1.345846  \n",
       "783                                       1.275732  \n",
       "\n",
       "[2985 rows x 784 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf7c63cb-9361-48f0-be97-2b01ee71a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Union olarak merge ettigimiz icin indexing'de ufak bir hata olustu. Bu sebepten oturu index'i tekrar reset'liyoruz fakat\n",
    "# bu sefer index, feature olarak gelmemesi ve tekrar drop kullanmamak icin parametre olarak drop=True pass ederek index'in feature olarak \n",
    "# shift edilmesinin onune gecmis oluyoruz.\n",
    "combined_df_reset = combined_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7bda6c7a-78ff-4ff0-9c92-bf3fa01a0466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Open__variance_larger_than_standard_deviation</th>\n",
       "      <th>Open__has_duplicate_max</th>\n",
       "      <th>Open__has_duplicate_min</th>\n",
       "      <th>Open__has_duplicate</th>\n",
       "      <th>Open__sum_values</th>\n",
       "      <th>Open__abs_energy</th>\n",
       "      <th>Open__mean_abs_change</th>\n",
       "      <th>Open__mean_change</th>\n",
       "      <th>Open__mean_second_derivative_central</th>\n",
       "      <th>...</th>\n",
       "      <th>Open__fourier_entropy__bins_5</th>\n",
       "      <th>Open__fourier_entropy__bins_10</th>\n",
       "      <th>Open__fourier_entropy__bins_100</th>\n",
       "      <th>Open__permutation_entropy__dimension_3__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_4__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_5__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_6__tau_1</th>\n",
       "      <th>Open__permutation_entropy__dimension_7__tau_1</th>\n",
       "      <th>Open__query_similarity_count__query_None__threshold_0.0</th>\n",
       "      <th>Open__mean_n_absolute_max__number_of_maxima_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.140826</td>\n",
       "      <td>28.289593</td>\n",
       "      <td>0.013991</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>...</td>\n",
       "      <td>1.210558</td>\n",
       "      <td>1.767009</td>\n",
       "      <td>2.430791</td>\n",
       "      <td>1.702816</td>\n",
       "      <td>2.830713</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.021379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.036788</td>\n",
       "      <td>9.073787</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>-0.000626</td>\n",
       "      <td>...</td>\n",
       "      <td>1.054920</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.955700</td>\n",
       "      <td>1.329661</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.005120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.103148</td>\n",
       "      <td>29.404967</td>\n",
       "      <td>0.338392</td>\n",
       "      <td>0.007472</td>\n",
       "      <td>-0.007883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793730</td>\n",
       "      <td>1.263626</td>\n",
       "      <td>2.311423</td>\n",
       "      <td>1.648841</td>\n",
       "      <td>2.309633</td>\n",
       "      <td>2.649159</td>\n",
       "      <td>2.798513</td>\n",
       "      <td>2.813355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.473320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>231.876674</td>\n",
       "      <td>238.060931</td>\n",
       "      <td>0.132384</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>-0.000157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889028</td>\n",
       "      <td>1.508808</td>\n",
       "      <td>3.515792</td>\n",
       "      <td>1.779465</td>\n",
       "      <td>3.120384</td>\n",
       "      <td>4.448227</td>\n",
       "      <td>5.171158</td>\n",
       "      <td>5.368324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.460903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.728347</td>\n",
       "      <td>233.290372</td>\n",
       "      <td>0.088443</td>\n",
       "      <td>-0.000281</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623387</td>\n",
       "      <td>1.241455</td>\n",
       "      <td>3.214773</td>\n",
       "      <td>1.783427</td>\n",
       "      <td>3.111290</td>\n",
       "      <td>4.423633</td>\n",
       "      <td>5.205801</td>\n",
       "      <td>5.405457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.194028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.387535</td>\n",
       "      <td>35.706599</td>\n",
       "      <td>0.125435</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>-0.002871</td>\n",
       "      <td>...</td>\n",
       "      <td>1.370515</td>\n",
       "      <td>1.817382</td>\n",
       "      <td>2.622996</td>\n",
       "      <td>1.768230</td>\n",
       "      <td>2.837155</td>\n",
       "      <td>3.485587</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.124443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.358493</td>\n",
       "      <td>44.703179</td>\n",
       "      <td>0.190596</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>-0.002700</td>\n",
       "      <td>...</td>\n",
       "      <td>1.363188</td>\n",
       "      <td>1.774477</td>\n",
       "      <td>3.014947</td>\n",
       "      <td>1.758812</td>\n",
       "      <td>2.936766</td>\n",
       "      <td>3.578324</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>3.663562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.213355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.749947</td>\n",
       "      <td>62.246140</td>\n",
       "      <td>0.169367</td>\n",
       "      <td>-0.003417</td>\n",
       "      <td>-0.001022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903384</td>\n",
       "      <td>1.379292</td>\n",
       "      <td>2.748145</td>\n",
       "      <td>1.775446</td>\n",
       "      <td>2.939232</td>\n",
       "      <td>3.558556</td>\n",
       "      <td>3.911968</td>\n",
       "      <td>3.944135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.350458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.870751</td>\n",
       "      <td>79.664053</td>\n",
       "      <td>0.166460</td>\n",
       "      <td>-0.002925</td>\n",
       "      <td>-0.000303</td>\n",
       "      <td>...</td>\n",
       "      <td>1.380208</td>\n",
       "      <td>1.962726</td>\n",
       "      <td>3.320362</td>\n",
       "      <td>1.771000</td>\n",
       "      <td>3.077269</td>\n",
       "      <td>3.939091</td>\n",
       "      <td>4.163311</td>\n",
       "      <td>4.189655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.345846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.049666</td>\n",
       "      <td>72.744778</td>\n",
       "      <td>0.182902</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>...</td>\n",
       "      <td>1.290039</td>\n",
       "      <td>1.919223</td>\n",
       "      <td>3.169368</td>\n",
       "      <td>1.784305</td>\n",
       "      <td>3.008863</td>\n",
       "      <td>3.927900</td>\n",
       "      <td>4.168650</td>\n",
       "      <td>4.174387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.275732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2985 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target  Open__variance_larger_than_standard_deviation  \\\n",
       "0         F                                            0.0   \n",
       "1         F                                            0.0   \n",
       "2         F                                            0.0   \n",
       "3         F                                            0.0   \n",
       "4         F                                            0.0   \n",
       "...     ...                                            ...   \n",
       "2980      T                                            0.0   \n",
       "2981      T                                            0.0   \n",
       "2982      T                                            0.0   \n",
       "2983      T                                            0.0   \n",
       "2984      T                                            0.0   \n",
       "\n",
       "      Open__has_duplicate_max  Open__has_duplicate_min  Open__has_duplicate  \\\n",
       "0                         0.0                      0.0                  1.0   \n",
       "1                         0.0                      0.0                  0.0   \n",
       "2                         0.0                      0.0                  0.0   \n",
       "3                         0.0                      0.0                  1.0   \n",
       "4                         0.0                      0.0                  0.0   \n",
       "...                       ...                      ...                  ...   \n",
       "2980                      0.0                      0.0                  0.0   \n",
       "2981                      0.0                      0.0                  0.0   \n",
       "2982                      0.0                      0.0                  0.0   \n",
       "2983                      0.0                      0.0                  0.0   \n",
       "2984                      0.0                      0.0                  0.0   \n",
       "\n",
       "      Open__sum_values  Open__abs_energy  Open__mean_abs_change  \\\n",
       "0            28.140826         28.289593               0.013991   \n",
       "1             9.036788          9.073787               0.002569   \n",
       "2            25.103148         29.404967               0.338392   \n",
       "3           231.876674        238.060931               0.132384   \n",
       "4           230.728347        233.290372               0.088443   \n",
       "...                ...               ...                    ...   \n",
       "2980         36.387535         35.706599               0.125435   \n",
       "2981         44.358493         44.703179               0.190596   \n",
       "2982         59.749947         62.246140               0.169367   \n",
       "2983         74.870751         79.664053               0.166460   \n",
       "2984         71.049666         72.744778               0.182902   \n",
       "\n",
       "      Open__mean_change  Open__mean_second_derivative_central  ...  \\\n",
       "0              0.000718                              0.000255  ...   \n",
       "1              0.000119                             -0.000626  ...   \n",
       "2              0.007472                             -0.007883  ...   \n",
       "3             -0.000171                             -0.000157  ...   \n",
       "4             -0.000281                              0.000247  ...   \n",
       "...                 ...                                   ...  ...   \n",
       "2980           0.000137                             -0.002871  ...   \n",
       "2981           0.003235                             -0.002700  ...   \n",
       "2982          -0.003417                             -0.001022  ...   \n",
       "2983          -0.002925                             -0.000303  ...   \n",
       "2984          -0.000018                              0.000428  ...   \n",
       "\n",
       "      Open__fourier_entropy__bins_5  Open__fourier_entropy__bins_10  \\\n",
       "0                          1.210558                        1.767009   \n",
       "1                          1.054920                        1.609438   \n",
       "2                          0.793730                        1.263626   \n",
       "3                          0.889028                        1.508808   \n",
       "4                          0.623387                        1.241455   \n",
       "...                             ...                             ...   \n",
       "2980                       1.370515                        1.817382   \n",
       "2981                       1.363188                        1.774477   \n",
       "2982                       0.903384                        1.379292   \n",
       "2983                       1.380208                        1.962726   \n",
       "2984                       1.290039                        1.919223   \n",
       "\n",
       "      Open__fourier_entropy__bins_100  \\\n",
       "0                            2.430791   \n",
       "1                            1.609438   \n",
       "2                            2.311423   \n",
       "3                            3.515792   \n",
       "4                            3.214773   \n",
       "...                               ...   \n",
       "2980                         2.622996   \n",
       "2981                         3.014947   \n",
       "2982                         2.748145   \n",
       "2983                         3.320362   \n",
       "2984                         3.169368   \n",
       "\n",
       "      Open__permutation_entropy__dimension_3__tau_1  \\\n",
       "0                                          1.702816   \n",
       "1                                          0.955700   \n",
       "2                                          1.648841   \n",
       "3                                          1.779465   \n",
       "4                                          1.783427   \n",
       "...                                             ...   \n",
       "2980                                       1.768230   \n",
       "2981                                       1.758812   \n",
       "2982                                       1.775446   \n",
       "2983                                       1.771000   \n",
       "2984                                       1.784305   \n",
       "\n",
       "      Open__permutation_entropy__dimension_4__tau_1  \\\n",
       "0                                          2.830713   \n",
       "1                                          1.329661   \n",
       "2                                          2.309633   \n",
       "3                                          3.120384   \n",
       "4                                          3.111290   \n",
       "...                                             ...   \n",
       "2980                                       2.837155   \n",
       "2981                                       2.936766   \n",
       "2982                                       2.939232   \n",
       "2983                                       3.077269   \n",
       "2984                                       3.008863   \n",
       "\n",
       "      Open__permutation_entropy__dimension_5__tau_1  \\\n",
       "0                                          3.178054   \n",
       "1                                          1.609438   \n",
       "2                                          2.649159   \n",
       "3                                          4.448227   \n",
       "4                                          4.423633   \n",
       "...                                             ...   \n",
       "2980                                       3.485587   \n",
       "2981                                       3.578324   \n",
       "2982                                       3.558556   \n",
       "2983                                       3.939091   \n",
       "2984                                       3.927900   \n",
       "\n",
       "      Open__permutation_entropy__dimension_6__tau_1  \\\n",
       "0                                          3.135494   \n",
       "1                                          1.386294   \n",
       "2                                          2.798513   \n",
       "3                                          5.171158   \n",
       "4                                          5.205801   \n",
       "...                                             ...   \n",
       "2980                                       3.496508   \n",
       "2981                                       3.688879   \n",
       "2982                                       3.911968   \n",
       "2983                                       4.163311   \n",
       "2984                                       4.168650   \n",
       "\n",
       "      Open__permutation_entropy__dimension_7__tau_1  \\\n",
       "0                                          3.091042   \n",
       "1                                          1.098612   \n",
       "2                                          2.813355   \n",
       "3                                          5.368324   \n",
       "4                                          5.405457   \n",
       "...                                             ...   \n",
       "2980                                       3.465736   \n",
       "2981                                       3.663562   \n",
       "2982                                       3.944135   \n",
       "2983                                       4.189655   \n",
       "2984                                       4.174387   \n",
       "\n",
       "      Open__query_similarity_count__query_None__threshold_0.0  \\\n",
       "0                                                   NaN         \n",
       "1                                                   NaN         \n",
       "2                                                   NaN         \n",
       "3                                                   NaN         \n",
       "4                                                   NaN         \n",
       "...                                                 ...         \n",
       "2980                                                NaN         \n",
       "2981                                                NaN         \n",
       "2982                                                NaN         \n",
       "2983                                                NaN         \n",
       "2984                                                NaN         \n",
       "\n",
       "      Open__mean_n_absolute_max__number_of_maxima_7  \n",
       "0                                          1.021379  \n",
       "1                                          1.005120  \n",
       "2                                          1.473320  \n",
       "3                                          1.460903  \n",
       "4                                          1.194028  \n",
       "...                                             ...  \n",
       "2980                                       1.124443  \n",
       "2981                                       1.213355  \n",
       "2982                                       1.350458  \n",
       "2983                                       1.345846  \n",
       "2984                                       1.275732  \n",
       "\n",
       "[2985 rows x 784 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e21d4a-ff30-4083-b4e2-86018b7967ce",
   "metadata": {},
   "source": [
    "## Prepare DataFrame =\n",
    "### 1) Fill Missing Values:\n",
    "2.Adim olan yuksek correlation degerlerine sahip feature'lari kaldirma isleminin yapilabilmesi icin ilk yapacagimiz sey imputer kullanarak missing data'lari doldurma islemini yapmak olacaktir. Cunku 2.adimin uygulanabilmesinin 2 tane sarti vardir. Ilki fit edilecek tum degerler numerical olmali, ikincisi ise icerisinde Nan value olmamalidir.\n",
    "### 2) Drop High Correlation Features:\n",
    "Buradaki amacimiz A-B ve B-C high correlation'a sahipse A-C high correlation'a sahiptir denmemesi için (geciskenlik ozelligi yoktur) direkt high correlation'lara sahip feature'lari kaldirmamak icin \"SmartCorrelatedSelection\" kullaniriz.\n",
    "### 3) Encoding Target Column:\n",
    "Dataframe'imizi modele vermeden once target column'inin degerlerinin map edilmesi gerekiyor. Bu yuzden sunları kullanabiliriz:\n",
    "* OneHotEncoder\n",
    "* LabelEncoder \n",
    "Ikisi de kullanilabilir fakat LabelEncoder kullanmak biraz daha kolay ve zahmet verici olmadıgı için onu kullanacagiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "82387a81-45e7-4092-a956-c500cc1a8692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X = combined_df_reset.drop('Target', axis=1).copy()\n",
    "X.replace([np.inf, -np.inf], 0, inplace=True) # Infinite Value'larin degerini 0 ile degistir.\n",
    "\n",
    "df_selection_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')), # Fill Missing Values\n",
    "    ('select_corr', SmartCorrelatedSelection( # Drop High Correlation Features\n",
    "        variables=None,\n",
    "        method=\"pearson\",\n",
    "        threshold=0.8,\n",
    "        missing_values=\"raise\",\n",
    "        selection_method=\"variance\",\n",
    "        estimator=None)\n",
    "    )\n",
    "])\n",
    "\n",
    "Xt = df_selection_pipeline.fit_transform(X)\n",
    "\n",
    "le = LabelEncoder()\n",
    "ye = le.fit_transform(combined_df_reset['Target'].copy()) # Encoding Target Column\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xt, ye, test_size = 0.2, random_state = 42) # Train %80- Test %20 olarak dataframe'i split et."
   ]
  },
  {
   "attachments": {
    "f2b4c7ad-fc5b-488a-90ef-01ea4e7c982c.webp": {
     "image/webp": "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"
    }
   },
   "cell_type": "markdown",
   "id": "2871fe4e-b96d-469f-8110-d1d8062de202",
   "metadata": {},
   "source": [
    "## Create Pipeline with ColumnTransformer Step by Step =\n",
    "### 1) Scaling:\n",
    "MinMaxScaler outlier'lara duyarli olsa da kullanimi kolay oldugu icin sonrasinda kullanacagimiz feature engineering method'larinin problem cikartmamasini saglamak. RobustScaler ise outlier degerlere daha az duyarli oldugu icin onu tercih etmek daha iyi olacaktir fakat bu proje kapsaminda MinMaxScaler kullanilacak. \n",
    "\n",
    "Istege bagli olarak Trim, Winsorize veya Recode kullanarak outlier'lar uzerinde manipulation islemlerini yapabiliriz. Bunu yapmak icin asagidaki pipeline'imiz icerisinde bulunan power_transform'un hemen altına bunlardan birini ekleyerek outliers uzerinde islem yapabilirsiniz.\n",
    "\n",
    "<b>Note</b>\n",
    "* <b>Trim:</b> Outlier'lari belirler sonra basic bir sekilde kaldirir.\n",
    "* <b>Winsorize:</b> Her bir outlier'a bakar ve en yakin normal deger ile degistirir.\n",
    "* <b>Recode:</b> Trim + imputation yapar.\n",
    "\n",
    "Outlier'lari gormek istiyorsaniz, train_test_split'ten hemen once\n",
    "* LocalOutlierFactor()\n",
    "  \n",
    "veya\n",
    "* IsolationForest()\n",
    "  \n",
    "kullanarak tespit edip gozlemleyebilirsiniz.\n",
    "### 2) Dropping Constant Features:  \n",
    "Bir dataframe'de surekli olarak tekrar eden degerler olabilir. Bu degerlere <b>constant features</b> denir. Bu feature'larin model training islemine hicbir katkisi olmaz. Bu sebepten oturu bunlari safe bir sekilde kaldirmak modelin train time complexity'sini hızlandırmaktadir. Bu method'un kotu tarafı disaridan gelen related bir dataset'i modele verirken column'larda sorun cıkarabilmesidir.\n",
    "\n",
    "![1_xSKlEFsbIV3pgBgoK9GpdA.webp](attachment:f2b4c7ad-fc5b-488a-90ef-01ea4e7c982c.webp)\n",
    "\n",
    "https://medium.com/nerd-for-tech/removing-constant-variables-feature-selection-463e2d6a30d9\n",
    "\n",
    "\n",
    "### 3) Transformation:\n",
    "Eger variable'larimiz yani data'larimiz normal distribution'a sahip degil ise bu data'larimizi Gauss distribution'ina donusturmek icin <b>transformation</b> method'larini kullanabiliriz. Bu proje kapsaminda <b>Yeo-Johnson Transformation</b>'ini kullanacagiz.\n",
    "### 4) Selecting Best Model and Parameters:\n",
    "RandomizedSearchCV, bir specific model icin hyperparameter aramasini gerceklestirmek icin kullanilan bir cross-validation tool'udur. \n",
    "Bu tool, bir search tree yerine random samples uzerinden gerceklestirir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c376d80-ddf9-4af5-be76-07c8a97811d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, error_score=&#x27;raise&#x27;,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                              Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                               MinMaxScaler()),\n",
       "                                                              (&#x27;variance&#x27;,\n",
       "                                                               VarianceThreshold()),\n",
       "                                                              (&#x27;power_transform&#x27;,\n",
       "                                                               PowerTransformer())])),\n",
       "                                             (&#x27;classifier&#x27;,\n",
       "                                              RandomForestClassifier())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;classifier__bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;classifier__max_depth&#x27;: [None, 5, 10,\n",
       "                                                                  15],\n",
       "                                        &#x27;classifier__min_samples_leaf&#x27;: [1, 2,\n",
       "                                                                         4],\n",
       "                                        &#x27;classifier__min_samples_split&#x27;: [2, 5,\n",
       "                                                                          10],\n",
       "                                        &#x27;classifier__n_estimators&#x27;: [50, 100,\n",
       "                                                                     150]},\n",
       "                   random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, error_score=&#x27;raise&#x27;,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                              Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                               MinMaxScaler()),\n",
       "                                                              (&#x27;variance&#x27;,\n",
       "                                                               VarianceThreshold()),\n",
       "                                                              (&#x27;power_transform&#x27;,\n",
       "                                                               PowerTransformer())])),\n",
       "                                             (&#x27;classifier&#x27;,\n",
       "                                              RandomForestClassifier())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;classifier__bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;classifier__max_depth&#x27;: [None, 5, 10,\n",
       "                                                                  15],\n",
       "                                        &#x27;classifier__min_samples_leaf&#x27;: [1, 2,\n",
       "                                                                         4],\n",
       "                                        &#x27;classifier__min_samples_split&#x27;: [2, 5,\n",
       "                                                                          10],\n",
       "                                        &#x27;classifier__n_estimators&#x27;: [50, 100,\n",
       "                                                                     150]},\n",
       "                   random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                                 (&#x27;variance&#x27;, VarianceThreshold()),\n",
       "                                 (&#x27;power_transform&#x27;, PowerTransformer())])),\n",
       "                (&#x27;classifier&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()), (&#x27;variance&#x27;, VarianceThreshold()),\n",
       "                (&#x27;power_transform&#x27;, PowerTransformer())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VarianceThreshold</label><div class=\"sk-toggleable__content\"><pre>VarianceThreshold()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PowerTransformer</label><div class=\"sk-toggleable__content\"><pre>PowerTransformer()</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "                   estimator=Pipeline(steps=[('preprocessor',\n",
       "                                              Pipeline(steps=[('scaler',\n",
       "                                                               MinMaxScaler()),\n",
       "                                                              ('variance',\n",
       "                                                               VarianceThreshold()),\n",
       "                                                              ('power_transform',\n",
       "                                                               PowerTransformer())])),\n",
       "                                             ('classifier',\n",
       "                                              RandomForestClassifier())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'classifier__bootstrap': [True, False],\n",
       "                                        'classifier__max_depth': [None, 5, 10,\n",
       "                                                                  15],\n",
       "                                        'classifier__min_samples_leaf': [1, 2,\n",
       "                                                                         4],\n",
       "                                        'classifier__min_samples_split': [2, 5,\n",
       "                                                                          10],\n",
       "                                        'classifier__n_estimators': [50, 100,\n",
       "                                                                     150]},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Sklearn output'unun numpy array olarak return etmemesi icin kullanilir.\n",
    "from sklearn import set_config\n",
    "# Pandas olarak return eder.\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "preprocessor = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('variance', VarianceThreshold()),\n",
    "    ('power_transform', PowerTransformer())] # Default method='yeo-johnson'\n",
    ")\n",
    "\n",
    "# Model Pipeline'ini olustur.\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor), # Pipeline'i calistirir.\n",
    "    ('classifier', RandomForestClassifier()) # Pipeline kullanilarak X_train hazirlandiktan sonra train icin kullanilacak classifier.\n",
    "])\n",
    "\n",
    "# Hiperparametreleri belirle.\n",
    "param_distributions = {\n",
    "    'classifier__n_estimators': [50, 100, 150],\n",
    "    'classifier__max_depth': [None, 5, 10, 15],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__bootstrap': [True, False],\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV ile pipeline'i uygula, modeli egit ve en iyi parametreleri bul.\n",
    "random_search = RandomizedSearchCV(pipeline, # Model icin olusturulan pipeline'dir. \n",
    "                                   param_distributions=param_distributions, # Hiperparametreler.\n",
    "                                   n_iter=10, # Searching isleminin ne kadar genis veya kisitli olacagini kontrol etmenize olanak tanir.\n",
    "                                   cv=5, # Dataset'imizin kac parcaya bolunup, her bir parcadan test icin kac parcanin kullanilacagini belirler. \n",
    "                                   random_state=42,\n",
    "                                   n_jobs=-1, # Tum cpu'larin kullanilmasini saglar.\n",
    "                                   error_score='raise') \n",
    "# Modeli Egit.\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbab7b02-b44b-45f4-b5e6-1268c0f1b50d",
   "metadata": {},
   "source": [
    "## Model Results:\n",
    "GridSearchCV()'nin en iyi model ve parametre olarak neleri sectigini gorelim ve prediction sonuclarina bakalim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8949fdc2-5681-41c6-8968-0f84689387d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'classifier__n_estimators': 50, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 2, 'classifier__max_depth': 15, 'classifier__bootstrap': False}\n",
      "Best Score:  0.6850863573765603\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameters: ', random_search.best_params_) # En iyi parametreler.\n",
    "print('Best Score: ', random_search.best_score_) # En iyi score.\n",
    "\n",
    "# Test seti uzerinde en iyi modeli kullanarak prediction islemi:\n",
    "y_pred = random_search.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d387d575-eb17-4743-91b3-5b73031613da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Sonucu ile prediction'lari Karsilastir.\n",
    "y_test_in = le.inverse_transform(y_test)\n",
    "y_pred_in = le.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b2fce77b-7ba6-46f5-a841-2d8800c76a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.6934673366834171\n",
      "Precision Score:  [0.84263959 0.65964912 0.52173913]\n",
      "Recall Score:  0.6934673366834171\n",
      "F1 Score:  0.685963028893356\n",
      "Mean Squared Error: 0.5175879396984925\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, mean_squared_error\n",
    "\n",
    "# Training Sonuclari:\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average=None)\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print('Accuracy Score: ', accuracy)\n",
    "print('Precision Score: ', precision)\n",
    "print('Recall Score: ', recall)\n",
    "print('F1 Score: ', f1)\n",
    "# y_pred ile y_test arasindaki hata miktari:\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c341ad2-6de7-47b3-aaff-256470c4e66b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoc:0, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:1, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:2, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:3, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:4, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:5, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:6, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:7, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:8, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:9, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:10, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:11, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:12, Predicted:F, Model Prediction:H, Correct: False\n",
      "Epoc:13, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:14, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:15, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:16, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:17, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:18, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:19, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:20, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:21, Predicted:F, Model Prediction:H, Correct: False\n",
      "Epoc:22, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:23, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:24, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:25, Predicted:H, Model Prediction:F, Correct: False\n",
      "Epoc:26, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:27, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:28, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:29, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:30, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:31, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:32, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:33, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:34, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:35, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:36, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:37, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:38, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:39, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:40, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:41, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:42, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:43, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:44, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:45, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:46, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:47, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:48, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:49, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:50, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:51, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:52, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:53, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:54, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:55, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:56, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:57, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:58, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:59, Predicted:H, Model Prediction:F, Correct: False\n",
      "Epoc:60, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:61, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:62, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:63, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:64, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:65, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:66, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:67, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:68, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:69, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:70, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:71, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:72, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:73, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:74, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:75, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:76, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:77, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:78, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:79, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:80, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:81, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:82, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:83, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:84, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:85, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:86, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:87, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:88, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:89, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:90, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:91, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:92, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:93, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:94, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:95, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:96, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:97, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:98, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:99, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:100, Predicted:F, Model Prediction:H, Correct: False\n",
      "Epoc:101, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:102, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:103, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:104, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:105, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:106, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:107, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:108, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:109, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:110, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:111, Predicted:F, Model Prediction:H, Correct: False\n",
      "Epoc:112, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:113, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:114, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:115, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:116, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:117, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:118, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:119, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:120, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:121, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:122, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:123, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:124, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:125, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:126, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:127, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:128, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:129, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:130, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:131, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:132, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:133, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:134, Predicted:T, Model Prediction:F, Correct: False\n",
      "Epoc:135, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:136, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:137, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:138, Predicted:F, Model Prediction:H, Correct: False\n",
      "Epoc:139, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:140, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:141, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:142, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:143, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:144, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:145, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:146, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:147, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:148, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:149, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:150, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:151, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:152, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:153, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:154, Predicted:F, Model Prediction:H, Correct: False\n",
      "Epoc:155, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:156, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:157, Predicted:F, Model Prediction:H, Correct: False\n",
      "Epoc:158, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:159, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:160, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:161, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:162, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:163, Predicted:F, Model Prediction:H, Correct: False\n",
      "Epoc:164, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:165, Predicted:T, Model Prediction:F, Correct: False\n",
      "Epoc:166, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:167, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:168, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:169, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:170, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:171, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:172, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:173, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:174, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:175, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:176, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:177, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:178, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:179, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:180, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:181, Predicted:H, Model Prediction:F, Correct: False\n",
      "Epoc:182, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:183, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:184, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:185, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:186, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:187, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:188, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:189, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:190, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:191, Predicted:H, Model Prediction:F, Correct: False\n",
      "Epoc:192, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:193, Predicted:F, Model Prediction:H, Correct: False\n",
      "Epoc:194, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:195, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:196, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:197, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:198, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:199, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:200, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:201, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:202, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:203, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:204, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:205, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:206, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:207, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:208, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:209, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:210, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:211, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:212, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:213, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:214, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:215, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:216, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:217, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:218, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:219, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:220, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:221, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:222, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:223, Predicted:F, Model Prediction:H, Correct: False\n",
      "Epoc:224, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:225, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:226, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:227, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:228, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:229, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:230, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:231, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:232, Predicted:F, Model Prediction:H, Correct: False\n",
      "Epoc:233, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:234, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:235, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:236, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:237, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:238, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:239, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:240, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:241, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:242, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:243, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:244, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:245, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:246, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:247, Predicted:T, Model Prediction:F, Correct: False\n",
      "Epoc:248, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:249, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:250, Predicted:H, Model Prediction:F, Correct: False\n",
      "Epoc:251, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:252, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:253, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:254, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:255, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:256, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:257, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:258, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:259, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:260, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:261, Predicted:T, Model Prediction:F, Correct: False\n",
      "Epoc:262, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:263, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:264, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:265, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:266, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:267, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:268, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:269, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:270, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:271, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:272, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:273, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:274, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:275, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:276, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:277, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:278, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:279, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:280, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:281, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:282, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:283, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:284, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:285, Predicted:F, Model Prediction:H, Correct: False\n",
      "Epoc:286, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:287, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:288, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:289, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:290, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:291, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:292, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:293, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:294, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:295, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:296, Predicted:F, Model Prediction:H, Correct: False\n",
      "Epoc:297, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:298, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:299, Predicted:H, Model Prediction:F, Correct: False\n",
      "Epoc:300, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:301, Predicted:H, Model Prediction:F, Correct: False\n",
      "Epoc:302, Predicted:T, Model Prediction:F, Correct: False\n",
      "Epoc:303, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:304, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:305, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:306, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:307, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:308, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:309, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:310, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:311, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:312, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:313, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:314, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:315, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:316, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:317, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:318, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:319, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:320, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:321, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:322, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:323, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:324, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:325, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:326, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:327, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:328, Predicted:T, Model Prediction:F, Correct: False\n",
      "Epoc:329, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:330, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:331, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:332, Predicted:T, Model Prediction:F, Correct: False\n",
      "Epoc:333, Predicted:F, Model Prediction:H, Correct: False\n",
      "Epoc:334, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:335, Predicted:T, Model Prediction:F, Correct: False\n",
      "Epoc:336, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:337, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:338, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:339, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:340, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:341, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:342, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:343, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:344, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:345, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:346, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:347, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:348, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:349, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:350, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:351, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:352, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:353, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:354, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:355, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:356, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:357, Predicted:T, Model Prediction:F, Correct: False\n",
      "Epoc:358, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:359, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:360, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:361, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:362, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:363, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:364, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:365, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:366, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:367, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:368, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:369, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:370, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:371, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:372, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:373, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:374, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:375, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:376, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:377, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:378, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:379, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:380, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:381, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:382, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:383, Predicted:T, Model Prediction:F, Correct: False\n",
      "Epoc:384, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:385, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:386, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:387, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:388, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:389, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:390, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:391, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:392, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:393, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:394, Predicted:H, Model Prediction:F, Correct: False\n",
      "Epoc:395, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:396, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:397, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:398, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:399, Predicted:H, Model Prediction:F, Correct: False\n",
      "Epoc:400, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:401, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:402, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:403, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:404, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:405, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:406, Predicted:F, Model Prediction:H, Correct: False\n",
      "Epoc:407, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:408, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:409, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:410, Predicted:H, Model Prediction:F, Correct: False\n",
      "Epoc:411, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:412, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:413, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:414, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:415, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:416, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:417, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:418, Predicted:F, Model Prediction:H, Correct: False\n",
      "Epoc:419, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:420, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:421, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:422, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:423, Predicted:H, Model Prediction:F, Correct: False\n",
      "Epoc:424, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:425, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:426, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:427, Predicted:T, Model Prediction:F, Correct: False\n",
      "Epoc:428, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:429, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:430, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:431, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:432, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:433, Predicted:F, Model Prediction:H, Correct: False\n",
      "Epoc:434, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:435, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:436, Predicted:T, Model Prediction:F, Correct: False\n",
      "Epoc:437, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:438, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:439, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:440, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:441, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:442, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:443, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:444, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:445, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:446, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:447, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:448, Predicted:F, Model Prediction:H, Correct: False\n",
      "Epoc:449, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:450, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:451, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:452, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:453, Predicted:H, Model Prediction:F, Correct: False\n",
      "Epoc:454, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:455, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:456, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:457, Predicted:F, Model Prediction:H, Correct: False\n",
      "Epoc:458, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:459, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:460, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:461, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:462, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:463, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:464, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:465, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:466, Predicted:F, Model Prediction:H, Correct: False\n",
      "Epoc:467, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:468, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:469, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:470, Predicted:H, Model Prediction:F, Correct: False\n",
      "Epoc:471, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:472, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:473, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:474, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:475, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:476, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:477, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:478, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:479, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:480, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:481, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:482, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:483, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:484, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:485, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:486, Predicted:H, Model Prediction:F, Correct: False\n",
      "Epoc:487, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:488, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:489, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:490, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:491, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:492, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:493, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:494, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:495, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:496, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:497, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:498, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:499, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:500, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:501, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:502, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:503, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:504, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:505, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:506, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:507, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:508, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:509, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:510, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:511, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:512, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:513, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:514, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:515, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:516, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:517, Predicted:T, Model Prediction:F, Correct: False\n",
      "Epoc:518, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:519, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:520, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:521, Predicted:T, Model Prediction:F, Correct: False\n",
      "Epoc:522, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:523, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:524, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:525, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:526, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:527, Predicted:T, Model Prediction:F, Correct: False\n",
      "Epoc:528, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:529, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:530, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:531, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:532, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:533, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:534, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:535, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:536, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:537, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:538, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:539, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:540, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:541, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:542, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:543, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:544, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:545, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:546, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:547, Predicted:F, Model Prediction:H, Correct: False\n",
      "Epoc:548, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:549, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:550, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:551, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:552, Predicted:F, Model Prediction:H, Correct: False\n",
      "Epoc:553, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:554, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:555, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:556, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:557, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:558, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:559, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:560, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:561, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:562, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:563, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:564, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:565, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:566, Predicted:T, Model Prediction:F, Correct: False\n",
      "Epoc:567, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:568, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:569, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:570, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:571, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:572, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:573, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:574, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:575, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:576, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:577, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:578, Predicted:T, Model Prediction:H, Correct: False\n",
      "Epoc:579, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:580, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:581, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:582, Predicted:H, Model Prediction:T, Correct: False\n",
      "Epoc:583, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:584, Predicted:T, Model Prediction:F, Correct: False\n",
      "Epoc:585, Predicted:F, Model Prediction:T, Correct: False\n",
      "Epoc:586, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:587, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:588, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:589, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:590, Predicted:T, Model Prediction:T, Correct: True\n",
      "Epoc:591, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:592, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:593, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:594, Predicted:H, Model Prediction:H, Correct: True\n",
      "Epoc:595, Predicted:F, Model Prediction:F, Correct: True\n",
      "Epoc:596, Predicted:H, Model Prediction:T, Correct: False\n"
     ]
    }
   ],
   "source": [
    "# Modelimizin test data'larina ne tur cevaplar verdigini iterative olarak gormek icin:\n",
    "for i in range(len(y_test)):\n",
    "    print(f\"Epoc:{i}, Predicted:{y_test_in[i]}, Model Prediction:{y_pred_in[i]}, Correct: {y_test_in[i] == y_pred_in[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda646b5-c89f-4107-8e48-2d240c70e8fd",
   "metadata": {},
   "source": [
    "## Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e945f884-5da4-433b-9cee-31de28a519b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqgAAAIlCAYAAAAZlgpaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB0Q0lEQVR4nO3dd1xV9RsH8M9hXTYylAvJUnGgOCEVB7hAcY80TQV3Oco9MhXLnau0LCfOtEzNLFPcKWaI4sSNggriQJbIuuf3Bz9uHhle9MK9wOf9ep1X3nO+53uei4QPz3dcQRRFEUREREREWkJH0wEQEREREb2KCSoRERERaRUmqERERESkVZigEhEREZFWYYJKRERERFqFCSoRERERaRUmqERERESkVZigEhEREZFWYYJKRERERFqFCSoRlQmJiYkYPXo0nJycoKenB0EQcPfu3WJ9piAI8PHxKdZnlGU+Pj4QBEHTYRCRFmKCSkRvJTw8HEOGDIGrqytMTExgZGSEqlWrYsCAAQgJCSnxeCZNmoTvvvsO9evXx+eff45Zs2ahQoUKJR6Hpty9exeCIEAQBLz33nvIzs7Ot92lS5eU7WrWrPlOzwwMDCyRXwSIqPzR03QARFS6KBQKTJw4EcuWLYOenh5at26NLl26QF9fH3fu3MEff/yBLVu24Msvv8SMGTNKLK4///wTNWrUwG+//VZiz4yMjISxsXGJPU8Venp6ePjwIQ4cOAB/f/8819etWwc9PT1kZWVpIDqpTZs24cWLF5oOg4i0EBNUIiqSL774AsuWLUP9+vWxc+dOVK1aVXI9LS0NK1euxNOnT0s0rocPH6Jly5Yl+sx3rUAWBy8vL1y4cAHr16/Pk6BmZGRg69at8Pf3x969ezUU4X8cHR01HQIRaSkO8RORym7duoVFixbB2toaf/31V57kFACMjIwwadIkzJ49W3L+6dOnGDduHFxcXCCTyVCpUiX06dMHV69ezdPHq0PH33//PWrVqgVDQ0M4OTlh9uzZUCgUedqKoojjx48rh68DAwPz9PW6oKAgCIKAY8eOSc7/+uuv8Pb2RqVKlWBoaAgHBwe0b98ee/bskbQraA5qcb1XVRgZGaFPnz74/fff8eTJE8m1vXv34smTJxg0aFC+9z58+BCzZs1CkyZNUKlSJchkMjg7O2PkyJGIj4+XtHV2dsbGjRsBAC4uLsqv+6tfj9zXDx48QGBgIORyOXR0dJRf79fnoL58+RLu7u7Q19fHP//8I3leWloa3NzcYGBggLCwsCJ9TYio9GEFlYhUFhwcjOzsbIwYMQK2traFtpXJZMo/P336FE2aNMGtW7fg4+ODDz/8EHfv3sXOnTvxxx9/ICQkBE2bNs3Tx6RJk3Ds2DF06tQJvr6+2LNnD4KCgpCRkYG5c+cCALp16wZnZ2fMnj0bTk5OysS0fv36b/UeV61ahZEjR8LOzg7du3eHtbU1YmNj8e+//2LPnj3o1q1bofcX53tV1eDBg7F69Wps3boVn332mfL8+vXrUalSJXTq1Cnf+06cOIElS5agTZs2aNy4MfT19XH+/HmsWrUKBw4cwLlz52BhYQEAGDt2LIKDg3HhwgV89tlnyvm+zs7Oeb4eTZs2hZWVFfr06YOMjAyYm5vn+3xDQ0P89NNP8PT0RL9+/RAREaFsO27cOERGRmL+/Pnw9PQs0teDiEohkYhIRT4+PiIA8dChQ0W6b/DgwSIAcdq0aZLzf/31lwhAdHV1FbOzs5XnAwICRACii4uL+PDhQ+X5x48fixUqVBDNzMzE9PR0SV8ARG9v7zzPzu0rKioqz7VZs2aJAMSjR48qzzVs2FA0MDAQ4+Pj87R/8uTJG59ZEu81P1FRUSIA0c/PTxRFUaxdu7ZYt25d5fX79++Lurq64oQJE5Sx16hRQ9LHo0ePxOTk5Dx9b9y4UQQgzpkzR3K+sK9t7jMAiIMGDRKzsrLyXPf29hbz+2do5cqVIgCxX79+oiiK4p49e0QAYqtWrSRfOyIquzjET0Qqi4uLAwBUrlxZ5XsyMjLw008/wdraGl988YXkmp+fH/z8/HDz5k2EhobmuXfGjBmws7NTvraxsUHXrl2RnJyM69evv+W7eDN9fX3o6+vnOW9tbV3ofdr0XgcNGoSLFy8iPDwcwH/V78GDBxd4T6VKlWBqaprn/IABA2Bubo5Dhw4VOQ4DAwMsWrQIurq6Kt8zatQodO7cGdu2bcOiRYswZMgQWFlZYdOmTdDR4T9bROUB/08nomJ17do1pKWl4f333893xXvunMWIiIg81xo2bJjnXG5y/Pz5c3WGqdS7d2+kpqaiTp06mDhxIvbt26fys7TpvQ4YMAD6+vpYv349gJwEtXHjxnBzcyv0vl27dsHPzw8VK1ZU7iero6ODpKQkPHz4sMhxuLi4wMbGpsj3rV+/HnZ2dpgyZQqePn2KNWvWFOkXIyIq3ZigEpHK5HI5AODBgwcq35OUlAQABc5Zze0zMTExz7Xc+Y6v0tPLmTpf0D6f72ry5MlYs2YN5HI5li5dis6dO6NixYro2rUroqKiCr1Xm95rpUqV4O/vj59++gkHDhzArVu3ClwclWvJkiXo2bMnzp8/D19fX0yYMAGzZs3CrFmzYGFhgfT09CLH8aa5ygWxsbFBixYtAABOTk7o0qXLW/VDRKUTE1QiUlmzZs0AAIcPH1b5ntxFLo8ePcr3eu75ghbOvKvcIeH89v3ML1EUBAFDhw7F2bNn8fjxY+zevRs9evTA3r170bFjx0KTRU2/19cNHjwYCQkJGDJkCIyMjNC3b98C22ZlZeGrr76Cvb09rly5gq1bt2LhwoUICgrCrFmzkJGR8VYxvO0nRf3yyy/4+eefYW1tjXv37mHWrFlv1Q8RlU5MUIlIZYGBgdDV1cXq1avx+PHjQtvmVttq1qwJQ0NDhIWF5bsp+/HjxwG8/ar7N7G0tASQf9X3/Pnzhd5rbW2Nbt26YceOHWjdujUiIyNx69atAttr+r2+zt/fH3K5HA8ePEDPnj0LTYyfPHmCxMRENGnSBBUrVpRcO3v2LNLS0vLckzuvVN3V7OjoaAwfPhyVKlVCREQEPDw8sGDBAuXXj4jKPiaoRKSyatWqYfLkyXjy5Ak6dOiQ75D3y5cvsXTpUgQFBQHIWSTTt29fPHnyBPPnz5e0PXToEPbv349q1aopq7Pq5uHhASBnDuardu7cmW/Cc+DAgTzV1szMTDx79gxAzj6jBdH0e32dnp4e9u7di927d79xq6pKlSrByMgI586dkyTXCQkJGDNmTL73WFlZAQDu37+vtpgVCgX69++P58+fIzg4GJUrV8a2bdtgZGSEAQMGICEhQW3PIiLtxX1QiahI5syZg5cvX2LZsmWoUaMGWrdujTp16kBfXx9RUVE4dOgQnj59ijlz5ijvWbhwIY4fP445c+YgNDQUjRs3Vu4NamxsjA0bNhTb6uxu3brBxcUFwcHBiImJQYMGDRAZGYkjR47A398ff/75p6R9nz59YGxsjObNm8PJyQmZmZkICQnB1atX0adPnzd++pEm32t+PD09Vdo3VEdHByNHjsSSJUtQr149dO7cGUlJSdi/fz+cnJxgb2+f557WrVtj8eLFGDFiBD744AOYmJjA0dER/fr1e+t4586di7///huffvopOnToAABwdXXFt99+iyFDhmD48OH45Zdf3rp/IiolNL3PFRGVTmFhYeLgwYPFatWqiUZGRqJMJhOdnZ3Fvn37igcPHszT/vHjx+Knn34qOjk5ifr6+qKNjY3Yq1cv8dKlS3naFnXvUlEseB9UURTFO3fuiF27dhXNzMxEExMTsU2bNmJYWFi+fX3//fdily5dRCcnJ9HQ0FC0trYWGzduLP74449iZmamSs8s7vean9f3QX0T5LMPakZGhjh37lzR1dVVlMlkoqOjozh+/HgxOTlZdHJyEp2cnPL0s2jRItHV1VXU19fP8/Uo7O9EFPPug3r69GlRT09PrFOnjpiWlpanfa9evUQA4po1a1R6j0RUegmiKIoayYyJiIiIiPLBOahEREREpFWYoBIRERGRVmGCSkRERERahQkqEREREWkVJqhEREREpFWYoBIRERGRVuFG/WWQQqHAw4cPYWZm9tafg01ERFReiKKI5ORk2Nvbl+gHaeR6+fIlMjIyiqVvAwMDGBoaFkvfxYkJahn08OFDODg4aDoMIiKiUiUmJgaVK1cu0We+fPkSLk6miIvPLpb+5XI5oqKiSl2SygS1DDIzMwMArDpRB0amuhqOhsqyza3rajoEKg8MZJqOgMq4LEUGjj/ZpPz3syRlZGQgLj4b98KdYW6m3uptUrICTo3uIiMjgwkqaV7usL6RqS6MzZigUvHREww0HQKVBzr8PqOSoclpcaZmAkzN1Pt8BUrvND8mqEREREQali0qkK3mD5/PFhXq7bAEcRU/EREREWkVVlCJiIiINEwBEQqot4Sq7v5KEiuoRERERKRVWEElIiIi0jAFFFD3jFH191hyWEElIiIiIq3CCioRERGRhmWLIrJF9c4ZVXd/JYkVVCIiIiLSKqygEhEREWkYV/FLMUElIiIi0jAFRGQzQVXiED8RERERaRVWUImIiIg0jEP8UqygEhEREZFWYQWViIiISMO4zZQUK6hEREREBAA4ceIEOnfuDHt7ewiCgD179kiup6SkYPTo0ahcuTKMjIxQq1YtrFq1StImPT0dY8aMgY2NDUxMTNClSxfcv3+/SHEwQSUiIiLSMEUxHUWVmpqKevXqYeXKlfleHzduHP766y9s2bIFkZGRGDduHMaMGYPffvtN2Wbs2LHYvXs3tm/fjpMnTyIlJQWdOnVCdna2ynFwiJ+IiIiIAAAdOnRAhw4dCrx++vRpBAQEwMfHBwAwfPhw/Pjjjzh79iy6du2KxMRErFu3Dps3b0bbtm0BAFu2bIGDgwMOHToEPz8/leJgBZWIiIhIw7L/vw+qug8ASEpKkhzp6elvHWfz5s2xd+9ePHjwAKIo4ujRo7hx44Yy8QwPD0dmZiZ8fX2V99jb26NOnToIDQ1V+TlMUImIiIg0LFssngMAHBwcYGFhoTzmz5//1nF+++23cHNzQ+XKlWFgYID27dvj+++/R/PmzQEAcXFxMDAwgKWlpeQ+W1tbxMXFqfwcDvETERERlWExMTEwNzdXvpbJZG/d17fffot//vkHe/fuhZOTE06cOIGRI0fCzs5OOaSfH1EUIQiCys9hgkpERESkYW+7qOlNfQKAubm5JEF9W2lpafj888+xe/dudOzYEQBQt25dREREYPHixWjbti3kcjkyMjKQkJAgqaLGx8fDy8tL5WdxiJ+IiIiI3igzMxOZmZnQ0ZGmj7q6ulAoctLhRo0aQV9fHyEhIcrrsbGxuHz5cpESVFZQiYiIiDRMAQHZUH0IXNU+iyolJQW3bt1Svo6KikJERASsrKzg6OgIb29vTJo0CUZGRnBycsLx48exadMmLF26FABgYWGBIUOGYMKECbC2toaVlRUmTpwId3f3QqcAvI4JKhEREREBAM6ePYtWrVopX48fPx4AEBAQgODgYGzfvh3Tpk3DRx99hGfPnsHJyQlz587Fxx9/rLxn2bJl0NPTQ+/evZGWloY2bdogODgYurq6KsfBBJWIiIhIwxRizqHuPovKx8cHYiEfkSqXy7Fhw4ZC+zA0NMSKFSuwYsWKogfwf5yDSkRERERahRVUIiIiIg3LLoY5qOruryQxQSUiIiLSMCaoUhziJyIiIiKtwgoqERERkYYpRAEKUc3bTKm5v5LECioRERERaRVWUImIiIg0jHNQpVhBJSIiIiKtwgoqERERkYZlQwfZaq4bZqu1t5LFCioRERERaRVWUImIiIg0TCyGVfxiKV7FzwSViIiISMO4SEqKQ/xEREREpFVYQSUiIiLSsGxRB9mimhdJiWrtrkSxgkpEREREWoUVVCIiIiINU0CAQs11QwVKbwmVFVQiIiIi0iqsoBIRERFpGFfxS7GCSkRERERahRVUIiIiIg0rnlX8pXcOKhNUIiIiIg3LWSSl3iF5dfdXkjjET0RERERahRVUIiIiIg1TQAfZ3GZKiRVUIiIiItIqrKASERERaRgXSUmxgkpEREREWoUVVCIiIiINU0CHH3X6ClZQiYiIiEirsIJKREREpGHZooBsUc0fdarm/koSE1QiIiIiDcsuhm2msjnET0RERESkHqygEhEREWmYQtSBQs3bTCm4zRQRERERkXqwgkpERESkYZyDKsUKKhERERFpFVZQiYiIiDRMAfVvC6VQa28lixVUIiIiItIqrKASERERaVjxfNRp6a1DMkElIiIi0rBsUQfZat5mSt39laTSGzkRERERlUmsoBIRERFpmAICFFD3Iin19leSWEElIiIiIq3CBJWIiIhIw3LnoKr7KKoTJ06gc+fOsLe3hyAI2LNnT542kZGR6NKlCywsLGBmZoYmTZogOjpaeT09PR1jxoyBjY0NTExM0KVLF9y/f79IcXCIn8qs2DBDXFhrgSdXZHgRrwff7+Lg3O6FpE3CLX2cWWyF2H+NABGwrJaBtt88gql9trLNo/MyhC2zQvwFGXT0RFjXykCHtXHQMyy9n9BBxaf3sGh4tX2CylXSkPFSB5ER5li/xAUP7hoDAHT1FBj46V14tnwGeeWXSE3RQ8TpCtiw1AXPHss0HD2VFr0HR8GrdTwqO6ciI10HkRcqYP03rnhwz0TZZtzsy2jXJVZy37WLFhgf8H5Jh0ulSGpqKurVq4dBgwahZ8+eea7fvn0bzZs3x5AhQzB79mxYWFggMjIShoaGyjZjx47F77//ju3bt8Pa2hoTJkxAp06dEB4eDl1dXZXiKPUJqo+PD+rXr4/ly5drOhSlu3fvwsXFBefPn0f9+vVVuicwMBDPnz/P9zcVejuZLwRY18xAjR7JCBkjz3M9KVoPe/vZo0avZHh8mgADUwWe39aHruy/xPPReRn+HGKHBiMS4DXjCXT1RTy9JoOgw+SU8lfHIxH7frLHjctm0NUVEfDZXcxdewkjOnsgPU0XMkMFqrml4KcfnHDnmglMzbMwYtptzPruCj7r3VDT4VMpUadhAvbtcMCNK+bQ1RMRMOoW5q46hxE9vJD+8r8E4OwpayybVVv5OjOTA6faqng+6rTo/XXo0AEdOnQo8Pr06dPh7++PRYsWKc9VqVJF+efExESsW7cOmzdvRtu2bQEAW7ZsgYODAw4dOgQ/Pz+V4ig1CWpgYCA2btyY5/yZM2dQq1YtDURUMAcHB8TGxsLGxkbToZRrjt5pcPROK/D6v0ut4NDyBZpMfqY8Z+6YJWlzep416gxMRP0RicpzFs7SNkSvmjnCXfJ66fTq2H7qH7i6JeNyeAW8SNHD9KF1JW1Wza2Gb34+j4p2L/E41hBEbzJztPSXmaVBtbH9yHG4uiXh8jlL5fnMDB0kPGVlvrxLSkqSvJbJZJDJiv59oVAo8Mcff2Dy5Mnw8/PD+fPn4eLigmnTpqFbt24AgPDwcGRmZsLX11d5n729PerUqYPQ0FCVE9RS9atU+/btERsbKzkaNWoEMzMzTYcmoaurC7lcDj29UpP/lzuiAog5bowKLpn4c7Acm5o4YXcve9wNMVa2SXuqg/gLhjCyysZvfeyxuakjfv/IDnFn+cOeVGdiljNdJDlRv5A2WVAogJQk/sygt2NimvOL8+vfZ+4eCdh2+BjW7DmFT2dchYVlhibCIxUoRKFYDiCncGZhYaE85s+f/1YxxsfHIyUlBQsWLED79u1x8OBBdO/eHT169MDx48cBAHFxcTAwMIClpaXkXltbW8TFxan8rFKVoMpkMsjlcsnRpk0bjB07VtnG2dkZ8+bNw+DBg2FmZgZHR0esXr1a0s+UKVNQvXp1GBsbo0qVKpgxYwYyMzOV14OCglC/fn1s3rwZzs7OsLCwwIcffojk5GRlG4VCgYULF6JatWqQyWRwdHTE3LlzAeQM8QuCgIiICABAdnY2hgwZAhcXFxgZGaFGjRr45ptvCn2vO3fuhLu7O4yMjGBtbY22bdsiNTX1Hb+ClCvtqS4yU3UQsboCKrdIg//6WLi0S8XB0bZ4+G9OBSspJucHffhKS9TsnYQO6+JgXTsD+wLskXiXiQSpQsSwybdxOdwc926Z5NtC30CBQeOicOyPSkhL5fcVvQ0RwyZcx+VzFXDvtqnybPgpG3z9eR1MG+6BNUurw7V2IuavPgs9/dL8Ce30NmJiYpCYmKg8pk2b9lb9KBQ53ztdu3bFuHHjUL9+fUydOhWdOnXCDz/8UOi9oihCEFTf9qpM/jRcsmQJvvrqK3z++efYuXMnPvnkE7Rs2RI1a9YEAJiZmSE4OBj29va4dOkShg0bBjMzM0yePFnZx+3bt7Fnzx7s27cPCQkJ6N27NxYsWKBMQqdNm4Y1a9Zg2bJlaN68OWJjY3Ht2rV841EoFKhcuTJ+/vln2NjYIDQ0FMOHD4ednR169+6dp31sbCz69u2LRYsWoXv37khOTsbff/8NUcx/3mN6ejrS09OVr18v5VNe4v9/Pju1eYG6g3KG723cMhB33hCRP5nD/v2Xyja1+iShRs+U/7d5ioenDXF9pxnen5igidCpFBn5xS241EjFxP71872uq6fA1CWREHSA776sVrLBUZkxcuo1uLimYOIgT8n5Ewf/m3t/77Ypbl41R/Cff+P9Fo8ResS2pMOkN1AUwxzU3I86NTc3h7m5+Tv3Z2NjAz09Pbi5uUnO16pVCydPngQAyOVyZGRkICEhQVJFjY+Ph5eXl8rPKlUJ6r59+2Bq+t9vhwVN4vX398fIkSMB5FRLly1bhmPHjikT1C+++ELZ1tnZGRMmTMCOHTskCapCoUBwcLBy+sCAAQNw+PBhzJ07F8nJyfjmm2+wcuVKBAQEAACqVq2K5s2b5xuPvr4+Zs+erXzt4uKC0NBQ/PzzzwUmqFlZWejRowecnJwAAO7u7nna5Zo/f76kf3ozQ8tsCHoiLKtJh7ssq2YiLjyngmpcMWdo1rJapqRNhSqZSIktVf/rkAZ8PP0WGrd6iskD6+Hpo7zTQnT1FJi2NBK2773EtEF1WT2lt/LxlGto7P0Yk4d44ml84fOXE57IEB9rCHvHF4W2I81QiDpQqPmjSdXdn4GBATw9PXH9+nXJ+Rs3bijzlUaNGkFfXx8hISHKHCc2NhaXL1+WLKx6k1L1E7FVq1ZYtWqV8rWJiQn69u2bp13duv8tQBAEAXK5HPHx8cpzO3fuxPLly3Hr1i2kpKQgKysrz28Wzs7OkrmtdnZ2yj4iIyORnp6ONm3aqBz7Dz/8gLVr1+LevXtIS0tDRkZGgSv869WrhzZt2sDd3R1+fn7w9fVFr1698sznyDVt2jSMHz9e+TopKQkODg4qx1Ye6RoAldzT8fyOdL5WYpQ+TO1z5nKZVc6CcaUsPI96rc1dfTi05A94KoiIT6bfRtO2TzA1sB4ePTDK0yI3ObV3SsPUwLqFzk8lyp+IT6ZcR9PW8Zg6rBEePcz7ffY6M4sMVLRNx7MnnEdPBUtJScGtW7eUr6OiohAREQErKys4Ojpi0qRJ6NOnD1q2bIlWrVrhr7/+wu+//45jx44BACwsLDBkyBBMmDAB1tbWsLKywsSJE+Hu7q5c1a+KUjUH1cTEBNWqVVMednZ2+bbT15f+sBcEQTlv4p9//sGHH36IDh06YN++fTh//jymT5+OjIwMlfswMnrzD4JX/fzzzxg3bhwGDx6MgwcPIiIiAoMGDcrzzFy6uroICQnB/v374ebmhhUrVqBGjRqIiorKt71MJlOW79VVxi8LMlMFPLlqgCdXDQAASff18eSqAVIe5mzBUnfIc9zZb4rIHWZIvKeHy5vNce+oMWr3yxnyFwSg3tDnuLzJAnf+MkHiPT2ELbfE8zv6qPlBcoHPpfJt5IxbaNX5ERZNqom0VF1Y2mTA0iYDBrKciryOrojPl0fCtXYyvp5cE7q6ULbh3EBS1chp19CqYywWfV4Haal6sLROh6V1uvL7zNAoC0PG3UDNus9RyS4N7o2eYdY3EUh6ro/TRyppOHrKTzaEYjmK6uzZs2jQoAEaNGgAABg/fjwaNGiAmTNnAgC6d++OH374AYsWLYK7uzvWrl2LX3/9VTKKvGzZMnTr1g29e/dGs2bNYGxsjN9//13lPVCBUlZBVYdTp07ByckJ06dPV567d+9ekfpwdXWFkZERDh8+jKFDh76x/d9//w0vLy/ltAMgZ45rYQRBQLNmzdCsWTPMnDkTTk5O2L17t6RSSoV7fFmGfQPsla//mW8NAKjePRk+Cx/DxfcFms9+gogfKyB0jjUquGSi3YpHkHv8N5/XPTAJ2ekCTs+zRnqiDqxrZqDjhtg821ER5erUN2dj9EWbLkrOL/28Og7tkcPGNh1NWz8FAHy3+5ykzZSAurgUVqFE4qTSrVPvnE/lWbQ2XHJ+6czaOPS7PRQKAc7VUtCm00OYmGUh4YkMF8IssWBKXaS9KHf/9FMR+Pj4FLjmJdfgwYMxePDgAq8bGhpixYoVWLFixVvHUe6+S6tVq4bo6Ghs374dnp6e+OOPP7B79+4i9WFoaIgpU6Zg8uTJMDAwQLNmzfD48WNcuXIFQ4YMyfeZmzZtwoEDB+Di4oLNmzcjLCwMLi4u+fZ/5swZHD58GL6+vqhUqRLOnDmDx48fa91+r9rOvvFLDL9xp9A2NXslo2avwquh9UdI90ElKoy/W8tCr8c/NHxjG6I38W/QrtDrGem6mDGKH/xQmpSGOaglqdwlqLlbI4wePRrp6eno2LEjZsyYgaCgoCL1M2PGDOjp6WHmzJl4+PAh7Ozs8PHHH+fb9uOPP0ZERAT69OkDQRDQt29fjBw5Evv378+3vbm5OU6cOIHly5cjKSkJTk5OWLJkSaGf7EBERERUVgjim+q4VOokJSXBwsICwefqwdhM9fkeREW17v0Gmg6ByoO3+MQboqLIUmTgcPxaJCYmlvg6jtx/s2eeaQtDU/UumHyZkokvGx/SyPt6V6W39ktEREREZVK5G+InIiIi0jacgyrFBJWIiIhIw7JFHWSrOaFUd38lqfRGTkRERERlEiuoRERERBomQoDiLTbWf1OfpRUrqERERESkVVhBJSIiItIwzkGVKr2RExEREVGZxAoqERERkYYpRAEKUb1zRtXdX0liBZWIiIiItAorqEREREQalg0dZKu5bqju/koSE1QiIiIiDeMQv1TpTa2JiIiIqExiBZWIiIhIwxTQgULNdUN191eSSm/kRERERFQmsYJKREREpGHZooBsNc8ZVXd/JYkVVCIiIiLSKqygEhEREWkYV/FLsYJKRERERFqFFVQiIiIiDRNFHShE9dYNRTX3V5KYoBIRERFpWDYEZEPNi6TU3F9JKr2pNRERERGVSaygEhEREWmYQlT/oiaFqNbuShQrqERERESkVVhBJSIiItIwRTEsklJ3fyWp9EZORERERGUSK6hEREREGqaAAIWaV92ru7+SxAoqEREREWkVVlCJiIiINCxbFJCt5lX86u6vJDFBJSIiItIwLpKSKr2RExEREVGZxAoqERERkYYpIKh/o34ukiIiIiIiUg9WUImIiIg0TCyGbaZEVlCJiIiIiNSDFVQiIiIiDVOIxTAHtRRvM8UKKhERERFpFVZQiYiIiDSM+6BKMUElIiIi0jAO8UuV3tSaiIiIiNTqxIkT6Ny5M+zt7SEIAvbs2VNg2xEjRkAQBCxfvlxyPj09HWPGjIGNjQ1MTEzQpUsX3L9/v0hxMEElIiIi0jDF/7eZUvdRVKmpqahXrx5WrlxZaLs9e/bgzJkzsLe3z3Nt7Nix2L17N7Zv346TJ08iJSUFnTp1QnZ2tspxcIifiIiIiAAAHTp0QIcOHQpt8+DBA4wePRoHDhxAx44dJdcSExOxbt06bN68GW3btgUAbNmyBQ4ODjh06BD8/PxUioMVVCIiIiINy52Dqu4DAJKSkiRHenr628epUGDAgAGYNGkSateuned6eHg4MjMz4evrqzxnb2+POnXqIDQ0VOXnMEElIiIiKsMcHBxgYWGhPObPn//WfS1cuBB6enr49NNP870eFxcHAwMDWFpaSs7b2toiLi5O5edwiJ+IiIhIw4pzFX9MTAzMzc2V52Uy2Vv1Fx4ejm+++Qbnzp2DIBQtVlEUi3QPK6hEREREZZi5ubnkeNsE9e+//0Z8fDwcHR2hp6cHPT093Lt3DxMmTICzszMAQC6XIyMjAwkJCZJ74+PjYWtrq/KzmKASERERaVhxzkFVlwEDBuDixYuIiIhQHvb29pg0aRIOHDgAAGjUqBH09fUREhKivC82NhaXL1+Gl5eXys/iED8RERGRhmnLRv0pKSm4deuW8nVUVBQiIiJgZWUFR0dHWFtbS9rr6+tDLpejRo0aAAALCwsMGTIEEyZMgLW1NaysrDBx4kS4u7srV/WrggkqEREREQEAzp49i1atWilfjx8/HgAQEBCA4OBglfpYtmwZ9PT00Lt3b6SlpaFNmzYIDg6Grq6uynEwQSUiIiLSMBF4q43139RnUfn4+EAUVb/z7t27ec4ZGhpixYoVWLFixVtEkINzUImIiIhIq7CCSkRERKRh2jIHVVuwgkpEREREWoUVVCIiIiINYwVVihVUIiIiItIqrKASERERaRgrqFJMUImIiIg0jAmqFIf4iYiIiEirsIJKREREpGGiKEBUc8VT3f2VJFZQiYiIiEirsIJKREREpGEKCGr/qFN191eSWEElIiIiIq3CCioRERGRhnEVvxQrqERERESkVVhBJSIiItIwruKXYgWViIiIiLQKK6hEREREGsY5qFJMUImIiIg0jEP8UhziJyIiIiKtwgpqGRbc0Bl6gr6mw6Ay7MDD45oOgcqBjl5dNB0ClXGCQvOVRrEYhvhZQSUiIiIiUhNWUImIiIg0TAQgiurvs7RiBZWIiIiItAorqEREREQapoAAAWreZkrN/ZUkVlCJiIiISKuwgkpERESkYdwHVYoJKhEREZGGKUQBAj9JSolD/ERERESkVVhBJSIiItIwUSyGbaZK8T5TrKASERERkVZhBZWIiIhIw7hISooVVCIiIiLSKqygEhEREWkYK6hSrKASERERkVZhBZWIiIhIw7gPqhQTVCIiIiIN4zZTUhziJyIiIiKtwgoqERERkYblVFDVvUhKrd2VKFZQiYiIiEirsIJKREREpGHcZkqKFVQiIiIi0iqsoBIRERFpmPj/Q919llasoBIRERERAODEiRPo3Lkz7O3tIQgC9uzZo7yWmZmJKVOmwN3dHSYmJrC3t8fAgQPx8OFDSR/p6ekYM2YMbGxsYGJigi5duuD+/ftFioMJKhEREZGG5c5BVfdRVKmpqahXrx5WrlyZ59qLFy9w7tw5zJgxA+fOncOuXbtw48YNdOnSRdJu7Nix2L17N7Zv346TJ08iJSUFnTp1QnZ2tspxcIifiIiISNO0ZIy/Q4cO6NChQ77XLCwsEBISIjm3YsUKvP/++4iOjoajoyMSExOxbt06bN68GW3btgUAbNmyBQ4ODjh06BD8/PxUioMVVCIiIqIyLCkpSXKkp6erre/ExEQIgoAKFSoAAMLDw5GZmQlfX19lG3t7e9SpUwehoaEq98sElYiIiEjTimN4//9D/A4ODrCwsFAe8+fPV0vIL1++xNSpU9GvXz+Ym5sDAOLi4mBgYABLS0tJW1tbW8TFxancN4f4iYiIiMqwmJgYZQIJADKZ7J37zMzMxIcffgiFQoHvv//+je1FUYQgqD4nVqUENTo6WuUOAcDR0bFI7YmIiIjKs5yPOlV/nwBgbm4uSVDfVWZmJnr37o2oqCgcOXJE0rdcLkdGRgYSEhIkVdT4+Hh4eXmp/AyVElRnZ+ciZb1FWaVFRERERKVDbnJ68+ZNHD16FNbW1pLrjRo1gr6+PkJCQtC7d28AQGxsLC5fvoxFixap/ByVEtT169cXKUElIiIiItVpy0edpqSk4NatW8rXUVFRiIiIgJWVFezt7dGrVy+cO3cO+/btQ3Z2tnJeqZWVFQwMDGBhYYEhQ4ZgwoQJsLa2hpWVFSZOnAh3d3flqn5VqJSgBgYGFu3dEREREVGpc/bsWbRq1Ur5evz48QCAgIAABAUFYe/evQCA+vXrS+47evQofHx8AADLli2Dnp4eevfujbS0NLRp0wbBwcHQ1dVVOY53WiSVlpaGZ8+ewdbWFnp6XG9FRERE9FZeWXWv1j6LyMfHB2Ihk2ELu5bL0NAQK1aswIoVK4r8/Fxvtc3U0aNH0bRpU5iZmcHJyQkXL14EAIwaNQq7du1662CIiIiIyqPcRVLqPkqrIieoR44cga+vL16+fImJEydCoVAor9nY2CA4OFid8RERERFROVPkBHXmzJnw9/fH+fPnMWfOHMm1evXqISIiQl2xEREREZUPYjEdpVSRJ46eP38ev/zyCwDkWdlfsWJFxMfHqycyIiIiIiqXipyg6unpITMzM99r8fHxMDMze+egiIiIiMoTbdlmSlsUeYjf09MTmzdvzvfazp070bRp03cOioiIiIjKryJXUKdOnQo/Pz90794dAwcOhCAIOHPmDNavX4+dO3fi6NGjxREnERERUdlWiueMqluRE9S2bdti48aNGDt2LH777TcAOdtLVahQAcHBwWjevLnagyQiIiKi8uOtdtfv378/evbsiVOnTiE+Ph42NjZo1qwZTExM1B0fERERUZnHOahSb/3xT0ZGRkX6TFUiIiIiKkBxbAtViqcMvFWCmpSUhO+++w5Hjx7F06dPYW1tjVatWuGTTz5BhQoV1BwiEREREZUnRU5Qo6Ki0KpVK0RHR8PJyQlyuRw3b97EoUOH8MMPP+Do0aOoUqVKccRKREREVEYJ/z/U3WfpVORtpj777DO8fPkSp06dQlRUFE6fPo2oqCicPHkS6enpGDt2bDGESURERETlRZET1CNHjmDu3Ll59jv18vLCnDlzcOTIEbUFR0RERFQu8KNOJYqcoMpkMjg4OOR7zdHRETKZ7J2DIiIiIqLyq8gJateuXfHLL7/ke+2XX35Bp06d3jkoIiIionKFFVQJlRZJnTt3Tvnnfv36YciQIfjggw/Qr18/yOVyxMXFYevWrTh79izWrVtXbMESERERUdmnUoLq4eEBQfhvJZgoioiJicGuXbsk5wDA19cX2dnZag6TiIiIqAwThZxD3X2WUiolqBs2bCjuOIiIiIjKLVHMOdTdZ2mlUoIaEBBQ3HEQEREREQF4h486JSIiIiI14UedSrxVgvrs2TNs27YNkZGRSEtLk1wTBIELpYiIiIjorRU5QY2OjoanpydevHiBFy9ewMbGBs+ePUN2djYsLS1hYWFRHHESERERlV1cJCVR5H1Qp06ditq1a+PRo0cQRRH79+9HamoqVqxYAUNDQ/zxxx/FEScRERERlRNFTlBPnz6NTz75BIaGhgBytpcyMDDAqFGjMGTIEEyaNEntQRIRERGVZYJYPEdpVeQE9dGjR7Czs4OOjg50dXWRlJSkvObt7Y2TJ0+qNUAiIiIiKl+KnKDa2tri2bNnAABnZ2ecPXtWee3u3bvQ0+PGAERERERFwo86lShyNtmkSROcP38eXbp0QY8ePfDll18iPT0dBgYG+Prrr9G6deviiJOIiIio7OIiKYkiJ6gTJ07E3bt3AQAzZ85EZGQkZs2aBVEU0bJlSyxfvlzNIRIRERFReVLkBLVRo0Zo1KgRAMDExAR79+5FUlISBEGAmZmZ2gMkIiIiKvO4Ub9Ekeeg5sfc3BxmZmY4ceIEh/iJiIiI6J2odUXT48ePcfz4cXV2SURERFT2sYIqoZYKKhERERGRunBPKCIiIiJNYwVVghVUIiIiItIqrKASERERaRr3QZVQKUGtW7euSp29+rGnRERERERvQ6UE1crKCoLw5izc2toaLi4u7xwUERERUXkiiDmHuvssrVRKUI8dO1bMYRCVjDqNU/DByMdwdX8Ba3kWggY74/RfFvm2/XRhDDoOeIYfZtpj99qKJRwplRaX/jHBL99Xws1Lxnj2SB+z1kXBq0Oi8npaqg7WzbXD6QMWSErQg23lDHQd8hidA54q2zyL18Par+xx7oQZXqTowKFqOj789BFadErM75FE8O9+F/7d78LWLg0AcC/KDD+td0X4P7b/byGi35AbaN/lHkzNM3H9iiVWLXFHdBQ/UEdrcZGURLlbJHXs2DEIgoDnz58X2s7Z2Zkf21oGGRorcOeKIb6b/l6h7Zq2T0TNhi/wJJbTtKlwL1/ooErtNIyaez/f6z/Meg9nj5lj8oporDl+DT2GP8b3X1RG6F/myjaLxjgh5rYMQcFR+PHIdTTzT8S8j51x65JRSb0NKmWexBsieFUtfDa4BT4b3AIXw60xY2EYHF2SAQC9+t9G9w/v4Iel7hg3pAUSnskwZ/lpGBlnaThyItVoTYIaGBiIbt265TmvakL5toKDg1GhQoVi6Zu0z9mj5ti4yA6n9lcosI21PBOj5jzAwlFOyMoqvRPMqWR4tk5G4JQ4NPfPv9oZGW6Mdh88Qz2vFMgdMuDf/ymquKXh5kVjSZuug5+gZoMXsHPKQL+xj2Bikc0ElQr07yk5zp62xcMYUzyMMcWmH2vhZZoeatZOACCia+872LHRFaHH7XDvjjmWflUfMsNseLfL/xcpIm2jNQkqARkZGZoOodwTBBGTv43GzlUVce+GoabDoTKg9vup+OegBZ7E6kMUgYhTpnhwR4ZG3smSNsf3VkBSgi4UCuDYngrITBdQ1ytFg5FTaaGjI6Jl2wcwNMxG5GVLyO1fwMomHef+/W9qUlamLi5HWKOWe4IGIyVSXalLUENDQ9GyZUsYGRnBwcEBn376KVJTU5XXt2zZAg8PD5iZmUEul6Nfv36Ij4/Pt69jx45h0KBBSExMhCAIEAQBQUFByusvXrzA4MGDYWZmBkdHR6xevVpy//379/Hhhx/CysoKJiYm8PDwwJkzZwAAt2/fRteuXWFrawtTU1N4enri0KFDkvudnZ0xZ84cBAYGwsLCAsOGDVPpPVLx6T0qHtnZwJ51NpoOhcqIkV89gGP1l/ioUW10dKqHLz6qgtHz76NO4//+n57+w11kZwn4oLY7OjnXwzdTHDBzXRTsnflLKxXMqUoSdh76E3uO/YFRky5izjQPxNw1g6VVOgDg+TOZpP3zZzJYWqdrIlRSgYD/Fkqp7XiLOE6cOIHOnTvD3t4egiBgz549kuuiKCIoKAj29vYwMjKCj48Prly5ImmTnp6OMWPGwMbGBiYmJujSpQvu3y9a9b5UJaiXLl2Cn58fevTogYsXL2LHjh04efIkRo8erWyTkZGBr776ChcuXMCePXsQFRWFwMDAfPvz8vLC8uXLYW5ujtjYWMTGxmLixInK60uWLIGHhwfOnz+PkSNH4pNPPsG1a9cAACkpKfD29sbDhw+xd+9eXLhwAZMnT4ZCoVBe9/f3x6FDh3D+/Hn4+fmhc+fOiI6OlsTw9ddfo06dOggPD8eMGTNUeo+vS09PR1JSkuSgoqvm/gLdhj7B4rGOeLv/rYny2rPOBtfCjTE7+A5W/nUdw2Y+xMpplXHuhKmyTfBCO6Qk6mLBjltYsf86eg6Px9wRLoiKZBWfCvYg2hRjArwxfnhz/LnbGeO/iICD83+VefH1BTICSvWiGSoZqampqFevHlauXJnv9UWLFmHp0qVYuXIlwsLCIJfL0a5dOyQn//e9N3bsWOzevRvbt2/HyZMnkZKSgk6dOiE7O1vlOLRqBci+fftgamoqOffqm/n666/Rr18/jB07FgDg6uqKb7/9Ft7e3li1ahUMDQ0xePBgZfsqVarg22+/xfvvv4+UlJQ8fRsYGMDCwgKCIEAul+eJx9/fHyNHjgQATJkyBcuWLcOxY8dQs2ZNbNu2DY8fP0ZYWBisrKwAANWqVVPeW69ePdSrV0/5es6cOdi9ezf27t0rSTZbt24tSYoHDhz4xvf4uvnz52P27Nn5f1FJZe6NU1HBJgtbwq4qz+nqAcNmPUS3YY8R0NhNg9FRaZSeJiB4gR1mrruLxm1zfnGs4vYSd64YYecPldCwZQoe3jXA3g0V8ePRa3Cu8RIAULX2S1w6Y4q9wTb4bCHnDFL+srJ0EPvABABw61oFVK/1HF1738HOLTn/FllapyPh6X//ZlSwTEfCa1VV0iJaslF/hw4d0KFDh/y7E0UsX74c06dPR48ePQAAGzduhK2tLbZt24YRI0YgMTER69atw+bNm9G2bVsAOaPbDg4OOHToEPz8/FSKQ6sqqK1atUJERITkWLt2rfJ6eHg4goODYWpqqjz8/PygUCgQFRUFADh//jy6du0KJycnmJmZwcfHBwDyVC5V8eoHFOQmsbnTBSIiItCgQQNlcvq61NRUTJ48GW5ubqhQoQJMTU1x7dq1PHF4eHhIXqvyHl83bdo0JCYmKo+YmJgiv1cCDv1qiY/bVMcn7f47nsTqYeeqipjer4qmw6NSKCtLQFamDnR0pGUrHV0RYs5gC9LTcn4Mv95G95U2RCoRAH19BeIeGuPZExkaeD5WXtLTU6BO/aeIvGSpwQBJU14fZU1Pf7upHlFRUYiLi4Ovr6/ynEwmg7e3N0JDQwHk5DGZmZmSNvb29qhTp46yjSpUqqC2bt1a5Q4FQcDhw4dVbv8qExMTSRUSgGTOgkKhwIgRI/Dpp5/mudfR0RGpqanw9fWFr68vtmzZgooVKyI6Ohp+fn5vtQBJX19f8loQBOUQvpFR4atrJ02ahAMHDmDx4sWoVq0ajIyM0KtXrzxxmJiYSF6/6T3mRyaTQSbjb8WqMDTOhr3Lf38HcocMVKmdhuTnunj8wADJCdL/JbKyBCTE6+P+bQ61Uv7SUnXwMOq////iYgxw+7IRzCpkoVLlTNRtmoI1X9nDwPABbCtn4OJpUxzaaYXhsx4AAByqvYS9Szq+meyAYTMfwtwyC6F/WeDcCTN8uemOpt4WabmBIyIR/k8lPH5kBCPjLHi3ewD3Bk8wc3wTAAJ++7kKeg+8iYcxJnh43wS9B95C+ktdHA+prOnQqSDFuA+qg4OD5PSsWbMka25UFRcXBwCwtbWVnLe1tcW9e/eUbQwMDGBpaZmnTe79qlApQVUoFCp9khSQU/4tLg0bNsSVK1fyJLG5Ll26hCdPnmDBggXKv4yzZ88W2qeBgUGR5kTkqlu3LtauXYtnz57lW0X9+++/ERgYiO7duwPImZN69+7dN/b7pvdI76Z6vTR8/ett5euPZz8EABzcYYkl4/L/BYCoMDcuGGNyr//+f/0xKGeP3Xa9n2Hi8mhMW3UX6+fZYeFoRyQ/10Ol9zIQOCUWnQbmbNSvpw/M2Xwb6+bZY1aAC9JSdWDvkoGJ30Tj/TbJ+T6TyNIqHRNmnoeVdTpSU/Vw95Y5Zo5vgoiwnJX7O7dUhYEsGyMnXoKpWSauX62AGeOaIO2FVs3so1cVY4IaExMDc/P/9l5+16LW6zmhKIpvzBNVafOqUvVJUlOmTEGTJk0watQoDBs2DCYmJoiMjERISAhWrFgBR0dHGBgYYMWKFfj4449x+fJlfPXVV4X26ezsjJSUFBw+fBj16tWDsbExjI2NC70HAPr27Yt58+ahW7dumD9/Puzs7HD+/HnY29ujadOmqFatGnbt2oXOnTtDEATMmDFDWX19l/dI7+biaVP42dd7c8P/47xTepN6Xik48DCiwOtWlbIwcXnh027eq5KBmWvvqjcwKtO+mV//DS0EbFtXA9vW1SiJcEjLmZubSxLUt5W7XicuLg52dnbK8/Hx8cqqqlwuR0ZGBhISEiRV1Pj4eHh5ean8LK2ag/omdevWxfHjx3Hz5k20aNECDRo0wIwZM5RfpIoVKyI4OBi//PIL3NzcsGDBAixevLjQPr28vPDxxx+jT58+qFixIhYtWqRSLAYGBjh48CAqVaoEf39/uLu7Y8GCBdDV1QUALFu2DJaWlvDy8kLnzp3h5+eHhg0bvvN7JCIiorJH7VtM/f9QJxcXF8jlcoSEhCjPZWRk4Pjx48rks1GjRtDX15e0iY2NxeXLl4uUoAriO4zJP378GGlpaXnOFzRXkkpGUlISLCws4IOu0BP033wD0VsqrHJIpC4dvbpoOgQq47IU6Th07zskJiaqpdJYFLn/ZjvPnQudfHbqeReKly9xd/r0Ir2vlJQU3Lp1CwDQoEEDLF26FK1atYKVlRUcHR2xcOFCzJ8/Hxs2bICrqyvmzZuHY8eO4fr16zAzMwMAfPLJJ9i3bx+Cg4NhZWWFiRMn4unTpwgPD1cW8t7krSajzJkzB99++y2ePn2a7/W3mdNJREREVG4V4xzUojh79ixatWqlfD1+/HgAQEBAAIKDgzF58mSkpaVh5MiRSEhIQOPGjXHw4EFlcgrkjCLr6emhd+/eSEtLQ5s2bRAcHKxycgq8RYK6fv16LFiwAFOnTsXMmTMxffp0iKKIzZs3w8jICFOmTClql0RERESkBXx8fApd8J77qZuF7QJgaGiIFStWvNPamSLPQf3uu+/w+eefY9q0aQCA7t27Y86cObh27RrMzMzw5MmTtw6GiIiIqFwSi+kopYqcoN66dQtNmjSBjk7Orbn7ehoZGWHChAl5Pq+eiIiIiKgoijzEr6eXc4sgCDA3N5dspG9jY4MHDx6oLzoiIiKicqA4Vt2ru7+SVOQKqqurq/KjND09PbFmzRpkZmYiOzsbq1evhrOzs7pjJCIiIirbRKF4jlKqyBVUf39/nDhxAgEBAZg2bRr8/PxQoUIF6OnpISUlBevXry+OOImIiIionChygjpz5kzln1u3bo3Q0FBs374dgiCgY8eOkq0JiIiIiEgFWrLNlLZ45w/l9fT0hKenpzpiISIiIiJ69wSViIiIiN4NF0lJFTlBdXFxgSAUPOlWEATcvn37nYIiIiIiovKryAmqt7d3ngT1yZMnCA0Nhbm5Oby9vdUWHBEREVG5wDmoEkVOUIODg/M9//TpU7Rr1w4dO3Z815iIiIiIqBwr8j6oBbG2tsakSZMwe/ZsdXVJREREVD6I/81DVddRriqohbGxscGdO3fU2SURERFR2cchfgm1VVAzMzOxZs0auLi4qKtLIiIiIiqHilxBbd26dZ5z6enpuHHjBp49e4aNGzeqJTAiIiKicoMVVIkiJ6gKhSLPKn5zc3P06tULAwYMgJeXl9qCIyIiIqLyp8gJ6rFjx4ohDCIiIqLyixv1SxV5DuqXX36Jhw8f5nstNjYWX3755TsHRURERETlV5ET1NmzZ+P+/fv5Xnv48CG3mSIiIiKid1LkBFUUC64Xp6SkQF9f/50CIiIiIqLyTaU5qBcvXkRERITy9Z9//olr165J2qSlpWHr1q2oWrWqWgMkIiIiKvO4il9CpQR19+7dyqF7QRAKnGdqZGSEDRs2qC86IiIionKAi6SkVEpQhw8fjk6dOkEURbz//vvYsGED6tSpI2kjk8lQtWpVGBkZFUugRERERFQ+qJSg2tnZwc7ODgBw9OhRNGrUCKampsUaGBEREVG5UoornupW5EVSbm5uBW4zdePGDTx58uSdgyIiIiKi8qvIG/WPGjUKFhYWWLNmTZ5rS5YsQVJSEn766Se1BEdERERULnCRlESRK6inTp2Cn59fvtf8/Pxw8uTJdw6KiIiIiMqvIldQnzx5Amtr63yvWVpa4vHjx+8cFBEREVF5wlX8UkWuoNra2uLSpUv5Xrt06VKBySsRERERkSqKnKC2b98ec+fOxY0bNyTnb968ifnz58Pf319twRERERGVC2IxHaVUkYf4g4KCsG/fPtStWxetWrVC5cqVcf/+fRw9ehQ2NjbKDf2JiIiISDUc4pcqcgXV3t4eZ8+exUcffYSLFy9i48aNuHjxIvr3749///0X9vb2xREnEREREZUTRa6gAjlJ6rp16/K99vjxY1SsWPGdgiIiIiIqV7jNlESRK6j5EUURf/75J3r27InKlSuro0siIiIiKqfeqoKa6/bt21i/fj02btyI2NhYGBgYoGfPnuqKjYiIiKh8YAVVosgJ6suXL/HLL79g3bp1+PvvvyGKIgRBwPjx4zF16lRuM0VERERE70TlIf6wsDB8/PHHkMvlCAwMxLlz5xAYGIh9+/ZBFEV07tyZySkRERHRW8hdxa/uo7RSqYJat25dXLlyBQDQtGlTDB48GH369IGJiQkSExOLNUAiIiIiKl9USlAvX74MQRDQsWNHLFiwAG5ubsUdFxEREVH5wTmoEioN8S9fvhx169bFvn374O7ujqZNm2Lt2rVITk4u7viIiIiIyj5+kpSESgnqp59+ivPnz+Pff//F8OHDce3aNQwfPhx2dnYYPnw4BEGAIAjFHSsRERERlQNF2gfVw8MDq1atQmxsLDZu3AgPDw/s3LkToihiyJAhWLJkCZ4+fVpcsRIRERGVSVwkJfVWG/UbGhpiwIABOHbsGG7cuIGpU6fixYsXmDRpEhwcHNQdIxERERGVI+/8SVJVq1bFvHnzEB0djb1796J9+/bqiIuIiIio/NCCOahZWVn44osv4OLiAiMjI1SpUgVffvklFArFf2GKIoKCgmBvbw8jIyP4+Pgod3pSJ7V81CkA6OjooFOnTti1a5e6uiQiIiKiErJw4UL88MMPWLlyJSIjI7Fo0SJ8/fXXWLFihbLNokWLsHTpUqxcuRJhYWGQy+Vo166d2hfOv9NHnRIRERHRuyuOOaO5/SUlJUnOy2QyyGSyPO1Pnz6Nrl27omPHjgAAZ2dn/PTTTzh79iyAnOrp8uXLMX36dPTo0QMAsHHjRtja2mLbtm0YMWKE2mJXWwWViIiIiLSPg4MDLCwslMf8+fPzbde8eXMcPnwYN27cAABcuHABJ0+ehL+/PwAgKioKcXFx8PX1Vd4jk8ng7e2N0NBQtcbMCioRERGRphXjRv0xMTEwNzdXns6vegoAU6ZMQWJiImrWrAldXV1kZ2dj7ty56Nu3LwAgLi4OAGBrayu5z9bWFvfu3VNr6ExQiYiIiDStGBNUc3NzSYJakB07dmDLli3Ytm0bateujYiICIwdOxb29vYICAhQtnt973tRFNW+Hz4TVCIiIiLCpEmTMHXqVHz44YcAAHd3d9y7dw/z589HQEAA5HI5gJxKqp2dnfK++Pj4PFXVd8U5qEREREQaJhTTURQvXryAjo40NdTV1VVuM+Xi4gK5XI6QkBDl9YyMDBw/fhxeXl5FfFrhWEElIiIiInTu3Blz586Fo6MjateujfPnz2Pp0qUYPHgwgJyh/bFjx2LevHlwdXWFq6sr5s2bB2NjY/Tr10+tsTBBJSIiItK0YpyDqqoVK1ZgxowZGDlyJOLj42Fvb48RI0Zg5syZyjaTJ09GWloaRo4ciYSEBDRu3BgHDx6EmZmZWkNngkpEREREMDMzw/Lly7F8+fIC2wiCgKCgIAQFBRVrLExQiYiIiDSsODfqL424SIqIiIiItAorqERERESapgVzULUJE1QiIiIibVCKE0p14xA/EREREWkVVlCJiIiINIyLpKRYQSUiIiIircIKKhEREZGmcZGUBCuoRERERKRVWEElIiIi0jDOQZViBZWIiIiItAorqERERESaxjmoEqygEhEREZFWYQW1DBP0DSAI+poOg8qwBnNGajoEKgdMPLI1HQKVcVmZL4F7mo2Bc1ClmKASERERaRqH+CU4xE9EREREWoUVVCIiIiJNYwVVghVUIiIiItIqrKASERERaRgXSUmxgkpEREREWoUVVCIiIiJN4xxUCVZQiYiIiEirsIJKREREpGGCKEIQ1VvyVHd/JYkJKhEREZGmcYhfgkP8RERERKRVWEElIiIi0jBuMyXFCioRERERaRVWUImIiIg0jXNQJVhBJSIiIiKtwgoqERERkYZxDqoUK6hEREREpFVYQSUiIiLSNM5BlWCCSkRERKRhHOKX4hA/EREREWkVVlCJiIiINI1D/BKsoBIRERGRVmEFlYiIiEgLlOY5o+rGCioRERERaRVWUImIiIg0TRRzDnX3WUqxgkpEREREWoUVVCIiIiIN4z6oUkxQiYiIiDSN20xJcIifiIiIiAAADx48QP/+/WFtbQ1jY2PUr18f4eHhyuuiKCIoKAj29vYwMjKCj48Prly5ovY4mKASERERaZigKJ6jKBISEtCsWTPo6+tj//79uHr1KpYsWYIKFSoo2yxatAhLly7FypUrERYWBrlcjnbt2iE5OVmtXw8O8RMRERERFi5cCAcHB2zYsEF5ztnZWflnURSxfPlyTJ8+HT169AAAbNy4Eba2tti2bRtGjBihtlhYQSUiIiLSNLGYDgBJSUmSIz09Pd8Q9u7dCw8PD3zwwQeoVKkSGjRogDVr1iivR0VFIS4uDr6+vspzMpkM3t7eCA0NVddXAgATVCIiIqIyzcHBARYWFspj/vz5+ba7c+cOVq1aBVdXVxw4cAAff/wxPv30U2zatAkAEBcXBwCwtbWV3Gdra6u8pi4c4iciIiLSsOLcZiomJgbm5ubK8zKZLN/2CoUCHh4emDdvHgCgQYMGuHLlClatWoWBAwf+168gSO4TRTHPuXfFCioRERFRGWZubi45CkpQ7ezs4ObmJjlXq1YtREdHAwDkcjkA5KmWxsfH56mqvismqERERESalvtRp+o+iqBZs2a4fv265NyNGzfg5OQEAHBxcYFcLkdISIjyekZGBo4fPw4vL693/xq8gkP8RERERBqmDZ8kNW7cOHh5eWHevHno3bs3/v33X6xevRqrV6/O6U8QMHbsWMybNw+urq5wdXXFvHnzYGxsjH79+qk1diaoRERERARPT0/s3r0b06ZNw5dffgkXFxcsX74cH330kbLN5MmTkZaWhpEjRyIhIQGNGzfGwYMHYWZmptZYmKASERERaZqWfNRpp06d0KlTpwKvC4KAoKAgBAUFvX1cKuAcVCIiIiLSKqygEhEREWmYNsxB1SasoBIRERGRVmEFlYiIiEjT3mJbKJX6LKVYQSUiIiIircIKKhEREZGGcQ6qFBNUIiIiIk3Tkm2mtAWH+ImIiIhIq7CCSkRERKRhHOKXYgWViIiIiLQKK6hEREREmqYQcw5191lKsYJKRERERFqFFVQiIiIiTeMqfglWUImIiIhIq7CCSkRERKRhAophFb96uytRTFCJiIiINE0Ucw5191lKcYifiIiIiLQKK6hEREREGsaN+qVYQSUiIiIircIKKhEREZGmcZspCVZQiYiIiEirsIJKREREpGGCKEJQ86p7dfdXklhBJSIiIiKtwgoqERERkaYp/n+ou89SigkqERERkYZxiF+KQ/xEREREpFVYQSUiIiLSNG4zJcEKKhERERFpFVZQiYiIiDRNFHMOdfdZSrGCSkRERERahRVUIiIiIg0TxJxD3X2WVqygEhEREZFWYQWVypU67yej14hYuLq/gLVtJmYPq4bTBy2V1/+6F5bvfWvnVcbOH+1KKkwqxf4YvQX2FZLznN9xtjYW/NUSszsfQZd61yXXLt6vhIDgniUVIpURNhap+KTLGTRxi4FMPwsx8RWw4KeWuB5T8f8tRAzuEI4uXtdgZpSOq/cqYekvzRAVZ6XRuKkAnIMqUWYT1ODgYIwdOxbPnz8vE88h9TA0zkZUpDFCfrHBjB9v57ne16O+5LWHz3OMW3QXJ/+0zNOWKD/91/eEzivjatUqPcMPH/2OkMiqynOnbjlg1u+tla8zszmYRUVjZpSOVWN/w7mb9pi4qgMSUozwnk0SktNkyjYftb2APq0uYe4WH8Q8tkCA7zksG/Un+s7pjbR0Aw1GT/RmGk1QBUEo9HpAQACCg4NLJhgqF84eq4Czxyr8/1XeBDXhsb7kddN2z3HhtBniYgyLPzgqExJeGEleD6p2DtHPzBF+z155LiNbF09TjUs6NCpDPmobgfjnppi/zUd5Lu6Z2SstRHzgfQmbDjbAiYsuAIC5W1th75zN8G10C7+FupVswPRGgiLnUHefpZVGE9TY2Fjln3fs2IGZM2fi+vX/hr6MjIzyu42oRFSwycT7rROxeIKLpkOhUkpPJxv+7jex5UxdAP/9Qu7h9BCHx21A8ksZwqPtsfLo+0h4wYSVVNfM/R7+jayMrwaFoH61WDxONMHuv93w++laAAB762TYWKTh32uVlfdkZuki4rYd6rg8YoKqjTjEL6HRcSW5XK48LCwsIAiC5NyJEyfQqFEjGBoaokqVKpg9ezaysrKU9z9//hzDhw+Hra0tDA0NUadOHezbt0/yjAMHDqBWrVowNTVF+/btJUlxYGAgunXrhsWLF8POzg7W1tYYNWoUMjMzlW0SEhIwcOBAWFpawtjYGB06dMDNmzcLfV+rVq1C1apVYWBggBo1amDz5s2S69euXUPz5s1haGgINzc3HDp0CIIgYM+ePQCA1q1bY/To0ZJ7nj59CplMhiNHjhTpa0xvr23PJ0hL1cGpvzi8T2+nVY0omBmm4/cLNZXnTt12xOd72mL4li5YesgLte3isbr/XujrZmswUipt7K2T0a15JGIeW2D8Kn/8drIWxvYMRXvPGwAAK/MXAIBnSdJCT0KSEazM00o8XqKi0to5qAcOHED//v3x7bffokWLFrh9+zaGDx8OAJg1axYUCgU6dOiA5ORkbNmyBVWrVsXVq1ehq6ur7OPFixdYvHgxNm/eDB0dHfTv3x8TJ07E1q1blW2OHj0KOzs7HD16FLdu3UKfPn1Qv359DBs2DEBOEnvz5k3s3bsX5ubmmDJlCvz9/XH16lXo60uHgwFg9+7d+Oyzz7B8+XK0bdsW+/btw6BBg1C5cmW0atUKCoUC3bp1g6OjI86cOYPk5GRMmDBB0sfQoUMxevRoLFmyBDJZznyirVu3wt7eHq1atcrzzPT0dKSnpytfJyUlvcNXnnL59X6CI3uskZnO+YH0drrVv4ZTtxzxOMVEee7g1WrKP99+bI2rsRXx55gtaFHtHo5cr6KJMKkU0hFEXIupiNX73gcA3LxvA2e7BHRrfhV/hVV/peVrU+kKn1lHmsSPOpXQ2n95586di6lTpyIgIABVqlRBu3bt8NVXX+HHH38EABw6dAj//vsvdu3ahXbt2qFKlSro1KkTOnTooOwjMzMTP/zwAzw8PNCwYUOMHj0ahw8fljzH0tISK1euRM2aNdGpUyd07NhR2SY3MV27di1atGiBevXqYevWrXjw4IGy2vm6xYsXIzAwECNHjkT16tUxfvx49OjRA4sXLwYAHDx4ELdv38amTZtQr149NG/eHHPnzpX00bNnTwiCgN9++015bsOGDQgMDMx33u78+fNhYWGhPBwcHIr+BSeJ2p7JcKj2En9tr/jmxkT5sLNIRmOX+9gTUavQdk9STBCbaAZHq8QSiozKgqdJxrgbV0Fy7t4jS9hapgAAniXlTBnJraTmsjRLy1NVJdJGWpughoeH48svv4SpqanyGDZsGGJjY/HixQtERESgcuXKqF69eoF9GBsbo2rV/1bO2tnZIT4+XtKmdu3akqrrq20iIyOhp6eHxo0bK69bW1ujRo0aiIyMzPeZkZGRaNasmeRcs2bNlO2vX78OBwcHyOVy5fX3339f0l4mk6F///5Yv349ACAiIgIXLlxAYGBgvs+cNm0aEhMTlUdMTEy+7Uh17fs8xo2LxoiK5LxAejtd6l3Ds1Qj/H3TqdB2FkYvYWuegicp/F4j1V26YwvHStJfahwqPkdcQs5CqYdPzfAk0QieNe4rr+vpZqN+1VhcjrIt0VhJNYIoFstRWmntEL9CocDs2bPRo0ePPNcMDQ1VWkD1+hC8IAgQX/vLyq+NQpGz7O31trlEUSx0B4LXr73a/k335ho6dCjq16+P+/fvY/369WjTpg2cnPL/h04mkymnAlDhDI2zYe/833QIuUM6qri9QPJzXTx+mPM1NDbNRouOCVg9h5VoejsCRHStdw37LtZAtvhfHcBIPxMftwzD4WtV8DjFGPYVkjHG5wyevzDEketcjEeq23HMHT+M+w0D2p3HkfNV4Ob0GF28rmHRjhb/byHgl+PuGNAuAvcfWyDmsQUGtjuP9Ew9HAyvVmjfRNpAaxPUhg0b4vr166hWLf//kerWrYv79+/jxo0bhVZR34WbmxuysrJw5swZeHl5AchZrHTjxg3UqpX/sF2tWrVw8uRJDBw4UHkuNDRU2b5mzZqIjo7Go0ePYGub81tsWFjezeHd3d3h4eGBNWvWYNu2bVixYoW63165VL1uKhbt+G+niBEzc6rNIb9YY8nEnPl/3p2fAgJwbC83s6a307jKfdhZpGDPK4ujAEAhCqhW6Rk61b0OM8MMPEkxRtjd9zBlty9eZHBfSlLdtehK+HytL0Z0/heB7c8h9qkZvt3VFCFnXZVtth6qB5l+FsZ/cBJmxhm4eq8Sxn3vzz1QtRVX8UtobYI6c+ZMdOrUCQ4ODvjggw+go6ODixcv4tKlS5gzZw68vb3RsmVL9OzZE0uXLkW1atVw7do1CIKA9u3bqyUGV1dXdO3aFcOGDcOPP/4IMzMzTJ06Fe+99x66du2a7z2TJk1C79690bBhQ7Rp0wa///47du3ahUOHDgEA2rVrh6pVqyIgIACLFi1CcnIypk+fDiBv5TV3sZSxsTG6d++ulvdU3l38xxztnTwLbbP/p0rY/1OlEoqIyqJ/7jigwZxP8pxPz9LDqJ86aSAiKotCrzgh9EphU0gErN/vgfX7PUosJipb5s+fj88//1y5+BvIGQmePXs2Vq9ejYSEBDRu3BjfffcdateurdZna+0cVD8/P+zbtw8hISHw9PREkyZNsHTpUskw96+//gpPT0/07dsXbm5umDx5MrKz1btVy4YNG9CoUSN06tQJTZs2hSiK+PPPP/NdwQ8A3bp1wzfffIOvv/4atWvXxo8//ogNGzbAx8cHAKCrq4s9e/YgJSUFnp6eGDp0KL744gsAOVMXXtW3b1/o6emhX79+ea4RERFRGSICUKj5eIcCalhYGFavXo26detKzi9atAhLly7FypUrERYWBrlcjnbt2iE5Oe9HPL8LQSxooiWVmFOnTqF58+a4deuWZFFXTEwMnJ2dERYWhoYNG6rcX1JSEiwsLNBK/wPoCfkn0kTq8GgYKzNU/EziuUcsFa+szJcI2zMDiYmJMDc3L9Fn5/6b3brBVOjpqrcYlZX9EkfOLyjy+0pJSUHDhg3x/fffY86cOahfvz6WL18OURRhb2+PsWPHYsqUKQBytrq0tbXFwoULMWLECLXFrrUV1LJs9+7dCAkJwd27d3Ho0CEMHz4czZo1UyanmZmZiI6OxpQpU9CkSZMiJadEREREr0pKSpIcr+6dnp9Ro0ahY8eOaNu2reR8VFQU4uLi4Ovrqzwnk8ng7e2N0NBQtcastXNQy7Lk5GRMnjwZMTExsLGxQdu2bbFkyRLl9VOnTqFVq1aoXr06du7cqcFIiYiIqESIKIZFUjn/eX1/9FmzZiEoKCjfW7Zv345z587lu4A7Li4OAJSLvHPZ2tri3r177x7vK5igasDAgQMlq/xf5+PjU+AWV0RERERFERMTIxniL2hrypiYGHz22Wc4ePBgoWtfCttOU12YoBIRERFpWjFuM2Vubq7SHNTw8HDEx8ejUaNGynPZ2dk4ceIEVq5cievXc7ZpjIuLg52dnbJNfHx8nqrqu+IcVCIiIiJCmzZtcOnSJURERCgPDw8PfPTRR4iIiECVKlUgl8sREhKivCcjIwPHjx9X7hevLqygEhEREWmaAoB6R8lz+iwCMzMz1KlTR3LOxMQE1tbWyvNjx47FvHnz4OrqCldXV8ybNw/Gxsbo16+fuqIGwASViIiIiFQ0efJkpKWlYeTIkcqN+g8ePAgzMzO1PocJKhEREZGGCaIIQc1zUNXR37Fjx6R9CgKCgoIK3AVAXZigEhEREWlaMS6SKo24SIqIiIiItAorqERERESaxgqqBCuoRERERKRVWEElIiIi0jRWUCVYQSUiIiIircIKKhEREZGmacFG/dqEFVQiIiIi0iqsoBIRERFpmLZu1K8pTFCJiIiINI2LpCQ4xE9EREREWoUVVCIiIiJNU4iAoOaKp4IVVCIiIiIitWAFlYiIiEjTOAdVghVUIiIiItIqrKASERERaVwxVFDBCioRERERkVqwgkpERESkaZyDKsEElYiIiEjTFCLUPiTPbaaIiIiIiNSDFVQiIiIiTRMVOYe6+yylWEElIiIiIq3CCioRERGRpnGRlAQrqERERESkVVhBJSIiItI0ruKXYAWViIiIiLQKK6hEREREmsY5qBJMUImIiIg0TUQxJKjq7a4kcYifiIiIiLQKK6hEREREmsYhfglWUImIiIhIq7CCSkRERKRpCgUANX80qYIfdUpEREREpBasoBIRERFpGuegSrCCSkRERERahRVUIiIiIk1jBVWCCSoRERGRpilEqH1nfUXpTVA5xE9EREREWoUVVCIiIiINE0UFRFG920Kpu7+SxAoqEREREWkVVlCJiIiINE0U1T9ntBQvkmIFlYiIiIi0ChNUIiIiIk3L3WZK3UcRzJ8/H56enjAzM0OlSpXQrVs3XL9+/bUwRQQFBcHe3h5GRkbw8fHBlStX1PmVAMAElYiIiIgAHD9+HKNGjcI///yDkJAQZGVlwdfXF6mpqco2ixYtwtKlS7Fy5UqEhYVBLpejXbt2SE5OVmssnINKREREpGkKBSCoedV9EVfx//XXX5LXGzZsQKVKlRAeHo6WLVtCFEUsX74c06dPR48ePQAAGzduhK2tLbZt24YRI0aoLXRWUImIiIg0rRiH+JOSkiRHenq6SiElJiYCAKysrAAAUVFRiIuLg6+vr7KNTCaDt7c3QkND1frlYIJKREREVIY5ODjAwsJCecyfP/+N94iiiPHjx6N58+aoU6cOACAuLg4AYGtrK2lra2urvKYuHOInIiIi0jBRoYCo5iH+3I36Y2JiYG5urjwvk8neeO/o0aNx8eJFnDx5Ms81QRBee46Y59y7YoJKREREVIaZm5tLEtQ3GTNmDPbu3YsTJ06gcuXKyvNyuRxATiXVzs5OeT4+Pj5PVfVdcYifiIiISNO0YJspURQxevRo7Nq1C0eOHIGLi4vkuouLC+RyOUJCQpTnMjIycPz4cXh5eanly5CLFVQiIiIiwqhRo7Bt2zb89ttvMDMzU84rtbCwgJGREQRBwNixYzFv3jy4urrC1dUV8+bNg7GxMfr166fWWJigEhEREWmaQgQEzX7U6apVqwAAPj4+kvMbNmxAYGAgAGDy5MlIS0vDyJEjkZCQgMaNG+PgwYMwMzNTR8RKTFCJiIiICKIKCa0gCAgKCkJQUFCxxsIElYiIiEjTRBGAujfqV3NFtgRxkRQRERERaRVWUImIiIg0TFSIENU8B1WVIXttxQSViIiISNNEBdQ/xK/m/koQh/iJiIiISKuwgkpERESkYRzil2IFlYiIiIi0CiuoRERERJrGOagSTFDLoNySfpaYqeFIqKzLznip6RCoHMjKzNZ0CFTGZWfm/CzT5JB4FjIBNT8+C6U3DxDE0jxBgfJ1//59ODg4aDoMIiKiUiUmJgaVK1cu0We+fPkSLi4uys+9Vze5XI6oqCgYGhoWS//FhQlqGaRQKPDw4UOYmZlBEARNh1MqJCUlwcHBATExMTA3N9d0OFRG8fuMSgK/z4pOFEUkJyfD3t4eOjolvzzn5cuXyMjIKJa+DQwMSl1yCnCIv0zS0dEp8d8Aywpzc3P+QKdix+8zKgn8PisaCwsLjT3b0NCwVCaRxYmr+ImIiIhIqzBBJSIiIiKtwgSVCIBMJsOsWbMgk8k0HQqVYfw+o5LA7zMqC7hIioiIiIi0CiuoRERERKRVmKASERERkVZhgkpEREREWoUJKmk1Hx8fjB07VtNhSNy9exeCICAiIkLlewIDA9GtW7dii4k079ixYxAEAc+fPy+0nbOzM5YvX14iMVHpFRwcjAoVKpSZ5xAVFRNU0gqBgYEQBCHPsWjRInz11VeaDk/CwcEBsbGxqFOnjqZDIRUU9MuBqgnl2+I//GVffj+zXj0CAwM1HSJRqcVPkiKt0b59e2zYsEFyrmLFitDV1dVQRPnT1dWFXC7XdBhEKsvIyICBgYGmwyhzYmNjlX/esWMHZs6cievXryvPGRkZaSIsojKBFVTSGjKZDHK5XHK0adNGMsTv7OyMefPmYfDgwTAzM4OjoyNWr14t6WfKlCmoXr06jI2NUaVKFcyYMQOZmZnK60FBQahfvz42b94MZ2dnWFhY4MMPP0RycrKyjUKhwMKFC1GtWjXIZDI4Ojpi7ty5APIO8WdnZ2PIkCFwcXGBkZERatSogW+++abQ97pz5064u7vDyMgI1tbWaNu2LVJTU9/xK0jvIjQ0FC1btoSRkREcHBzw6aefSv5OtmzZAg8PD5iZmUEul6Nfv36Ij4/Pt69jx45h0KBBSExMVFbTgoKClNdfvHhR6Pfw/fv38eGHH8LKygomJibw8PDAmTNnAAC3b99G165dYWtrC1NTU3h6euLQoUOS+52dnTFnzhwEBgbCwsICw4YNU+k9UtG8+rPKwsICgiBIzp04cQKNGjWCoaEhqlSpgtmzZyMrK0t5//PnzzF8+HDY2trC0NAQderUwb59+yTPOHDgAGrVqgVTU1O0b99ekhTnjg4sXrwYdnZ2sLa2xqhRoyQ/7xISEjBw4EBYWlrC2NgYHTp0wM2bNwt9X6tWrULVqlVhYGCAGjVqYPPmzZLr165dQ/PmzWFoaAg3NzccOnQIgiBgz549AIDWrVtj9OjRknuePn0KmUyGI0eOFOlrTOUXE1QqdZYsWQIPDw+cP38eI0eOxCeffIJr164pr5uZmSE4OBhXr17FN998gzVr1mDZsmWSPm7fvo09e/Zg37592LdvH44fP44FCxYor0+bNg0LFy7EjBkzcPXqVWzbtg22trb5xqNQKFC5cmX8/PPPuHr1KmbOnInPP/8cP//8c77tY2Nj0bdvXwwePBiRkZE4duwYevToAW5JrDmXLl2Cn58fevTogYsXL2LHjh04efKk5B/ZjIwMfPXVV7hw4QL27NmDqKioAodwvby8sHz5cpibmyM2NhaxsbGYOHGi8nph38MpKSnw9vbGw4cPsXfvXly4cAGTJ0+GQqFQXvf398ehQ4dw/vx5+Pn5oXPnzoiOjpbE8PXXX6NOnToIDw/HjBkzVHqPpD4HDhxA//798emnn+Lq1av48ccfERwcrPxFV6FQoEOHDggNDcWWLVtw9epVLFiwQDJi9OLFCyxevBibN2/GiRMnEB0dLfk+AoCjR4/i9u3bOHr0KDZu3Ijg4GAEBwcrrwcGBuLs2bPYu3cvTp8+DVEU4e/vL0liX7V792589tlnmDBhAi5fvowRI0Zg0KBBOHr0qDLubt26wdjYGGfOnMHq1asxffp0SR9Dhw7Ftm3bkJ6erjy3detW2Nvbo1WrVu/0daVyRCTSAgEBAaKurq5oYmKiPHr16iV6e3uLn332mbKdk5OT2L9/f+VrhUIhVqpUSVy1alWBfS9atEhs1KiR8vWsWbNEY2NjMSkpSXlu0qRJYuPGjUVRFMWkpCRRJpOJa9asybe/qKgoEYB4/vz5Ap85cuRIsWfPnpL317VrV1EURTE8PFwEIN69e7fA+0l98vveMjExEQ0NDUUAYkJCgjhgwABx+PDhkvv+/vtvUUdHR0xLS8u333///VcEICYnJ4uiKIpHjx5V9ieKorhhwwbRwsIiz31v+h7+8ccfRTMzM/Hp06cqv0c3NzdxxYoVkmd069ZN0uZt3iOp7vW/7xYtWojz5s2TtNm8ebNoZ2cniqIoHjhwQNTR0RGvX79eYH8AxFu3binPfffdd6Ktra3ydUBAgOjk5CRmZWUpz33wwQdinz59RFEUxRs3bogAxFOnTimvP3nyRDQyMhJ//vnnfOP28vIShw0bJonlgw8+EP39/UVRFMX9+/eLenp6YmxsrPJ6SEiICEDcvXu3KIqi+PLlS9HKykrcsWOHsk39+vXFoKCgfN8rUX44B5W0RqtWrbBq1SrlaxMTE/Tt2zdPu7p16yr/nDuk9upQ686dO7F8+XLcunULKSkpyMrKgrm5uaQPZ2dnmJmZKV/b2dkp+4iMjER6ejratGmjcuw//PAD1q5di3v37iEtLQ0ZGRmoX79+vm3r1auHNm3awN3dHX5+fvD19UWvXr1gaWmp8vOoaF7/3gKAM2fOoH///gCA8PBw3Lp1C1u3blVeF0URCoUCUVFRqFWrFs6fP4+goCBERETg2bNnyopmdHQ03NzcihRPYd/DERERaNCgAaysrPK9NzU1FbNnz8a+ffvw8OFDZGVlIS0tLU8F1cPDQ/JalfdI6hMeHo6wsDBlxRTImQ708uVLvHjxAhEREahcuTKqV69eYB/GxsaoWrWq8vWrP6dy1a5dW1J1tbOzw6VLlwDk/CzT09ND48aNldetra1Ro0YNREZG5vvMyMhIDB8+XHKuWbNmymlL169fh4ODg2Qe/vvvvy9pL5PJ0L9/f6xfvx69e/dGRESEcuSBSFVMUElrmJiYoFq1am9sp6+vL3ktCIIyWfjnn3/w4YcfYvbs2fDz84OFhQW2b9+OJUuWqNxHURc2/Pzzzxg3bhyWLFmCpk2bwszMDF9//bVyzuDrdHV1ERISgtDQUBw8eBArVqzA9OnTcebMGbi4uBTp2aSa/L637t+/r/yzQqHAiBEj8Omnn+a519HREampqfD19YWvry+2bNmCihUrIjo6Gn5+fsjIyChyPO/y/Tdp0iQcOHAAixcvRrVq1WBkZIRevXrlicPExETy+k3vkdRLoVBg9uzZ6NGjR55rhoaGKv2cye/7RHxtKlBh30uvt80liiIEQSjwua9fe7X9m+7NNXToUNSvXx/379/H+vXr0aZNGzg5Ob3xPqJcTFCpTDl16hScnJwkc6Lu3btXpD5cXV1hZGSEw4cPY+jQoW9s//fff8PLywsjR45Unrt9+3ah9wiCgGbNmqFZs2aYOXMmnJycsHv3bowfP75IsZJ6NGzYEFeuXCnwF6RLly7hyZMnWLBgARwcHAAAZ8+eLbRPAwMDZGdnFzmWunXrYu3atXj27Fm+VdS///4bgYGB6N69O4CcOal37959Y79veo+kXg0bNsT169cL/HrXrVsX9+/fx40bNwqtor4LNzc3ZGVl4cyZM/Dy8gKQs1jpxo0bBVbMa9WqhZMnT2LgwIHKc6Ghocr2NWvWRHR0NB49eqSclx8WFpanH3d3d3h4eGDNmjXYtm0bVqxYoe63R2UcF0lRmVKtWjVER0dj+/btuH37Nr799lvs3r27SH0YGhpiypQpmDx5MjZt2oTbt2/jn3/+wbp16wp85tmzZ3HgwAHcuHEDM2bMyPcHdq4zZ85g3rx5OHv2LKKjo7Fr1y48fvyYQ6waNGXKFJw+fRqjRo1CREQEbt68ib1792LMmDEAciqMBgYGWLFiBe7cuYO9e/e+cX9eZ2dnpKSk4PDhw3jy5AlevHihUix9+/aFXC5Ht27dcOrUKdy5cwe//vorTp8+DSDn+23Xrl3KYdN+/fopK2bv8h5JvWbOnIlNmzYhKCgIV65cQWRkJHbs2IEvvvgCAODt7Y2WLVuiZ8+eCAkJQVRUFPbv34+//vpLbTG4urqia9euGDZsGE6ePIkLFy6gf//+eO+999C1a9d875k0aRKCg4Pxww8/4ObNm1i6dCl27dqlXJzVrl07VK1aFQEBAbh48SJOnTqlLAi8XlkdOnQoFixYgOzsbOUvVESqYoJKZUrXrl0xbtw4jB49GvXr10doaChmzJhR5H5mzJiBCRMmYObMmahVqxb69OlT4JZCH3/8MXr06IE+ffqgcePGePr0qaSa+jpzc3OcOHEC/v7+qF69Or744gssWbIEHTp0KHKcpB5169bF8ePHcfPmTbRo0QINGjTAjBkzYGdnByBnP97g4GD88ssvcHNzw4IFC7B48eJC+/Ty8sLHH3+MPn36oGLFili0aJFKsRgYGODgwYOoVKkS/P394e7uLlndvWzZMlhaWsLLywudO3eGn58fGjZs+M7vkdTLz88P+/btQ0hICDw9PdGkSRMsXbpUMsz966+/wtPTE3379oWbmxsmT578VlX3wmzYsAGNGjVCp06d0LRpU4iiiD///DPP1IBc3bp1wzfffIOvv/4atWvXxo8//ogNGzbAx8cHQM4UpT179iAlJQWenp4YOnSoMuk2NDSU9NW3b1/o6emhX79+ea4RvYkgFjRJhYiIiOgNTp06hebNm+PWrVuSRV0xMTFwdnZGWFiYSr9EEb2KCSoRERGpbPfu3TA1NYWrqytu3bqFzz77DJaWljh58iQAIDMzE7GxsZg6dSru3buHU6dOaThiKo24SIqIiIhUlpycjMmTJyMmJgY2NjZo27atZKeUU6dOoVWrVqhevTp27typwUipNGMFlYiIiIi0ChdJEREREZFWYYJKRERERFqFCSoRERERaRUmqERERESkVZigEhEREZFWYYJKRCUuODgYgiAoDz09PVSuXBmDBg3CgwcPSiQGZ2dnBAYGKl8fO3YMgiDg2LFjReonNDQUQUFBeP78uVrjA4DAwEA4Ozu/sZ2Pjw/q1Kmjlmfm/t2cPXtWLf292ufdu3fV1icRlW1MUIlIYzZs2IDTp08jJCQEw4YNw08//YQWLVogNTW1xGNp2LAhTp8+XeRPvAkNDcXs2bOLJUElIiqvuFE/EWlMnTp14OHhAQBo1aoVsrOz8dVXX2HPnj346KOP8r3nxYsXMDY2Vnss5ubmaNKkidr7JSKiomMFlYi0Rm6CeO/ePQA5Q9ympqa4dOkSfH19YWZmhjZt2gAAMjIyMGfOHNSsWRMymQwVK1bEoEGD8PjxY0mfmZmZmDx5MuRyOYyNjdG8eXP8+++/eZ5d0BD/mTNn0LlzZ1hbW8PQ0BBVq1bF2LFjAQBBQUGYNGkSAMDFxUU5ZeHVPnbs2IGmTZvCxMQEpqam8PPzw/nz5/M8Pzg4GDVq1IBMJkOtWrWwadOmt/oaFuTs2bP48MMP4ezsDCMjIzg7O6Nv377Kr/XrEhISMGjQIFhZWcHExASdO3fGnTt38rQ7dOgQ2rRpA3NzcxgbG6NZs2Y4fPiwWmMnovKHCSoRaY1bt24BACpWrKg8l5GRgS5duqB169b47bffMHv2bCgUCnTt2hULFixAv3798Mcff2DBggUICQmBj48P0tLSlPcPGzYMixcvxsCBA/Hbb7+hZ8+e6NGjBxISEt4Yz4EDB9CiRQtER0dj6dKl2L9/P7744gs8evQIADB06FCMGTMGALBr1y6cPn1aMk1g3rx56Nu3L9zc3PDzzz9j8+bNSE5ORosWLXD16lXlc4KDgzFo0CDUqlULv/76K7744gt89dVXOHLkyLt/Uf/v7t27qFGjBpYvX44DBw5g4cKFiI2NhaenJ548eZKn/ZAhQ6Cjo4Nt27Zh+fLl+Pfff+Hj4yOZyrBlyxb4+vrC3NwcGzduxM8//wwrKyv4+fkxSSWidyMSEZWwDRs2iADEf/75R8zMzBSTk5PFffv2iRUrVhTNzMzEuLg4URRFMSAgQAQgrl+/XnL/Tz/9JAIQf/31V8n5sLAwEYD4/fffi6IoipGRkSIAcdy4cZJ2W7duFQGIAQEBynNHjx4VAYhHjx5VnqtatapYtWpVMS0trcD38vXXX4sAxKioKMn56OhoUU9PTxwzZozkfHJysiiXy8XevXuLoiiK2dnZor29vdiwYUNRoVAo2929e1fU19cXnZycCnx2Lm9vb7F27dpvbPeqrKwsMSUlRTQxMRG/+eYb5fncv5vu3btL2p86dUoEIM6ZM0cURVFMTU0VraysxM6dO0vaZWdni/Xq1RPff//9PH2+/jUiIioIK6hEpDFNmjSBvr4+zMzM0KlTJ8jlcuzfvx+2traSdj179pS83rdvHypUqIDOnTsjKytLedSvXx9yuVw5xH706FEAyDOftXfv3tDTK3wK/o0bN3D79m0MGTIEhoaGRX5vBw4cQFZWFgYOHCiJ0dDQEN7e3soYr1+/jocPH6Jfv34QBEF5v5OTE7y8vIr83IKkpKRgypQpqFatGvT09KCnpwdTU1OkpqYiMjIyT/vXv2ZeXl5wcnJSfk1DQ0Px7NkzBAQESN6fQqFA+/btERYWppHFbkRUNnCRFBFpzKZNm1CrVi3o6enB1tYWdnZ2edoYGxvD3Nxccu7Ro0d4/vw5DAwM8u03d8j66dOnAAC5XC65rqenB2tr60Jjy53LWrlyZdXezGtypwF4enrme11HR6fQGHPPqWtrpn79+uHw4cOYMWMGPD09YW5uDkEQ4O/vL5kS8eqz8zuXG2/u++vVq1eBz3z27BlMTEzUEj8RlS9MUIlIY2rVqqVcxV+QV6uKuWxsbGBtbY2//vor33vMzMwAQJmExsXF4b333lNez8rKUiZaBcmdB3v//v1C2xXExsYGALBz5044OTkV2O7VGF+X37m3kZiYiH379mHWrFmYOnWq8nx6ejqePXuW7z0FxVOtWjUA/72/FStWFLj7weuVcCIiVTFBJaJSp1OnTti+fTuys7PRuHHjAtv5+PgAALZu3YpGjRopz//888/Iysoq9BnVq1dH1apVsX79eowfPx4ymSzfdrnnX69C+vn5QU9PD7dv384zReFVNWrUgJ2dHX766SeMHz9emZDfu3cPoaGhsLe3LzROVQiCAFEU87yHtWvXIjs7O997tm7dKok7NDQU9+7dw9ChQwEAzZo1Q4UKFXD16lWMHj36nWMkInoVE1QiKnU+/PBDbN26Ff7+/vjss8/w/vvvQ19fH/fv38fRo0fRtWtXdO/eHbVq1UL//v2xfPly6Ovro23btrh8+TIWL16cZ9pAfr777jt07twZTZo0wbhx4+Do6Ijo6GgcOHAAW7duBQC4u7sDAL755hsEBARAX18fNWrUgLOzM7788ktMnz4dd+7cQfv27WFpaYlHjx7h33//hYmJCWbPng0dHR189dVXGDp0KLp3745hw4bh+fPnCAoKyneYvSBJSUnYuXNnnvMVK1aEt7c3WrZsia+//ho2NjZwdnbG8ePHsW7dOlSoUCHf/s6ePYuhQ4figw8+QExMDKZPn4733nsPI0eOBACYmppixYoVCAgIwLNnz9CrVy9UqlQJjx8/xoULF/D48WOsWrVK5fiJiCQ0vUqLiMqf3FXdYWFhhbYLCAgQTUxM8r2WmZkpLl68WKxXr55oaGgompqaijVr1hRHjBgh3rx5U9kuPT1dnDBhglipUiXR0NBQbNKkiXj69GnRycnpjav4RVEUT58+LXbo0EG0sLAQZTKZWLVq1Ty7AkybNk20t7cXdXR08vSxZ88esVWrVqK5ubkok8lEJycnsVevXuKhQ4ckfaxdu1Z0dXUVDQwMxOrVq4vr168XAwICVF7FDyDfw9vbWxRFUbx//77Ys2dP0dLSUjQzMxPbt28vXr58Oc/XIffv5uDBg+KAAQPEChUqiEZGRqK/v7/k65rr+PHjYseOHUUrKytRX19ffO+998SOHTuKv/zyS54+uYqfiFQliKIoaig3JiIiIiLKg9tMEREREZFWYYJKRERERFqFCSoRERERaRUmqERERESkVZigEhEREZFWYYJKRERERFqFCSoRERERaRUmqERERESkVZigEhEREZFWYYJKRERERFqFCSoRERERaZX/AV/13WN3AQdKAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Modelin actual data'lara yaptigi prediction sonuclarini gorsellestirmek icin confusion matrix olustur.\n",
    "cm = confusion_matrix(y_test, y_pred) \n",
    "\n",
    "class_names = ['Financials', 'Healthcare', 'Technology']\n",
    "\n",
    "# Confusion Matrix'i Gorsellestirme.\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "disp.plot(ax=ax)\n",
    "\n",
    "# Tag ve Header ekle.\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('Actual Label', fontsize=12)\n",
    "plt.title('Confusion Matrix', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b74f185-b110-44df-9056-c714fb0fe670",
   "metadata": {},
   "source": [
    "## Bonus: Real Estate Sector Predictions\n",
    "Train edilmis modelimizi kullanarak real estate sektorundeki data'ların hangi sektore benzedigini gorelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccaaff7-a73f-4cfe-9b87-4bb4745c734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_data(sectors=\"real-estate\").to_csv(\"Datasets/Real-Estate.csv\")\n",
    "\n",
    "real_estate = pd.read_csv(\"Datasets/Real-Estate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c186e8f-371c-4e37-8c2e-47cef897ad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_symbols_re = [str(symbol) for symbol in real_estate.Symbol if isinstance(symbol, str)]\n",
    "\n",
    "real_estate_data = yf.download(valid_symbols_re, start='2005-01-01') \n",
    "\n",
    "real_estate_data_open = real_estate_data['Open'].resample(\"M\").last().pct_change() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40a9db5-1c24-4f08-a64e-b4d181f18a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_df = get_ts(real_estate_data_open)\n",
    "re_df.dropna(inplace=True)\n",
    "\n",
    "last_re_df = extracting_symbols_features(re_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1233b1a0-7b7e-4c21-88c0-cd3f95f332bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_re_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bd3c3c-4287-4fe9-b6f8-6d263f4e4778",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_re_df.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab5fbc3-fa12-446b-b3da-e3f72ab9f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_re_df_X = last_re_df.copy()\n",
    "last_re_df_X.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "last_re_df_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dbdcea-9375-48a8-8684-3402afe818ba",
   "metadata": {},
   "source": [
    "Modelimizin kullandigi feature'lari gormek icin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e785cf8c-6a3f-4352-86da-4c7aeca95360",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pipeline[-1]\n",
    "\n",
    "df_importances = pd.DataFrame(clf.feature_names_in_, columns=['Feature'])\n",
    "\n",
    "df_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77363e0b-09ce-4dfe-80a0-8ab14dcb8f59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last_re_df_X_processed = preprocessor.fit_transform(last_re_df_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690ce873-03ec-4aef-a351-4bce54a3d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = random_search.predict(last_re_df_X_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b636de-85e9-417b-9e01-46ee5253c4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_labels = le.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f86359-654f-49ee-9596-484158327bcb",
   "metadata": {},
   "source": [
    "## Save Model By Onnx:\n",
    "Scikit-learn modelleri icin uyumlu olan skl2onnx library'si icerisindeki convert_sklearn() method'unu kullanarak modelimizi istedigimiz formatta save edebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3fe9f6a5-93b1-4462-a2e1-79156fa5b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Cast etme warning'ini gormek istemiyorsak kullanilabilir.\n",
    "warnings.filterwarnings(\"ignore\", message=\"overflow encountered in cast\")\n",
    "\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "# En iyi modeli alın\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# ONNX formatına dönüştürme için giriş veri tipini belirtin\n",
    "initial_type = [('float_input', FloatTensorType([None, X_train.shape[1]]))]\n",
    "\n",
    "# Scikit-learn modelini ONNX formatına dönüştürün\n",
    "onnx_model = convert_sklearn(best_model, initial_types=initial_type)\n",
    "\n",
    "# ONNX modelini dosyaya kaydedin\n",
    "with open(\"best_model.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
